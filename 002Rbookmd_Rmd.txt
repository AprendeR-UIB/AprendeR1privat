
# Descripción de datos cuantitativos {#chap:edquan}

 Los datos cuantitativos\index{datos!cuantitativos} son los que expresan cantidades que se representan mediante números, tales como los resultados de contar objetos o individuos o de medir pesos, distancias, tiempos o concentraciones, y se suelen clasificar en continuos  y discretos.
Los `datos continuos` \index{datos!continuos} son los que, si pudiéramos medirlos con precisión infinita, en principio podrían tomar todos los valores de un intervalo de la recta real:  por ejemplo, el peso o la altura de un individuo o el tiempo que tarda un determinado proceso.
En cambio, los `datos discretos` \index{datos!discretos} son los que pueden tomar sólo un conjunto  contable de valores: el resultado obtenido al lanzar un dado, el número de individuos en una población, el número de aminoácidos en una proteína\ldots\ En todo caso, hay que tener en cuenta que esta distinción es sólo teórica: en la práctica, todos los datos son discretos, ya que la precisión infinita no existe. Pero a veces es necesario suponer que unos datos son continuos para poder usar técnicas específicas en su análisis.

Para estudiar una `variable cuantitativa`  (una lista de datos cuantitativos), podemos usar las frecuencias y las frecuencias acumuladas de sus diferentes valores, 
como en las variables ordinales, puesto que podemos ordenar los datos cuantitativos con el orden natural de los números reales. Pero además de las frecuencias, disponemos de otras muchas técnicas descriptivas, ya que, como los datos cuantitativos son números reales y tienen el significado de números reales, podemos operar con ellos.

Los datos cuantitativos admiten dos tipos de tratamiento, según trabajemos con los datos originales o `brutos`  (*raw data*) o los agrupemos en clases o intervalos (recordad el Ejemplo  \@ref(ex:sprayord)). En esta lección vamos a tratar sólo  la primera situación, y en la  Lección 
\@ref(chap:cut) estudiaremos la descripción de datos agrupados.

## Frecuencias

 
El tratamiento de las frecuencias de datos cuantitativos es similar al de los datos ordinales, excepto por el hecho de que no se tienen en cuenta todos los niveles posibles, sino sólo los  observados.

\begin{ejemplo}\label{ex:18.1}
Hemos pedido las edades a un grupo de 15 voluntarios de una ONG. Las respuestas, en años, han sido las siguientes:
$$
18, 22, 16, 19, 23, 18, 35, 16, 45, 20, 20, 22, 40, 18, 45.
$$
Las diferentes edades que hemos observado son 16, 18, 19, 20, 22, 23, 35, 40 y 45, y por lo tanto sólo nos interesan las frecuencias de estas edades. Las podemos calcular con `R` y así, de paso, recordaremos cómo se hace.


```
> edades=c(18,22,16,19,23,18,35,16,45,20,20,22,40,18,45)
> table(edades)    #Frecuencias absolutas
edades
16 18 19 20 22 23 35 40 45 
 2  3  1  2  2  1  1  1  2 
> round(prop.table(table(edades)), 2)    #Frecuencias relativas
edades
  16   18   19   20   22   23   35   40   45 
0.13 0.20 0.07 0.13 0.13 0.07 0.07 0.07 0.13 
> cumsum(table(edades))  #Frecuencias absolutas acumuladas
16 18 19 20 22 23 35 40 45 
 2  5  6  8 10 11 12 13 15 
> round(cumsum(prop.table(table(edades))), 2)   #Frecuencias relativas acumuladas
  16   18   19   20   22   23   35   40   45 
0.13 0.33 0.40 0.53 0.67 0.73 0.80 0.87 1.00 
```
\end{ejemplo}

Supongamos que realizamos $n$ observaciones de una propiedad que se mide con un número real, y obtenemos la lista de datos cuantitativos (la `variable cuantitativa` )
$$
x_1, \ldots, x_n.
$$
Sean $X_1, \ldots, X_k$ los  valores distintos que aparecen en esta lista de datos; los consideraremos ordenados
$$
X_1 < X_2 < \cdots < X_k.
$$
Entonces, en esta variable cuantitativa:\indR{table}\indR{prop.table}\indR{cumsum} 

* La `frecuencia absoluta` \index{frecuencia!absoluta} de $X_j$  es el número $n_j$ de elementos que son iguales a $X_j$.

* La `frecuencia absoluta acumulada` \index{frecuencia!absoluta acumulada} de $X_j$   es 
$\displaystyle N_j=\sum\limits_{i=1}^j n_i.$

* La `frecuencia relativa` \index{frecuencia!relativa} de $X_j$   es 
$\displaystyle f_j=\frac{n_j}{n}.$

* La `frecuencia relativa acumulada` \index{frecuencia!relativa acumulada} de $X_j$ es
$\displaystyle F_j=\frac{N_j}{n}=\sum\limits_{i=1}^j f_i.$


 
\begin{ejemplo}
\label{ex:dados}
Lanzamos 10 veces un dado de seis caras al aire y anotamos los resultados:
\begin{center}
1, 2, 1, 4, 5, 6, 3, 5, 6, 3.
\end{center}
En este caso, $n=10$, y los distintos valores observados son
$$
X_1=1,\ X_2=2,\ X_3=3,\ X_4=4,\ X_5=5,\ X_6=6.
$$
Vamos a calcular las frecuencias de este experimento, y las organizaremos en forma de *data frame* para visualizarlas como una tabla:
```
> dados=c(1,2,1,4,5,6,3,5,6,3)
> table(dados)
dados
1 2 3 4 5 6 
2 1 2 1 2 2 
> prop.table(table(dados))
dados
  1   2   3   4   5   6 
0.2 0.1 0.2 0.1 0.2 0.2 
> cumsum(table(dados))
 1  2  3  4  5  6 
 2  3  5  6  8 10 
> cumsum(prop.table(table(dados)))
  1   2   3   4   5   6 
0.2 0.3 0.5 0.6 0.8 1.0 
> tabla_df=data.frame(Resultado=1:6, 
  Frec_Abs=as.vector(table(dados)), 
  Frec_Rel=as.vector(round(prop.table(table(dados)), 2)), 
  Frec_Abs_Acum=as.vector(cumsum(table(dados))), 
  Frec_Rel_Acum=as.vector(round(cumsum(prop.table(table(dados))),
   2)))
> tabla_df
  Resultado Frec_Abs Frec_Rel Frec_Abs_Acum Frec_Rel_Acum
1         1        2      0.2             2           0.2
2         2        1      0.1             3           0.3
3         3        2      0.2             5           0.5
4         4        1      0.1             6           0.6
5         5        2      0.2             8           0.8
6         6        2      0.2            10           1.0
```
Para entrar una tabla unidimensional como una variable en un *data frame*, es conveniente transformarla en vector con `as.vector`. De lo contrario, cada `table` y cada `prop.table` añadirían una columna extra con los nombres de los niveles. Comprobadlo.
\end{ejemplo}

## Medidas de tendencia central

  Las medidas de tendencia central son las que dan un valor representativo de todas las observaciones; las más importantes son:

* La `moda` \index{moda}, que es el valor, o los valores, de máxima frecuencia (absoluta o relativa, tanto da).

* La `media aritmética` \index{media}, o `valor medio` \index{valor medio|see{media}}, 
$$
 \overline{x}=\frac{\sum_{i=1}^n
x_i}{n}=\frac{\sum_{j=1}^k n_j\cdot X_j}{n}=
\sum_{j=1}^k f_j\cdot X_j.
$$

* La `mediana` \index{mediana}, que representa el valor central en la lista ordenada de observaciones y se define formalmente de la manera siguiente. Si denotamos por
$$
x_{(1)}\leq x_{(2)}\leq \cdots \leq x_{(n)}
$$
los datos de la variable cuantitativa ordenados de menor a mayor, la mediana es

* Si $n$ es par, la media de los dos datos centrales:
$$
\frac{x_{\left(\frac{n}{2}\right)}+x_{\left(\frac{n}{2}+1\right)}}{2}.
$$
*  Si $n$ es impar,  el dato central: $x_{\left(\frac{n+1}{2}\right)}$.


En estos apuntes, cuando hablemos de la *media*  de unos datos nos referiremos siempre a su media aritmética. Hay otros tipos de media, como por ejemplo la media geométrica o la armónica, que no estudiaremos.


\begin{ejemplo}
En la situación del Ejemplo \@ref(ex:18.1), la moda es 18 y  la media es
$$
\frac{18+22+16+19+23+18+35+16+45+20+20+22+40+18+45}{15}=25.1333.
$$
Si ordenamos los 15 resultados, quedan de la siguiente manera:
$$
16, 16, 18, 18, 18, 19, 20, 20, 22, 22, 23, 35, 40, 45, 45
$$
Su mediana es la entrada central en esta lista, es decir, la octava: 20.

En la situación del Ejemplo \@ref(ex:dados), la moda es, de hecho, cuatro valores: 1, 3, 5 y 6. La media es
$$
\frac{1+2+1+4+5+6+3+5+6+3}{10}=3.6.
$$
Como esta variable contiene 10 datos, su mediana es la media aritmética de sus dos resultados centrales (el quinto y el sexto) en la lista ordenada de resultados
$$
1, 1, 2, 3, 3, 4, 5, 5, 6, 6. 
$$
Por lo tanto, su mediana es $(3+4)/2=3.5$.
\end{ejemplo}

Ya explicamos cómo se calcula la moda con `R` en la Lección \@ref(chap:edqual). La única diferencia aquí es que, como trabajamos con datos cuantitativos, es conveniente que el resultado lo demos como un número, aplicándole `as.numeric`\indR{as.numeric}. En cuanto a la media y la mediana, se calculan aplicando las funciones `mean` y  `median`, respectivamente, al vector de datos.\indR{mean}\indR{median)
```
> edades=c(18,22,16,19,23,18,35,16,45,20,20,22,40,18,45)
> as.numeric(names(which(table(edades)==max(table(edades)))))  #La moda
[1] 18
> mean(edades) #La media
[1] 25.13333
> median(edades)  #La mediana
[1] 20
> dados=c(1,2,1,4,5,6,3,5,6,3)
> as.numeric(names(which(table(dados)==max(table(dados))))) 
[1] 1 3 5 6
> mean(dados)
[1] 3.6
> median(dados)
[1] 3.5
```

  
## Medidas de posición

 Las medidas de posición estiman qué valores dividen la población en unas determinadas proporciones; los valores que determinan estas posiciones reciben el nombre de `cuantiles` . 
En este sentido, la mediana es también una medida de posición, puesto que divide la variable en dos mitades.


Dada una proporción $0<p<1$, el `cuantil de orden $p$`  de una variable cuantitativa\index{cuantil}, que denotaremos por $Q_p$, es  el valor más pequeño tal que su frecuencia relativa acumulada es mayor o igual que $p$. En otras palabras, si tenemos un conjunto de datos $x_1, \ldots, x_n$ y los ordenamos de menor a mayor, $Q_p$ es el número más pequeño que deja a su izquierda (incluyéndolo a él) como mínimo
la fracción $p$ de los datos, es decir, 
$p\cdot n$ datos.
De esta manera, la mediana viene a ser el cuantil $Q_{0.5}$.


\begin{ejemplo}\label{ex:18.4}
Consideremos otro experimento de lanzamiento de dados. Esta vez lo lanzamos 30 veces y obtenemos los resultados siguientes:
$$
2, 4, 5, 6, 3, 2, 4, 5, 1, 2, 1, 3, 4, 2, 3, 4, 1, 2, 5, 6, 5, 5, 3, 2, 1, 3, 4, 2, 2, 1.
$$
Ordenamos estos resultados de menor a mayor.
```
> dados2=c(2,4,5,6,3,2,4,5,1,2,1,3,4,2,3,4,1,2,5,6,5,5,3,2,1,3,4,
   2,2,1)
> length(dados2)
[1] 30
> dados2=sort(dados2)
> dados2
[1] 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6
```
Si nos pidieran el cuantil $Q_{0.2}$, sería el primer elemento en esta lista ordenada que fuera mayor o igual que, como mínimo, el 20\% de los datos. Como el 20\% de 30 es 6, sería el sexto elemento.
```
> dados2[6]
[1] 2
```
Si nos pidieran en cambio $Q_{0.65}$, sería el primer elemento en esta lista ordenada  mayor o igual que, como mínimo, el 65\% de los datos. Como el 65\% de 30 es 19.5, sería el vigésimo elemento.
```
> dados2[20]
[1] 4
```

También podemos calcular los cuantiles comparando la proporción $p$ con las frecuencias relativas acumuladas.
```
> cumsum(prop.table(table(dados2)))
        1         2         3         4         5         6 
0.1666667 0.4333333 0.6000000 0.7666667 0.9333333 1.0000000 
```
El primer elemento con frecuencia relativa acumulada $\geq 0.2$ es 2, lo que implica que $Q_{0.2}=2$, y el
primer elemento con frecuencia relativa acumulada $\geq 0.65$ es 4, por lo que $Q_{0.65}=4$.
\end{ejemplo}


Algunos cuantiles  tienen nombre propio:

* La `mediana` \index{mediana} es el cuantil $Q_{0.5}$.

* Los `cuartiles` \index{cuartil} son los cuantiles $Q_{0.25}$, $Q_{0.5}$ y $Q_{0.75}$, y reciben, respectivamente, los nombres de `primer cuartil` , `segundo cuartil`  (o mediana) y `tercer cuartil` . $Q_{0.25}$ será, pues, el menor valor que es mayor o igual que  una cuarta parte de los datos, y $Q_{0.75}$, el menor valor que es mayor o igual que   tres cuartas partes de los datos.


* Los `deciles` \index{decil} son los cuantiles $Q_{p}$ con $p$ un múltiplo entero de 0.1: el `primer decil`  es $Q_{0.1}$, el  `segundo decil`  es $Q_{0.2}$, y así sucesivamente.

* Los `percentiles` \index{percentil} son los cuantiles $Q_{p}$ con $p$ un múltiplo entero de 0.01.


Ha llegado el momento de avisar que la definición de cuantil que hemos dado es más bien orientativa; en realidad, y salvo para el caso de la mediana, no hay un consenso sobre cómo se tienen que calcular los cuantiles, de manera que se han propuesto métodos diferentes que pueden dar  resultados diferentes. 
La razón es que el objetivo final del cálculo de cuantiles no es solo encontrar el primer valor cuya frecuencia relativa acumulada en la variable sea mayor o igual que $p$, sino también estimar qué vale este valor para el total de la población.

Con `R`, los cuantiles de orden $p$ de un vector $x$ se calculan con la instrucción\indR{quantile} 

`quantile(`$x$`, p)`.

Veamos algunos ejemplos:
```
> x=c(1,2,3,4,5,6,2,3,2,3,4,2,2,3,2,2,5,7,3,4,2,1,3,6)
> round(cumsum(prop.table(table(x))), 3)
    1     2     3     4     5     6     7 
0.083 0.417 0.667 0.792 0.875 0.958 1.000 
> quantile(x, 0.1)
10% 
  2 
> quantile(x, 0.25)
25% 
  2 
> quantile(x, 0.75)
75% 
  4 
```


`R` dispone de 9 métodos diferentes para calcular cuantiles, que se pueden especificar dentro de `quantile` con el parámetro `type`\indRp{quantile}{type}. En la mayoría de las ocasiones se obtiene el mismo resultado con todos los métodos, pero no siempre. Para saber en detalle las fórmulas que usa  `quantile` para cada valor de `type`, se puede consultar la entrada correspondiente de la *Wikipedia*.^[  [http://en.wikipedia.org/wiki/quantile](http://en.wikipedia.org/wiki/quantile) ]  El método que hemos usado en el Ejemplo \@ref(ex:18.4) es el que corresponde a `type=1`, y siempre da un dato de los observados. El problema es que, entonces, `quantile(x,0.5,type=1)` y  `median(x)` pueden dar resultados diferentes. El método por defecto, que no hace falta especificar, es `type=7`.
```
> x=c(1,2,3,4,5,6,2,3,2,3,4,2,2,3,2,2,5,7,3,4,2,1,3,6)
> round(cumsum(prop.table(table(x))), 3)
    1     2     3     4     5     6     7 
0.083 0.417 0.667 0.792 0.875 0.958 1.000 
> quantile(x, 0.67)
 67% 
3.41 
> quantile(x, 0.67, type=1)
67% 
  4 
> dados=c(1,2,1,4,5,6,3,5,6,3)
> round(cumsum(prop.table(table(dados))), 3)
  1   2   3   4   5   6 
0.2 0.3 0.5 0.6 0.8 1.0 
> median(dados)
[1] 3.5
> quantile(dados, 0.5, type=1)
50% 
  3 
> quantile(dados, 0.5, type=7)
50% 
3.5 
```


Seguramente os preguntáis: si los cuantiles se pueden calcular de diferentes maneras, ¿cómo lo tenéis que hacer vosotros?  Como en el nivel de este curso no es necesario afinar tanto, aquí usaremos la función `quantile` sin especificar `type`, es decir, con su método por defecto; no hace falta que sepáis qué hace este método, lo importante es que entendáis el concepto de cuantil y qué representa, *grosso modo*, el resultado de `quantile`.


## Medidas de dispersión

 Las medidas de dispersión evalúan lo desperdigados que están los datos. Las más importantes son:

* El `rango` , o `recorrido` \index{rango}\index{recorrido|see{rango}}, que es la diferencia entre el máximo y el mínimo de las observaciones.

* El `rango intercuartílico` \index{rango intercuartílico}, que es la diferencia $Q_{0.75}-Q_{0.25}$.

* La `varianza` \index{varianza}, que es la media aritmética de las diferencias al cuadrado entre los datos $x_i$ y la media $\overline{x}$ de la variable; la denotamos por $s^2$. Es decir, 
$$
s^2=\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}=\frac{\sum_{i=1}^k n_i\cdot
(X_i-\overline{x})^2}{n}=\sum_{i=1}^k f_i\cdot (X_i-\overline{x})^2.
$$

* La `desviación típica` \index{desviación típica}, que es la raíz cuadrada positiva $s$ de la varianza: 
$s=\sqrt{s^2}$.

* La `varianza muestral` \index{varianza!muestral}, que es la corrección siguiente de la varianza:
$$
\tilde{s}^2 =\frac{n}{n-1} \cdot s^2=\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n-1}.
$$
Esto es, la varianza muestral se calcula con la misma fórmula que la varianza salvo que el denominador es $n-1$ en lugar de $n$.

* La  `desviación típica muestral` \index{desviación típica!muestral}, que es la raíz cuadrada positiva $\tilde{s}$ de la varianza muestral: $\tilde{s}=\sqrt{\tilde{s}^2}$.



La distinción entre la versión muestral y  la <<`verdadera` >> de la varianza está motivada por la interrelación entre la estadística descriptiva y la inferencial de la que hablábamos en la introducción de la Lección \@ref(chap:df). Por un lado, es natural medir la variabilidad de un conjunto de datos cuantitativos mediante su varianza <<verdadera>>, definida como la media de las distancias (al cuadrado) de los datos a su valor promedio; pero, por otro lado, nuestro conjunto de datos será, normalmente,  una muestra de una población mucho mayor, de la que querremos estimar información, y en concreto su variabilidad. Por poner un ejemplo, las flores iris recogidas en la tabla de datos `iris` forman  una muestra de la  población de `todas`  las flores iris. Con las técnicas de la estadística descriptiva, resumimos y representamos las características de esta muestra concreta; pero este estudio suele ser sólo un paso previo al análisis inferencial de estos datos,  cuyo objetivo no es analizar esta muestra en si misma, sino inferir información sobre todas las flores iris a partir de esta muestra; así, lo más probable es que, en realidad, la variabilidad de las longitudes de los sépalos de las flores de iris setosa en esta muestra nos interese sobre todo como  estimación de la variabilidad 
de las longitudes de los sépalos de `todas`  las flores de esta especie.

Pues bien, resulta que la varianza <<verdadera>> de una muestra tiende a dar valores más pequeños que la varianza real de la población, mientras que  la varianza muestral  tiende a dar valores alrededor de la varianza real  de la población. Para muestras grandes, la diferencia no es sustancial: si $n$ es grande, dividir por $n$ o por $n-1$ no significa una gran diferencia, y  sobre todo si tenemos en cuenta que se trata de estimar la varianza de la población, no de calcularla exactamente. Pero si el tamaño de la muestra es pequeño (pongamos, de menos de $25$ individuos), la varianza muestral de una muestra aproxima significativamente mejor la varianza real de la población que su varianza <<verdadera>>.  La justificación de este hecho se basa en la teoría de la estimación de parámetros y se sale de los objetivos de este curso.

 
¿Y por qué definimos la varianza y desviación típica, si ambas medidas dan una información equivalente? El motivo es que si los elementos de una variable cuantitativa tienen unidades (metros, años, individuos por metro cuadrado\ldots), 
su varianza (sea <<verdadera>>  o muestral) tiene estas unidades al cuadrado; por ejemplo, si los $x_i$ son años, los valores de  $s^2$ y $\tilde{s}^2$ representan años al cuadrado. En cambio, las desviaciones típicas tienen las mismas unidades que los datos, por lo que se pueden comparar con ellos, y de ahí su utilidad. 

La varianza tiene las propiedades matemáticas siguientes:

* $s^2\geq 0$, porque es una suma de cuadrados de numeros reales.

* Si $s^2=0$, todos los sumandos $(x_i-\overline{x})^2$ son 0 y, por lo tanto, todos los datos son iguales  a su media. En particular, $s^2=0$ significa que todos los datos son iguales.


* A partir de la fórmula dada para $s^2$, se tiene que
$$
\begin{array}{rl}
n\cdot s^2 & \displaystyle = \sum_{i=1}^n (x_i-\overline{x})^2=
\sum_{i=1}^n (x_i^2-2\overline{x}x_i+\overline{x}^2)=
\sum_{i=1}^n x_i^2-2\sum_{i=1}^n\overline{x}x_i+\sum_{i=1}^n\overline{x}^2\\[2ex]
&  \displaystyle =
\sum_{i=1}^n x_i^2-2\overline{x}\Big(\sum_{i=1}^n x_i\Big)+n\overline{x}^2=
\sum_{i=1}^n x_i^2-2\overline{x}\cdot n\overline{x}+n\overline{x}^2=
\sum_{i=1}^n x_i^2-n\overline{x}^2
\end{array}
 $$
de donde deducimos que
$$
s^2=\frac{\sum_{i=1}^n x_i^2-n\overline{x}^2}{n}=
 \frac{\sum_{i=1}^n x_i^2}{n}-\overline{x}^2.
$$
Es decir, `la varianza es la media de los cuadrados de los datos, menos el cuadrado de la media de los datos` .


Hay que ir con cuidado con  la desviación típica y la desviación típica muestral. En los trabajos científicos es frecuente que se utilice una u otra sin especificar cuál es, y se la llame <<desviación típica>> (*standard deviation*) y se la denote por $s$ independientemente de cuál sea en realidad. Asimismo, la mayoría de paquetes estadísticos llevan funciones para calcular la varianza y la desviación típica (sin más aclaraciones) que, en realidad,  calculan  sus versiones muestrales; como veremos en un momento, éste va ser justamente el caso de `R`. El motivo es que, como ya hemos comentado, suele interesar más su aspecto inferencial que el descriptivo.

  
Con `R`,  podemos calcular la medidas de dispersión para un vector $x$ definidas al principio de esta sección mediante de las funciones siguientes:

* La instrucción `range(x)`\indR{range} nos da sus valores  mínimo y  máximo.

* El `rango` \index{rango} de $x$ se puede calcular con `diff(range(x))`.

* Su `rango intercuartílico` \index{rango intercuartílico} se calcula con \verb?IQR(x)?\indR{IQR}. Naturalmente, si se desea, se puede especificar el parámetro `type` de los cuantiles.

* Su `varianza muestral` \index{varianza!muestral} se obtiene con la función `var`\indR{var}.

* Su `desviación típica muestral` \index{desviación típica!muestral} se calcula con la función `sd`\indR{sd}.

* Para calcular su `varianza` \index{varianza}, tenemos que multiplicar el resultado de `var` por $(n-1)/n$, donde $n$ es el número de datos que contiene $x$ (que podemos calcular con `length`); por consiguiente,
la varianza de $x$ se puede calcular con la instrucción

`var(x)*(length(x)-1)/length(x)`.



* Para calcular su `desviación típica` \index{desviación típica}, tenemos que efectuar la raíz cuadrada de la varianza, calculada con el procedimiento anterior: por ejemplo  (y aprovechando que, por definición, `sd(...)=sqrt(var(...))`), mediante la instrucción

`sd(x)*sqrt((length(x)-1)/length(x))`.


¡Id con cuidado! Recordad que las funciones `var` y `sd` `no calculan la varianza y la desviación típica` , sino sus versiones muestrales.


```
> x=c(1,2,3,4,5,6,2,3,2,3,4,2,2,3,2,2,5,7,3,4,2,1,3,6)
> diff(range(x))   #Rango
[1] 6
> IQR(x)  #Rango intercuartílico
[1] 2
> var(x) #Varianza muestral
[1] 2.606884
> sd(x) #Desviación típica muestral
[1] 1.614585
> var(x)*(length(x)-1)/length(x) #Varianza
[1] 2.498264
> sd(x)*sqrt((length(x)-1)/length(x)) #Desviación típica
[1] 1.580590
> sqrt(var(x)*(length(x)-1)/length(x)) #Otra manera de calcular la desviación típica
[1] 1.580590
```

Si se aplica la función `summary`\indR{summary}  a un vector numérico, se obtiene un resumen estadístico que contiene sus valores mínimo y máximo, sus tres cuartiles y su media.
```
> summary(x)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   2.000   3.000   3.208   4.000   7.000 
```
La función `summary` produce otros tipos de resúmenes para otras clases de objetos; por ejemplo, ya vimos en la Lección \@ref(chap:lm) el resultado de aplicar `summary` a una `lm`.

Cuando aplicamos la función `summary` a un *data frame*, se aplica simultáneamente a todas sus variables, y así de manera rápida podemos observar si hay diferencias apreciables entre sus variables numéricas. A modo de ejemplo, si la aplicamos al *data frame* formado por las variables numéricas de la tabla `iris`, obtenemos lo siguiente:
```
> summary(iris[,1:4])
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
```
De manera similar, si quisiéramos comparar numéricamente las longitudes de pétalos y sépalos de las flores de especie setosa con las de las flores de especie virgínica, podríamos entrar  lo siguiente:
```
> summary(subset(iris, Species=="setosa", c("Sepal.Length",
  "Petal.Length")))
  Sepal.Length    Petal.Length  
 Min.   :4.300   Min.   :1.000  
 1st Qu.:4.800   1st Qu.:1.400  
 Median :5.000   Median :1.500  
 Mean   :5.006   Mean   :1.462  
 3rd Qu.:5.200   3rd Qu.:1.575  
 Max.   :5.800   Max.   :1.900  
> summary(subset(iris, Species=="virginica", 
  c("Sepal.Length","Petal.Length")))
  Sepal.Length    Petal.Length  
 Min.   :4.900   Min.   :4.500  
 1st Qu.:6.225   1st Qu.:5.100  
 Median :6.500   Median :5.550  
 Mean   :6.588   Mean   :5.552  
 3rd Qu.:6.900   3rd Qu.:5.875  
 Max.   :7.900   Max.   :6.900  
```
y deducimos así a simple vista que los pétalos y sépalos de las iris virgínica son más grandes que los de las iris setosa.

La función `by` sirve para aplicar una función a algunas columnas de un *data frame* segmentándolas según los niveles de un factor\indR{by}.
Su sintaxis es

`by(``columnas` `, ``factor` `, FUN=``función` `)`

Por lo tanto, usando `by` con `FUN=summary`, podemos calcular este resumen estadístico en las subpoblaciones definidas por los niveles de un factor.  Por ejemplo:
```
> by(iris[, 1:4], iris$Species, FUN=summary)
iris$Species: setosa
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.300   Min.   :1.000   Min.   :0.100  
 1st Qu.:4.800   1st Qu.:3.200   1st Qu.:1.400   1st Qu.:0.200  
 Median :5.000   Median :3.400   Median :1.500   Median :0.200  
 Mean   :5.006   Mean   :3.428   Mean   :1.462   Mean   :0.246  
 3rd Qu.:5.200   3rd Qu.:3.675   3rd Qu.:1.575   3rd Qu.:0.300  
 Max.   :5.800   Max.   :4.400   Max.   :1.900   Max.   :0.600  
--------------------------------------------------- 
iris$Species: versicolor
  Sepal.Length    Sepal.Width     Petal.Length   Petal.Width   
 Min.   :4.900   Min.   :2.000   Min.   :3.00   Min.   :1.000  
 1st Qu.:5.600   1st Qu.:2.525   1st Qu.:4.00   1st Qu.:1.200  
 Median :5.900   Median :2.800   Median :4.35   Median :1.300  
 Mean   :5.936   Mean   :2.770   Mean   :4.26   Mean   :1.326  
 3rd Qu.:6.300   3rd Qu.:3.000   3rd Qu.:4.60   3rd Qu.:1.500  
 Max.   :7.000   Max.   :3.400   Max.   :5.10   Max.   :1.800  
--------------------------------------------------- 
iris$Species: virginica
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.900   Min.   :2.200   Min.   :4.500   Min.   :1.400  
 1st Qu.:6.225   1st Qu.:2.800   1st Qu.:5.100   1st Qu.:1.800  
 Median :6.500   Median :3.000   Median :5.550   Median :2.000  
 Mean   :6.588   Mean   :2.974   Mean   :5.552   Mean   :2.026  
 3rd Qu.:6.900   3rd Qu.:3.175   3rd Qu.:5.875   3rd Qu.:2.300  
 Max.   :7.900   Max.   :3.800   Max.   :6.900   Max.   :2.500  
```


Usar `by` es equivalente a usar `aggregate`, pero el resultado se muestra de manera diferente. En este caso, era más conveniente usar `by`.
Entrad la instrucción siguiente y lo comprobaréis.
```
> aggregate(cbind(Sepal.Length,Sepal.Width,Petal.Length,
  Petal.Width)~Species, data=iris, FUN=summary)
```
\medskip




La mayoría de las instrucciones para calcular medidas estadísticas no admiten valores `NA`\indR{NA}.
\medskip

```
> z=c(1,2,NA,4)
> sum(z)
[1] NA
> mean(z)
[1] NA
> var(z)
[1] NA
```
Para no tenerlos en cuenta a la hora de calcularlas, lo más conveniente es incluir el parámetro \verb?na.rm=TRUE? en el argumento de la función.\indRp{mean}{na.rm=TRUE}\indRp{var}{na.rm=TRUE}\indRp{sd}{na.rm=TRUE}

```
> sum(z, na.rm=TRUE)
[1] 7
> mean(z, na.rm=TRUE)
[1] 2.333333
> var(z, na.rm=TRUE)
[1] 2.333333
```
%Si esto no funciona, por ejemplo si la función que queréis aplicar no admite este parámetro, otra posibilidad es eliminar los `NA` con la función \verb?na.omit?\indR{na.omit}, como  ya explicamos en la Lección \@ref(chap:vect).
%```
%> f=function(x){sqrt(sum(x^2))}
%> f(z)
%[1] NA
%> f(z, na.rm=TRUE)
%Error in f(z, na.rm = TRUE) : unused argument(s) (na.rm = TRUE)
%> f(na.omit(z))
%[1] 4.582576
%```



## Diagramas de caja

 Un `diagrama de caja` \index{diagrama de caja}, o *box plot*\index{box plot@{\sl box plot}|see{diagrama de caja}}, es un gráfico que resume algunos datos estadísticos de una variable cuantitativa (véase la Figura \@ref(boxplot)). Este gráfico marca básicamente cinco valores:

* Los lados inferior y superior de la caja representan el primer y el tercer cuartil, por lo que la altura de la caja es igual al rango intercuartílico.

* La línea gruesa que divide la caja marca la mediana.

* Los valores $b_{inf}, b_{sup}$ son los  `bigotes` \index{bigotes} (*whiskers*) del gráfico. Si denotamos por $m$ y $M$ el mínimo y el máximo de los datos, estos valores se calculan con las fórmulas
$$
\begin{array}{l}
b_{inf}=\mbox{máx}\{m, Q_{0.25}-1.5\cdot\left(Q_{0.75}-Q_{0.25})\right\}\\
b_{sup}=\mbox{mín}\{M, Q_{0.75}+1.5\cdot\left(Q_{0.75}-Q_{0.25})\right\}
\end{array}
$$
Es decir, los bigotes marcan el mínimo y el máximo de la variable, excepto cuando están muy alejados de la caja intercuartílica; en este caso, el bigote inferior marca el valor por debajo de $Q_{0.25}$ a distancia 1.5 veces la altura de esta caja, y el  superior marca el valor por encima de $Q_{0.75}$ a distancia 1.5 veces la altura de esta caja.

* Si hay datos más allá de los bigotes (menores que $b_{inf}$ o mayores que $b_{sup}$), se marcan como puntos aislados: son los `valores atípicos`   (*outliers*) de la variable\index{valores atípicos}.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{boxplotgen.pdf}
\end{center}
\caption{Esquema de un diagrama de caja.}\label{boxplot}
\end{figure}




La instrucción básica para dibujar un diagrama de caja con `R` es `boxplot`\indR{boxplot}. Por ejemplo,
```
> x=c(1,2,3,4,5,6,2,3,2,3,4,2,2,3,2,2,5,7,3,4,2,1,3,6)
> boxplot(x)
```
produce la Figura \@ref(fig:18.2).
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{boxplot1}
\end{center}
\caption{Un diagrama de caja.}\label{fig:18.2}
\end{figure}



La instrucción `boxplot` admite los parámetros usuales de `plot` para mejorar o hacer más informativo el resultado: `main`, `xlab`, `ylim`, `yaxp`, `col`, etc.; podéis consultarlos en su Ayuda.
Por ejemplo, si queremos producir un diagrama de caja de las longitudes de pétalos de las flores de especie setosa recogidas en el *data frame* `iris`, con más marcas en el eje vertical para facilitar la lectura de los valores y un título oportuno, podemos entrar lo siguiente:\indRp{boxplot}{yaxp}\indRp{boxplot}{main}
```
> boxplot(iris[iris$Species=="setosa", ]$Petal.Length, main="Longitudes de pétalos de las Iris setosa", yaxp=c(1,1.9,9)) 
```
y obtenemos  la Figura \@ref(fig:18.3), donde podemos observar un valor atípico.


\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{boxplot2.pdf}
\end{center}
\caption{Diagrama de caja de las longitudes de pétalos de las iris setosa.}\label{fig:18.3}
\end{figure}

Para dibujar varios diagramas de caja en un mismo gráfico, por ejemplo para poder compararlos, basta aplicar la instrucción `boxplot` a todos los vectores simultáneamente. Por ejemplo, 
```
> x=c(1,2,3,4,5,6,2,3,2,3,4,2,2,3,2,2,5,7,3,4,2,1,3,6)
> y=c(5,1,3,5,5,4,1,2,5,5,4,4,1,5,5,4,1,2,6,1)
> z=c(3,5,6,1,2,3,1,2,5,1,5,2,4,2,6,5,2,1,4,4,1,6,5,5,4,6,4,5,4,5)
> boxplot(x, y, z, names=c("x","y","z"))
```
produce el diagrama de la izquierda de la Figura \@ref(fig:18.4).  Hemos especificado dentro del `boxplot` las etiquetas de los diagramas de caja con el parámetro `names`\indRp{boxplot}{names): de lo contrario, el gráfico hubiera sido más difícil de interpretar, probadlo. Si preferís las cajas horizontales, podéis añadir el parámetro `horizontal=TRUE`:
```
> boxplot(x, y, z, names=c("x","y","z"), horizontal=TRUE)
```
produce el gráfico de la  derecha de la Figura \@ref(fig:18.4).

\vspace*{-3ex}

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{boxplot3}\
\includegraphics[width=0.45\linewidth]{boxplot3h}
\end{center}
\caption{Dos gráficos con varios diagramas de caja simultáneos.}\label{fig:18.4}
\end{figure}
\vspace*{-2ex}


Podemos dibujar los diagramas de caja de todas las variables de un *data frame* en un solo paso, aplicando la función `boxplot` al  \df; por ejemplo, 
```
> boxplot(iris)
```
produce el gráfico de la izquierda de la Figura \@ref(fig:18.5).
Observaréis que este gráfico no es muy satisfactorio. Dibujar el diagrama de caja de la variable <<Species>>, que es un factor, no tiene ningún sentido, y los nombres, además, no han quedado muy vistosos; podemos mejorar este gráfico, incluyendo sólo las cuatro primeras variables y cambiando un poco los nombres, con la instrucción siguiente, que produce el gráfico de la derecha de la Figura \@ref(fig:18.5):
\medskip

```
> boxplot(iris[, 1:4], names=c("Sepal\n length", "Sepal\n width", 
 "Petal\n length", "Petal\n width"))
```
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{boxplotiris}\
\includegraphics[width=0.45\linewidth]{boxplotiris2}
\end{center}
\caption{Diagramas de caja del *data frame* `iris`.}\label{fig:18.5} 
\end{figure}

El objetivo de agrupar varios diagramas de caja en un único gráfico suele ser el poder compararlos visualmente, y esto normalmente sólo tiene sentido cuando las variables tienen significados muy similares, o mejor, cuando son la misma variable sobre poblaciones diferentes. En concreto, a menudo querremos producir diagramas de caja de una variable cuantitativa segmentada por un factor, porque esto nos permitirá comparar el comportamiento de esta variable sobre cada uno de los niveles del factor. La manera más conveniente de hacerlo es partir de un *data frame* donde el factor sea una variable, digamos, $F$, y el vector de datos numéricos otra variable, digamos, $X$. Entonces, para cada nivel $L$ de $F$, obtendremos un diagrama de caja de los valores que toma la variable $X$ en los individuos de nivel $L$. 

La sintaxis básica de la instrucción para dibujar en un único gráfico los diagramas de caja de una variable numérica de un *data frame* segmentada por un factor del *data frame* es
\indRp{boxplot}{data}

`boxplot(``variable numérica` `\~{`}`variable factor` `, data=``data frame` `)`.

A modo de ejemplo, para dibujar en un único gráfico un diagrama de caja de la variable <<Sepal.Length>> 
del *data frame* `iris` para cada uno de los niveles del factor <<Species>>, podemos entrar
```
> boxplot(Sepal.Length~Species, data=iris, ylab="Longitudes de 
  sépalos (cm)", main="Tabla Iris")
```
y obtenemos  la Figura \@ref(fig:18.7), donde podemos observar diferencias sustanciales entre las longitudes de los sépalos de las tres especies, y además un valor inusualmente pequeño en el conjunto de valores de las flores virgínica.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{boxplotiris3.pdf}
\end{center}
\caption{Diagramas de caja de las longitudes de sépalos de las flores iris agrupadas por especies.}\label{fig:18.7}
\end{figure}


Aparte de los parámetros de la función `plot` que tengan sentido, 
la función `boxplot` dispone de algunos  parámetros específicos. Destacamos el parámetro `notch` que, igualado a `TRUE`, añade una muesca en la mediana de cada caja. Estas muescas se calculan de tal manera que si las de dos diagramas de caja no se solapan, se puede tomar como evidencia significativa de que las medianas de las poblaciones correspondientes son diferentes;
por ejemplo, 
```
> boxplot(Sepal.Length~Species, data=iris, main="Tabla Iris",  
  notch=TRUE, ylab="Longitudes de sépalos (cm)", 
  col=c("red","blue","green"))
```
produce el gráfico de la Figura \@ref(fig:bpnotch) donde, colores aparte, vemos que las muescas no se solapan, lo que nos permite afirmar con un alto grado de confianza que las medianas de las longitudes de los sépalos de las tres especies de flores iris son diferentes (en general, y no sólo para la muestra concreta recogida en el \df). Este tipo de conclusiones son las que persigue la estadística inferencial.^[  Pero cuidado, que podamos afirmar algo sobre el total de la población con un alto grado de confianza no significa que sea verdad.] 
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{irisnotch.pdf}
\end{center}
\caption{Diagramas de caja con muescas de las longitudes de sépalos de las flores iris agrupadas por especies.}\label{fig:bpnotch} 
\end{figure}

A veces es útil superponer a un diagrama de caja una marca en el valor correspondiente a la media aritmética. Para ello se puede usar la función `points`. Entrad las instrucciones siguientes:
```
> boxplot(Sepal.Length~Species, data=iris, col="lightgray")
> medias=aggregate(Sepal.Length~Species, data=iris, FUN=mean)
> points(medias, col="red", pch=18)
```
La primera instrucción produce el diagrama de caja de las longitudes de los sépalos de las flores iris agrupadas según la especie, de color gris claro; la segunda, calcula las medias de dichas longitudes para cada especie; finalmente, la tercera, añade al diagrama de caja de cada especie un diamante rojo en la ordenada correspondiente al valor de su media. El resultado es la Figura \@ref(fig:bp-diam).
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{irisdiam.pdf}
\end{center}
\caption{Diagramas de caja de las longitudes de sépalos de las flores iris agrupadas por especies con las medias marcadas.\label{fig:bp-diam}} 
\end{figure}




El resultado de una instrucción `boxplot` tiene una estructura interna que podemos aprovechar. Observemos, por ejemplo, el resultado siguiente:\medskip

```
> str(boxplot(Sepal.Length~Species, data=iris))
List of 6
 $ stats: num [1:5, 1:3] 4.3 4.8 5 5.2 5.8 4.9 5.6 5.9 6.3 7 ...
 $ n    : num [1:3] 50 50 50
 $ conf : num [1:2, 1:3] 4.91 5.09 5.74 6.06 6.34 ...
 $ out  : num 4.9
 $ group: num 3
 $ names: chr [1:3] "setosa" "versicolor" "virginica"
```
Esto muestra que un `boxplot`, como objeto de `R`, es en realidad una `list`. Los significados de sus componentes se pueden consultar en la Ayuda de la función. Aquí queremos destacar las siguientes:

* `stats`  nos da, para cada diagrama de caja en el gráfico, las ordenadas de sus cinco líneas horizontales: 
$b_{inf}, Q_{0.25}, Q_{0.5}, Q_{0.75}, b_{sup}$.

\vspace*{-2ex}

```
> #Añadimos el parámetro plot=FALSE para que no dibuje el boxplot
> boxplot(Sepal.Length~Species, data=iris, plot=FALSE)$stats
     [, 1] [, 2] [, 3]
[1, ]  4.3  4.9  5.6
[2, ]  4.8  5.6  6.2
[3, ]  5.0  5.9  6.5
[4, ]  5.2  6.3  6.9
[5, ]  5.8  7.0  7.9
```
\vspace*{-2ex}


* `out` nos da los valores atípicos. Si hay más de un diagrama de caja, 
la componente `group` nos indica los diagramas a los que pertenecen estos  valores atípicos. 

\vspace*{-2ex}

```
> boxplot(Sepal.Length~Species, data=iris, plot=FALSE)$out
[1] 4.9
> boxplot(Sepal.Length~Species, data=iris, plot=FALSE)$group
[1] 3
```

\begin{ejemplo}
Recordemos del Ejemplo \@ref(ex:sprayord) el *data frame* `InsectSprays` que viene predefinido en `R`. Este *data frame* tiene una variable factor `spray` con 6 niveles que corresponden a tipos de insecticidas,  y una variable numérica `count` que contiene números de insectos recolectados en campos tratados con los insecticidas. En aquel ejemplo convertimos la variable `count` en una variable ordinal, pero está claro que se trata de una variable cuantitativa; por lo tanto, podemos usar las técnicas explicadas en esta lección para comparar de manera más significativa la efectividad de los insecticidas a partir de los datos brutos de esta variable.

En primer lugar, obtenemos un resumen estadístico de los números de insectos recogidos en los campos tratados con cada tipo de insecticida.
```
> by(InsectSprays$count, InsectSprays$spray, FUN=summary)
InsectSprays$spray: A
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   7.00   11.50   14.00   14.50   17.75   23.00 
--------------------------------------------------- 
InsectSprays$spray: B
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   7.00   12.50   16.50   15.33   17.50   21.00 
--------------------------------------------------- 
InsectSprays$spray: C
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.000   1.000   1.500   2.083   3.000   7.000 
--------------------------------------------------- 
InsectSprays$spray: D
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  2.000   3.750   5.000   4.917   5.000  12.000 
--------------------------------------------------- 
InsectSprays$spray: E
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.00    2.75    3.00    3.50    5.00    6.00 
--------------------------------------------------- 
InsectSprays$spray: F
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   9.00   12.50   15.00   16.67   22.50   26.00 
```
Echando un vistazo a las columnas de las medianas y medias vemos que los insecticidas C, D y E son, en término medio, más efectivos que A, B y F. Como una imagen vale más que mil palabras, a continuación dibujamos en un gráfico los diagramas de caja  de los valores de `count` separados por los niveles de `spray`.
\medskip

```
> boxplot(count~spray, data=InsectSprays, ylab="Número de 
  insectos", xlab="Tipo de insecticida", col="pink")
```
Obtenemos  la Figura  \@ref(fig:18.8), que muestra a simple vista  la misma diferencia en la efectividad de los insecticidas. También se ve en este gráfico que los números de insectos obtenidos en los campos tratados con los insecticidas C, D y E presentan una menor variabilidad que el resto, puesto que sus cajas intercuartílicas son mucho más cortas; lo podemos confirmar calculando las correspondientes desviaciones típicas muestrales.
```
> aggregate(count~spray, data=InsectSprays, FUN=sd)
  spray    count
1     A 4.719399
2     B 4.271115
3     C 1.975225
4     D 2.503028
5     E 1.732051
6     F 6.213378
```


\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{bpspray.pdf}
\end{center}
\caption{Diagramas de caja de los números de insectos en campos tratados con diferentes insecticidas.}\label{fig:18.8}
\end{figure}

\end{ejemplo}





## Guía rápida de funciones



* `table` calcula la tabla de frecuencias absolutas de un vector.

* `prop.table` calcula la tabla de frecuencias relativas de un vector  a partir de su tabla de frecuencias absolutas. 

* `cumsum` calcula las sumas acumuladas de un vector.

* `as.vector` transforma un objeto en un vector.

* `mean` calcula la media de un vector numérico.

* `median` calcula la mediana de un vector numérico.

* `as.numeric(names(which(table(`$x$`)==max(table(`$x$`)))))` calcula la moda del vector $x$.

* `quantile(`$x$`, `$p$`)` calcula el cuantil de orden $p$ del vector numérico $x$. El parámetro `type` permite especificar el método.

* `range` produce un vector con  el  mínimo y  el máximo  de un vector numérico.

* `IQR` calcula  el rango intercuartílico  de un vector numérico. El parámetro `type` permite especificar el método de cálculo de los cuantiles.



*  `var` calcula la varianza muestral  de un vector numérico.

*  `sd` calcula la desviación típica muestral  de un vector numérico.

*  `summary`, aplicado a un vector numérico, calcula sus extremos, sus cuartiles y su media; aplicado a un *data frame*, calcula resúmenes similares para todas sus variables.

* `by(`\df`, ``factor` `, FUN=``función` `)` aplica la `función`  a las variables del *data frame* segmentadas según el `factor` .

* `boxplot` dibuja los diagramas de caja de los vectores numéricos a los que se aplica. 
Algunos parámetros importantes:

* Los de `plot` que tengan sentido.

* `horizontal`: igualado a `TRUE`, dibuja las cajas horizontales.

* `names`: sirve para especificar los nombres bajo los diagramas de caja en un gráfico que contenga varios.

* `notch`: dibuja cinturas alrededor de las medianas que permiten contrastar si las medianas poblacionales son diferentes.

* `plot`: igualado a `FALSE` calcula el diagrama de caja, pero no lo dibuja.

Como objeto de datos, el resultado de esta función es una `list` entre cuyas componentes destacamos:

* `stats`: contiene, para cada diagrama de caja en el gráfico, las ordenadas de sus cinco líneas horizontales: 
$b_{inf}, Q_{0.25}, Q_{0.5}, Q_{0.75}, b_{sup}$.

* `out`: contiene los valores atípicos. 

* `group`: indica los diagramas a los que pertenecen los valores atípicos. 






## Ejercicio

 Considerad de nuevo la tabla  del ejercicio de la lección anterior, que se encuentra en  [http://aprender.uib.es/Rdir/Notas2011A.txt](http://aprender.uib.es/Rdir/Notas2011A.txt) . 
Definid un *data frame* con esta tabla, y comprobad con `str` y `head` que el *data frame* obtenido tiene la estructura deseada.



* Calculad la media, la mediana y la desviación típica (redondeadas a 2 cifras decimales) de las notas numéricas del examen, tanto globalmente como por grupos. ¿En qué grupo hay más variación de notas? ¿Qué grupo tiene la nota media más alta? ¿Hay mucha diferencia en estos dos valores entre los grupos?

* Dibujad en un único gráfico los diagramas de caja de las notas numéricas del examen de cada grupo; añadid marcas en las notas medias; poned nombres, título, etc., para que resulte más informativo. ¿Tiene algún grupo algún valor atípico? ¿Podéis decir a partir de este gráfico en qué grupo hay más variación de notas? 

* Agrupad los estudiantes de los dos grupos de Biología, BLM y BLT, en uno solo, BL, y repetid los dos puntos anteriores para los grados BL y BQ.

* ¿Podéis extraer alguna conclusión sobre si  el examen ha ido mejor en algún grupo  que en los demás, o mejor en un grado que en el otro? 


# Descripción de datos cuantitativos multidimensionales {#chap:multi}

 En general, los datos que se recogen en  experimentos son multidimensionales: medimos varias variables aleatorias sobre una misma muestra de individuos, y organizamos esta información en tablas de datos en las que las filas representan los individuos observados y cada columna corresponde a una variable diferente. En lecciones anteriores ya han aparecido datos cualitativos y ordinales multidimensionales, 
para los que hemos calculado 
y representado gráficamente sus frecuencias globales y marginales; en esta lección estudiamos algunos estadísticos específicos para resumir y representar la relación existente entre diversas variables cuantitativas.



## Matrices de datos cuantitativos

  Supongamos  que hemos medido $p$ características de $n$ individuos u objetos; como resultado, hemos obtenido $p$ variables cuantitativas, cada una formada por $n$ observaciones. Estas variables están emparejadas, en el sentido de que la primera entrada de cada variable corresponde a un mismo individuo, la segunda entrada a otro individuo, y así sucesivamente. Para trabajar con estas observaciones, las disponemos en una tabla de datos donde cada fila corresponde a un individuo y cada columna, a una variable. En `R`, definiremos esta tabla en forma de *data frame*, pero, por conveniencia de lenguaje, en el texto de esta lección la representaremos como una matriz
$$
{X}=\begin{pmatrix}
x_{1 1} & x_{1 2} &\ldots & x_{1 p}\\
x_{2 1} & x_{2 2} &\ldots & x_{2 p}\\
\vdots & \vdots   &   \ddots    &\vdots\\ 
x_{n 1} & x_{n 2} &\ldots & x_{n p}
\end{pmatrix}.
$$
Utilizaremos las  notaciones siguientes:

* Denotaremos la $i$-ésima fila de $X$ por 
$$
{{x}_{i\bullet}}=(x_{i 1}, x_{i 2}, \ldots, x_{i p}).
$$
Este vector está compuesto por las observaciones de las $p$ variables sobre el $i$-ésimo individuo.
 
 * Denotaremos la  $j$-ésima columna de $X$ por
 $$
x_{\bullet j}=\begin{pmatrix}x_{1 j} \\ x_{2 j}\\ \vdots \\ x_{n j}
\end{pmatrix}.
$$
Esta columna está formada por todos los valores de la $j$-ésima variable.

Observad que, en cada caso, el punto en el subíndice representa el índice <<variable>> de los elementos del vector o de la columna.

De esta manera, podremos expresar la matriz de datos ${X}$ tanto por filas como por columnas:
$$
{X}=\begin{pmatrix}{x}_{1\bullet}\\x_{2\bullet}\\\vdots \\
{x}_{n\bullet}\end{pmatrix}=({x}_{\bullet1}, {x}_{\bullet 2}, \ldots, {x}_{\bullet p}).
$$

Con estas notaciones, podemos generalizar al caso multidimensional los estadísticos de una variable cuantitativa, 
definiéndolos como los vectores  que se obtienen aplicando el estadístico concreto a cada columna de la tabla de datos.  Así:

* El `vector de medias`  de ${X}$ es el vector formado por las medias aritméticas de sus columnas:
$$
\overline{{X}}=(\overline{{{x}}}_{\bullet1}, \overline{{x}}_{\bullet 2}, \ldots, \overline{{x}}_{\bullet p}), 
$$
donde, para cada $j=1, \ldots, p$, 
$$
\overline{{x}}_{\bullet j}=\frac{1}{n}\sum\limits_{i=1}^n x_{i j}.
$$


* El `vector de varianzas`   de ${X}$ es el vector  formado por  las varianzas  de sus columnas:
$$
s^2_{{X}}=(s^2_{1}, s^2_2, \ldots, s^2_p), 
$$
donde 
$$
s_j^2=\frac{1}{n}\sum_{i=1}^n {(x_{ij}-\overline{{x}}_{\bullet j})^2}.
$$

* El `vector de varianzas muestrales`   de ${X}$ está formado por  las varianzas muestrales  de sus columnas:
$$
\widetilde{s}^2_{{X}}=(\widetilde{s}^2_{1}, 
\widetilde{s}^2_2, \ldots, \widetilde{s}^2_p), 
$$
donde 
$$
\widetilde{s}_j^2=\frac{1}{n-1}\sum_{i=1}^n {(x_{ij}-\overline{{x}}_{\bullet j})^2}=\frac{n}{n-1}s_j^2.
$$


* Los `vectores de desviaciones típicas`  $s_{{X}}$ y `de desviaciones típicas muestrales`  $\widetilde{s}_{{X}}$ de $X$ son los  formados por las desviaciones típicas y las desviaciones típicas muestrales de sus columnas, respectivamente:
$$
\begin{array}{l}
s_{{X}}=(s_{1}, s_2, \ldots, s_p)=(\sqrt{{s}^2_{1}}, 
\sqrt{{s}^2_2}, \ldots, \sqrt{{s}^2_p})\\[1ex]
\widetilde{s}_{{X}}=(\widetilde{s}_{1}, 
\widetilde{s}_2, \ldots, \widetilde{s}_p)=(\sqrt{\widetilde{s}^2_{1}}, 
\sqrt{\widetilde{s}^2_2}, \ldots, \sqrt{\widetilde{s}^2_p})
\end{array}
$$


Estos vectores de estadísticos se pueden calcular con `R` aplicando la función correspondiente al estadístico a todas las columnas de la tabla de datos. La manera más sencilla de hacerlo en un solo paso es usando la función `sapply`, si  tenemos guardada la tabla como un *data frame*, o  `apply` con `MARGIN=2`, si la tenemos guardada en forma de matriz.



\begin{ejemplo}\label{mult:ex0}
Consideremos la tabla de datos
$$
{X}=\begin{pmatrix}
1&-1&3\\
1&0&3\\
2&3&0\\
3&0&1
\end{pmatrix}
$$
formada por 4 observaciones de 3 variables; por lo tanto, $n=4$ y $p=3$. Vamos a guardarla en un *data frame* y a calcular sus estadísticos. 
```
> X=data.frame(V1=c(1,1,2,3),V2=c(-1,0,3,0),V3=c(3,3,0,1))
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> sapply(X, mean) #Vector de medias
  V1   V2   V3 
1.75 0.50 1.75 
> sapply(X, var) #Vector de varianzas muestrales
       V1        V2        V3 
0.9166667 3.0000000 2.2500000 
> sapply(X, sd) #Vector de desviaciones típicas muestrales
       V1        V2        V3 
0.9574271 1.7320508 1.5000000 
> var_ver=function(x){var(x)*(length(x)-1)/length(x)}   #Varianza  "verdadera"
> sd_ver=function(x){sqrt(var_ver(x))} #Desv. típica "verdadera"
> sapply(X, var_ver) #Vector de varianzas "verdaderas"
    V1     V2     V3 
0.6875 2.2500 1.6875 
> sapply(X, sd_ver) #Vector de desviaciones típicas "verdaderas"
       V1        V2        V3 
0.8291562 1.5000000 1.2990381 
```
\end{ejemplo}

A veces es conveniente aplicar una transformación lineal a una tabla de datos ${X}$, sumando a cada columna un valor y luego multiplicando cada columna resultante por otro valor. El ejemplo más común de    trasformación lineal es la `tipificación de datos` .

Dada una variable cuantitativa,^[  De ahora en adelante, supondremos que todas las variables cuantitativas que aparezcan en lo que queda de lección, incluidas las columnas de tablas de datos, son no constantes y, por lo tanto, tienen desviación típica no nula. ] 
su `variable tipificada`   es el vector que se obtiene restando a cada entrada la media aritmética de la variable y dividiendo  el resultado por su desviación típica; de esta manera, la variable tipificada tiene media aritmética $0$
y varianza~$1$. Tipificar una variable es conveniente cuando se quiere trabajar con sus datos sin que influyan las unidades en los que están medidos: al dividir por su desviación típica, los valores resultantes son  adimensionales.

Tipificar las variables de una tabla de datos permite compararlas dejando de lado las diferencias que pueda haber entre sus valores medios o sus varianzas. Llamaremos `matriz tipificada`   de una matriz de datos ${X}$ a la matriz ${Z}$ que se obtiene tipificando cada columna; es decir, para tipificar una matriz de datos ${X}$, primero restamos a cada columna su media aritmética (llamaremos `matriz centrada`  de ${X}$ 
 a la matriz obtenida en este paso), y, a continuación, dividimos cada columna de la matriz centrada por su 
desviación típica, que coincide con la desviación típica de la columna original de ${X}$:
$$
{Z}=\begin{pmatrix}
\frac{x_{1 1}- \overline{{x}}_{\bullet 1}}{s_1}& \frac{x_{1 2}- \overline{{x}}_{\bullet 2}}{s_2} &\ldots & \frac{x_{1 p}- \overline{{x}}_{\bullet p}}{s_p}\\[2ex]
\frac{x_{2 1} - \overline{{x}}_{\bullet 1}}{s_1}& \frac{x_{2 2}- \overline{{x}}_{\bullet 2}}{s_2} &\ldots & \frac{x_{2 p}- \overline{{x}}_{\bullet p}}{s_p}\\[2ex]
\vdots & \vdots   & \ddots      &\vdots\\ 
\frac{x_{n 1} - \overline{{x}}_{\bullet 1}}{s_1}& \frac{x_{n 2}- \overline{{x}}_{\bullet 2}}{s_2} &\ldots & \frac{x_{n p}-
\overline{{x}}_{\bullet p}}{s_p}
\end{pmatrix}.
$$

La manera más sencilla de aplicar una transformación lineal a una tabla de datos ${X}$, y en particular de tipificarla, es usando la instrucción 

`scale(X, center=\ldots, scale=\ldots)`

donde:

* `X`  puede ser tanto  una matriz como un \df; el resultado será un objeto de la misma clase.


*  El valor del parámetro `center` es el vector que restamos a sus columnas, en el sentido de que cada entrada de este vector se restará a todas las entradas de la columna correspondiente.  Su valor por defecto (que no es necesario especificar, aunque también se puede especificar 
con `center=TRUE`) es el vector $\overline{X}$ de medias de $X$; para especificar que no se reste nada, podemos usar
`center=FALSE`. 

* El valor del parámetro `scale` es el vector por el que dividimos las columnas  de la matriz obtenida tras restar el valor de `center`:
cada columna se divide por la entrada correspondiente de este vector.
Su valor por defecto (de nuevo, se puede especificar igualando el parámetro a `TRUE`) es el vector  $\widetilde{s}_X$ de  desviaciones típicas `muestrales` ;
para especificar que no se divida por nada, podemos usar
`scale=FALSE`. 

En particular, la instrucción 
`scale(X)`
centra la tabla de datos $X$ y divide sus columnas por sus `desviaciones típicas muestrales` ; por lo tanto, no la tipifica según nuestra definición, ya que no las divide por sus desviaciones típicas <<verdaderas>>. 

\begin{ejemplo}\label{mult:ex1}
Vamos a centrar la tabla de datos $X$ del Ejemplo \@ref(mult:ex0).
```
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> X_centrada=scale(X, center=TRUE, scale=FALSE)
> X_centrada
        V1   V2    V3
[1, ] -0.75 -1.5  1.25
[2, ] -0.75 -0.5  1.25
[3, ]  0.25  2.5 -1.75
[4, ]  1.25 -0.5 -0.75
attr(, "scaled:center")
  V1   V2   V3 
1.75 0.50 1.75 
```
Observad la estructura del resultado: en primer lugar nos da la matriz centrada, y a continuación nos dice que tiene un atributo llamado `"scaled:center"` cuyo valor es el vector usado para centrarla. Este atributo no interferirá para nada en las operaciones que se realicen con la matriz centrada, pero, si os molesta, recordad de la Lección \@ref(chap:vect) que se puede eliminar sustituyendo el resultado de centrar la matriz en los puntos suspensivos de la instrucción siguiente:

`attr(\ldots , "scaled:center")=NULL`.

```
> attr(X_centrada, "scaled:center")=NULL
> X_centrada
        V1   V2    V3
[1, ] -0.75 -1.5  1.25
[2, ] -0.75 -0.5  1.25
[3, ]  0.25  2.5 -1.75
[4, ]  1.25 -0.5 -0.75
```

Como ya hemos avisado, para tipificar esta tabla de datos  `no`  podemos hacer lo siguiente: 
```
> X_tip=scale(X)
> X_tip
             V1         V2         V3
[1, ] -0.7833495 -0.8660254  0.8333333
[2, ] -0.7833495 -0.2886751  0.8333333
[3, ]  0.2611165  1.4433757 -1.1666667
[4, ]  1.3055824 -0.2886751 -0.5000000
attr(, "scaled:center")
  V1   V2   V3 
1.75 0.50 1.75 
attr(, "scaled:scale")
       V1        V2        V3 
0.9574271 1.7320508 1.5000000 
```

Para hacerlo bien en base a la definición que hemos dado, tenemos dos opciones. Una posibilidad es  multiplicar la matriz anterior por $\sqrt{n/(n-1)}$, donde $n$ es el número de filas de la tabla.^[  Como
$\widetilde{s] _X=\sqrt{\frac{n}{n-1}}\cdot s_X$, se tiene que
$\frac{1}{s_X}=\sqrt{\frac{n}{n-1}}\cdot \frac{1}{\widetilde{s}_X}$; por lo tanto, si queríamos dividir por $s_X$
y `scale(X)` ha dividido por $\widetilde{s}_X$, basta multiplicar su resultado por $\sqrt{\frac{n}{n-1}}$.}
```
> n=dim(X)[1]  #Número de filas de X
> n
[1] 4
> X_tip=scale(X)*sqrt(n/(n-1)) 
> X_tip
             V1         V2         V3
[1, ] -0.9045340 -1.0000000  0.9622504
[2, ] -0.9045340 -0.3333333  0.9622504
[3, ]  0.3015113  1.6666667 -1.3471506
[4, ]  1.5075567 -0.3333333 -0.5773503
attr(, "scaled:center")
  V1   V2   V3 
1.75 0.50 1.75 
attr(, "scaled:scale")
       V1        V2        V3 
0.9574271 1.7320508 1.5000000 
```

Otra posibilidad es usar, como valor del parámetro `scale`, el vector  $s_X$ de desviaciones típicas de las columnas.
```
> sd_ver=function(x){sqrt(var(x)*(length(x)-1)/length(x))} 
> X_dtv=sapply(X, sd_ver) #Desviaciones típicas "verdaderas"
> X_tip1=scale(X, scale=X_dtv) #Escalamos dividiendo las columnas por X_dtv
> X_tip1
             V1         V2         V3
[1, ] -0.9045340 -1.0000000  0.9622504
[2, ] -0.9045340 -0.3333333  0.9622504
[3, ]  0.3015113  1.6666667 -1.3471506
[4, ]  1.5075567 -0.3333333 -0.5773503
attr(, "scaled:center")
  V1   V2   V3 
1.75 0.50 1.75 
attr(, "scaled:scale")
       V1        V2        V3 
0.8291562 1.5000000 1.2990381 
```

Observaréis que la matriz resultante es la misma, pero el atributo que indica el vector por el que hemos dividido las columnas es diferente: ahora ha sido el de desviaciones típicas.
En ambos casos, podemos usar la función `attr` para eliminar uno a uno los dos atributos, `"{`scaled:center"} y `{`"scaled:scale"}, que se han añadido a la matriz tipificada.
```
> attr(X_tip, "scaled:center")=NULL
> attr(X_tip, "scaled:scale")=NULL
> X_tip
             V1         V2         V3
[1, ] -0.9045340 -1.0000000  0.9622504
[2, ] -0.9045340 -0.3333333  0.9622504
[3, ]  0.3015113  1.6666667 -1.3471506
[4, ]  1.5075567 -0.3333333 -0.5773503
```
\end{ejemplo}



## Covarianzas y correlaciones

 La `covarianza`  entre dos variables es una medida de la propensión que tienen ambas variables a variar conjuntamente. Cuando la covarianza es positiva, si una de las dos variables crece o decrece, la otra tiene el mismo comportamiento; en cambio, cuando la covarianza es negativa, esta tendencia se invierte: si una variable crece, la otra decrece y viceversa. Por desgracia, interpretar el valor de la covarianza más allá de su signo es difícil, por lo que introduciremos una versión <<normalizada>> de la misma, la `correlación de Pearson` , que mide de manera más precisa la relación lineal entre dos variables. 

La covarianza generaliza la varianza, en el sentido de que la varianza  de una variable es su covarianza consigo misma. Y como en el caso de la varianza, definiremos dos versiones de la covarianza: la <<`verdadera` >>, que se usa para medir la tendencia a la variación conjunta de dos conjuntos específicos de datos, y la `muestral` , que además aproxima mejor la covarianza de las variables definidas sobre la población total.
La diferencia estará de nuevo en el denominador.


Formalmente, la `covarianza`  de las variables ${x}_{\bullet i}$ y
${x}_{\bullet j}$ de una matriz de datos ${X}$ es
$$
s_{i j}=\frac{1}{n} \sum_{k =1}^n\big((x_{k i}-\overline{{x}}_{\bullet i})(x_{kj}-\overline{{x}}_{\bullet j})\big)= 
\frac{1}{n} \Big(\sum_{k =1}^n x_{k i} x_{k j}\Big) - \overline{{x}}_{\bullet i} \overline{{x}}_{\bullet j},
$$
y  su `covarianza muestral`   es
$$
\widetilde{s}_{ij} =
\frac{1}{n-1} \sum_{k =1}^n\big((x_{k i}-\overline{{x}}_{\bullet i})(x_{kj}-\overline{{x}}_{\bullet j})\big)= 
\frac{n}{n-1} s_{ij}.
$$


Es inmediato comprobar a partir de sus definiciones que ambas covarianzas son simétricas, y que la covarianza, tanto <<verdadera>> como muestral, de una variable consigo misma es su correspondiente varianza:
$$ 
s_{i j}= s_{j i}, \quad \widetilde{s}_{i j}= \widetilde{s}_{j i}, \quad
s_{i i}=s_{i}^2, \quad \widetilde{s}_{ii}=\widetilde{s}_i^2.
$$

\begin{ejemplo}\label{mult:ex-cov-vect1}
La covarianza de las dos primeras columnas de la matriz de datos
$$
{X}=\begin{pmatrix}
1&-1&3\\
1&0&3\\
2&3&0\\
3&0&1
\end{pmatrix}.
$$
del Ejemplo \@ref(mult:ex0) se calcularía de la manera siguiente, teniendo en cuenta que sus medias son $1.75$ y $0.5$, respectivamente:
$$
s_{12}=\frac{1}{4}(1\cdot (-1)+1\cdot 0+2\cdot 3+3\cdot 0)-1.75\cdot 0.5=1.25-0.875=0.375.
$$
Su covarianza muestral se obtendría multiplicando  este valor por $4/3$:
$$
\widetilde{s}_{12} = \frac{4}{3} s_{12}=0.5.
$$
\end{ejemplo}

La covarianza `muestral`  de dos vectores numéricos de la misma longitud $n$ se puede calcular con `R` mediante la función `cov`.
Para obtener su covarianza <<verdadera>>, hay que multiplicar el resultado de `cov` por $(n-1)/n$.
```
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> cov(X$V1, X$V2)   #Covarianza MUESTRAL
[1] 0.5
> (3/4)*cov(X$V1, X$V2)  #Covarianza "verdadera"
[1] 0.375
```
Queremos recalcar que, como en el caso de la varianza con `var`, `R` calcula con `cov` la versión muestral de la covarianza. 



Las `matrices de covarianzas`   y de  `covarianzas muestrales`   de una tabla de datos ${X}$ son, respectivamente, 
$$
\mathbf{S}=
\begin{pmatrix}  
 s_{1 1} & s_{1 2} & \ldots & s_{1 p}\\
 s_{2 1} & s_{2 2} & \ldots & s_{2 p}\\
  \vdots & \vdots  &   \ddots     & \vdots\\
 s_{p 1} & s_{p 2} & \ldots & s_{p p}
\end{pmatrix}, 
\qquad
\widetilde{\mathbf{S}}=
\begin{pmatrix}  
 \widetilde{s}_{1 1} & \widetilde{s}_{1 2} & \ldots & \widetilde{s}_{1 p}\\
 \widetilde{s}_{2 1} & \widetilde{s}_{2 2} & \ldots & \widetilde{s}_{2 p}\\
  \vdots & \vdots  &  \ddots      & \vdots\\
\widetilde{s}_{p 1} & \widetilde{s}_{p 2} & \ldots & \widetilde{s}_{p p}
\end{pmatrix},
$$
donde cada $s_{i j}$ y cada $\widetilde{s}_{i j}$ son, respectivamente, la covarianza  y la covarianza muestral  de las correspondientes columnas ${x}_{\bullet i}$ y ${x}_{\bullet j}$.
Estas matrices de covarianzas  miden la tendencia a la variabilidad conjunta de
los datos de ${X}$.

La matriz de covarianzas muestrales de $X$ se calcula aplicando la función `cov` al *data frame* o a la matriz que contenga dicha tabla.  Para obtener su matriz de covarianzas <<verdaderas>>, es suficiente multiplicar el resultado de  `cov` por $(n-1)/n$, donde $n$ es el número de filas de $X$.
```
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> n=dim(X)[1]
> cov(X)  #Matriz de covarianzas muestrales
            V1        V2        V3
V1  0.9166667  0.500000 -1.083333
V2  0.5000000  3.000000 -2.166667
V3 -1.0833333 -2.166667  2.250000
> ((n-1)/n)*cov(X)  #Matriz de covarianzas "verdaderas"
        V1     V2      V3
V1  0.6875  0.375 -0.8125
V2  0.3750  2.250 -1.6250
V3 -0.8125 -1.625  1.6875
```


La `correlación lineal de Pearson`  (o, de ahora en adelante, simplemente `correlación` ) de las variables 
${x}_{\bullet i}$ y ${x}_{\bullet j}$ de ${X}$
es 
$$
r_{i j}=\frac{s_{i j}}{s_i s_j}.
$$
Observad que 
$$
\frac{\widetilde{s}_{i j}}{\widetilde{s}_i\cdot \widetilde{s}_j}=
\frac{\frac{n}{n-1}\cdot {s}_{i j}}{\sqrt{\frac{n}{n-1}}\cdot {s}_i \cdot\sqrt{\frac{n}{n-1}}\cdot{s}_j}=
\frac{s_{i j}}{s_i \cdot s_j}=r_{i j},
$$
por lo que esta correlación se puede calcular también a partir de las versiones muestrales de la covarianza y las desviaciones típicas  por medio de la misma fórmula.

La correlación $r_{i j}$ tiene las propiedades siguientes:



* Es símétrica: $r_{i j}=r_{j i}$.

* $-1\leq r_{i j}\leq 1$.

* $r_{i i}=1$.

* $r_{i j}$ tiene el mismo signo que $s_{i j}$.

* $r_{i j}=\pm 1$ si y, sólo si, existe una relación lineal perfecta entre las
variables ${x}_{\bullet i}$ y ${x}_{\bullet j}$: es decir, si, y sólo si, existen valores $a, b\in \mathbb{R}$ tales que 
$$
\left(\begin{array}{c}
x_{1j}\\  \vdots \\ x_{nj}\end{array}\right)=
a\cdot \left(\begin{array}{c}
x_{1i}\\ \vdots \\ x_{ni}\end{array}\right) +b.
$$
La pendiente $a$ de esta relación lineal tiene el mismo signo
que $r_{i j}$.

* El coeficiente de determinación $R^2$ de la regresión lineal por mínimos cuadrados de  ${x}_{\bullet j}$ respecto de ${x}_{\bullet i}$ (véase la Lección \@ref(chap:lm))
es igual al cuadrado de su correlación, $r_{i j}^2$; por lo tanto, cuánto más se aproxime el valor absoluto de $r_{ij}$  a $1$,
más se acercan las
variables ${x}_{\bullet i}$ y ${x}_{\bullet j}$ a depender linealmente la una de la otra.

Así pues, la correlación entre dos variables viene a ser una covarianza <<normalizada>>, ya que, como vemos, su valor está entre $-1$ y $1$, y  mide la tendencia de las variables a estar relacionadas según una función lineal. En concreto, cuanto más se acerca la correlación a 1 (respectivamente, a $-1$), más se acerca una (cualquiera) de las variables a ser función lineal creciente (respectivamente, decreciente) de la otra.  


Con `R`, la correlación de Pearson de dos vectores se puede calcular por medio de la función `cor`.


\begin{ejemplo}
En ejemplos anteriores hemos calculado la covarianza y las varianzas de las dos primeras columnas de la matriz de datos
$$
{X}=\begin{pmatrix}
1&-1&3\\
1&0&3\\
2&3&0\\
3&0&1
\end{pmatrix}.
$$
Hemos obtenido los valores siguientes:
$$
s_{12}=0.375, \quad s_1=\frac{\sqrt{11}}{4}=0.82916, \quad s_2= \frac{3}{2}=1.5.
$$
Por lo tanto, su correlación es
$$
r_{1 2}=\frac{0.375}{0.82916\cdot 1.5}=0.3015.
$$
Ahora vamos a calcularla con `R`, y aprovecharemos para confirmar su relación con el valor de $R^2$ de la regresión lineal de la segunda columna respecto de la primera.
```
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> cor(X$V1, X$V2)
[1] 0.3015113
> cor(X$V1, X$V2)^2
[1] 0.09090909
> summary(lm(X$V2~X$V1))$r.squared
[1] 0.09090909
```
\end{ejemplo}

La `matriz de correlaciones`  de ${X}$ es 
$$
\mathbb{R}=
\begin{pmatrix}
1 & r_{1 2} & \ldots & r_{1 p}\\
r_{2 1} & 1 & \ldots & r_{2 p}\\
\vdots & \vdots & \ddots & \vdots\\
r_{p 1} & r_{p 2} & \ldots & 1
\end{pmatrix},
$$
donde cada $r_{i j}$ es la correlación de las  columnas correspondientes de  ${X}$.
Esta matriz de correlaciones  se puede calcular con `R` con la misma instrucción `cor`, que se puede aplicar tanto a una matriz como a un *data frame*
```
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> cor(X)
           V1         V2         V3
V1  1.0000000  0.3015113 -0.7543365
V2  0.3015113  1.0000000 -0.8339504
V3 -0.7543365 -0.8339504  1.0000000
```

`R` también dispone de la función `cov2cor` que, aplicada a la matriz de covarianzas (muestrales o <<verdaderas>>), calcula la matriz de correlaciones de los datos originales.
```
> S=cov(X)
> cov2cor(S)
           V1         V2         V3
V1  1.0000000  0.3015113 -0.7543365
V2  0.3015113  1.0000000 -0.8339504
V3 -0.7543365 -0.8339504  1.0000000
```

Se tiene el teorema siguiente, que se puede demostrar mediante un simple, aunque farragoso, cálculo algebraico:

\begin{teorema}
La matriz de correlaciones de ${X}$ es igual a  la matriz de covarianzas de
 su matriz  tipificada.
\end{teorema}

La importancia de este resultado es que, si la tabla de datos es muy grande, suele ser más eficiente tipificar primero la tabla y luego calcular la matriz de covarianzas de la tabla tipificada que calcular directamente la matriz de correlaciones de la tabla original.
Comprobemos que el teorema es cierto para nuestra matriz de datos.
```
> X
  V1 V2 V3
1  1 -1  3
2  1  0  3
3  2  3  0
4  3  0  1
> n=dim(X)[1]
> X_tip=scale(X)*sqrt(n/(n-1)) 
> cov(X_tip)*(n-1)/n
           V1         V2         V3
V1  1.0000000  0.3015113 -0.7543365
V2  0.3015113  1.0000000 -0.8339504
V3 -0.7543365 -0.8339504  1.0000000
```

Cuando se calcula la covarianza o la correlación de dos vectores que contienen  `NA`, lo usual es no tenerlos en cuenta: es decir, si un vector contiene un `NA` en una  posición, se eliminan de ambos vectores sus entradas en dicha posición. De esta manera, se tomaría como covarianza de
$$
\left(\begin{array}{c}
1\\ 2\\ \mbox{\it NA}\\ 4\\ 6\\ 2\end{array}\right)\mbox{ y }
\left(\begin{array}{c} 2\\ 4\\ -3\\ 5\\ 7\\ \mbox{\it NA}\end{array}\right)
$$
la de
$$
\left(\begin{array}{c}1\\ 2\\ 4\\ 6\end{array}\right)\mbox{ y }
\left(\begin{array}{c} 2\\ 4\\ 5\\ 7\end{array}\right).
$$
Al aplicar `cov` o `cor` a un par de vectores que contengan `NA`, se obtiene, por defecto, `NA`. Si se quiere que `R` calcule el valor sin tener en cuenta los `NA`, se ha de especificar  añadiendo el parámetro `use="{`complete.obs"} (que le indica que ha de usar las `observaciones completas` , es decir, las posiciones que no tienen `NA` en ninguno de los dos vectores).
```
> x=c(1,2,NA,4,6,2)
> y=c(2,4,-3,5,7,NA)
> x1=c(1,2,4,6)  #Quitamos las entradas 3a y 6a 
> x2=c(2,4,5,7)  #Quitamos las entradas 3a y 6a 
> cov(x, y)
[1] NA
> cov(x, y, use="complete.obs")
[1] 4.5
> cov(x1, x2)
[1] 4.5
> cor(x, y)
[1] NA
> cor(x, y, use="complete.obs")
[1] 0.9749135
> cor(x1, x2)
[1] 0.9749135
```

Al calcular las matrices de covarianzas, covarianzas muestrales o correlaciones de una tabla de datos que contenga `NA`, se suele seguir una de las dos estrategias siguientes, según lo que interese al usuario:

* Para cada par de columnas, se calcula su covarianza o su correlación 
con la estrategia explicada más arriba para dos vectores, obviando el hecho de que forman parte de una tabla de datos mayor; es decir, al efectuar el cálculo para un par de columnas concreto, se eliminan de cada una de ellas sus entradas `NA` y aquellas en cuya fila la otra tiene un `NA`. 
Esta opción se especifica dentro de la función `cov` o `cor` con el parámetro `use="{`pairwise.complete.obs"} (observaciones completas por parejas).

* Antes de nada, se eliminan  las filas de la tabla que contienen algún `NA` en alguna columna, dejando solo en la tabla las filas <<completas>>, las que no contienen ningún `NA`. Luego se calcula la matriz de covarianzas o de correlaciones  de  la tabla resultante. Esta opción se especifica con el parámetro   `use="{`complete.obs"}. 

Veamos un ejemplo:
```
> X=cbind(c(1,2,NA,4,6,2), c(2,4,-3,5,7,NA), c(-2,1,0,2,3,0))
> X
     [, 1] [, 2] [, 3]
[1, ]    1    2   -2
[2, ]    2    4    1
[3, ]   NA   -3    0
[4, ]    4    5    2
[5, ]    6    7    3
[6, ]    2   NA    0
> cov(X)
     [, 1] [, 2]     [, 3]
[1, ]   NA   NA       NA
[2, ]   NA   NA       NA
[3, ]   NA   NA 3.066667
> cov(X, use="pairwise.complete.obs")
     [, 1]  [, 2]     [, 3]
[1, ]  4.0  4.50 3.500000
[2, ]  4.5 14.50 4.750000
[3, ]  3.5  4.75 3.066667
> cov(X, use="complete.obs")
         [, 1]     [, 2]     [, 3]
[1, ] 4.916667 4.500000 4.333333
[2, ] 4.500000 4.333333 4.333333
[3, ] 4.333333 4.333333 4.666667
> Y=cbind(c(1,2,4,6), c(2,4,5,7), c(-2,1,2,3)) #Eliminamos las filas con algún NA
> Y
     [, 1] [, 2] [, 3]
[1, ]    1    2   -2
[2, ]    2    4    1
[3, ]    4    5    2
[4, ]    6    7    3
> cov(Y)  #Dará lo mismo que con use="complete.obs"
         [, 1]     [, 2]     [, 3]
[1, ] 4.916667 4.500000 4.333333
[2, ] 4.500000 4.333333 4.333333
[3, ] 4.333333 4.333333 4.666667
```

\begin{ejemplo}\label{ex:irismult}
Recordaréis el *data frame* `iris`, que tabulaba las longitudes y anchuras de los pétalos y los sépalos de una muestra de flores iris de tres especies. Vamos a extraer un sub*data frame* con sus cuatro variables numéricas y calcularemos sus matrices de covarianzas y correlaciones.
```
 > str(iris)
'data.frame':	150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa", "versicolor", ..: 1 1 1 1 1 1 1 1 1 1 ...
> iris_num=iris[, 1:4]
> cov(iris_num)  #Covarianzas muestrales
             Sepal.Length Sepal.Width Petal.Length Petal.Width
Sepal.Length    0.6856935  -0.0424340    1.2743154   0.5162707
Sepal.Width    -0.0424340   0.1899794   -0.3296564  -0.1216394
Petal.Length    1.2743154  -0.3296564    3.1162779   1.2956094
Petal.Width     0.5162707  -0.1216394    1.2956094   0.5810063
> n=dim(iris_num)[1]    #Número de filas; son 150, recordemos
> cov(iris_num)*(n-1)/n  #Covarianzas "verdaderas"
             Sepal.Length Sepal.Width Petal.Length Petal.Width
Sepal.Length   0.68112222 -0.04215111    1.2658200   0.5128289
Sepal.Width   -0.04215111  0.18871289   -0.3274587  -0.1208284
Petal.Length   1.26582000 -0.32745867    3.0955027   1.2869720
Petal.Width    0.51282889 -0.12082844    1.2869720   0.5771329
> cor(iris_num)    #Correlaciones
             Sepal.Length Sepal.Width Petal.Length Petal.Width
Sepal.Length    1.0000000  -0.1175698    0.8717538   0.8179411
Sepal.Width    -0.1175698   1.0000000   -0.4284401  -0.3661259
Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654
Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000
```


Observamos, por ejemplo, una gran correlación lineal positiva entre la longitud y la anchura de los pétalos, $0.9628654$, lo que indica una estrecha relación lineal con pendiente positiva entre estas magnitudes. Valdría la pena, entonces, calcular la recta de regresión lineal de una de estas medidas en función de la otra:
```
> lm(Petal.Length~Petal.Width, data=iris_num)

Call:
lm(formula = Petal.Length ~ Petal.Width, data = iris_num)

Coefficients:
(Intercept)  Petal.Width  
      1.084        2.230  

> summary(lm(Petal.Length~Petal.Width, data=iris_num))$r.squared
[1] 0.9271098
```
En cambio, la correlación entre la longitud y la anchura de los sépalos es $-0.1175698$, muy cercana a cero, lo que es señal de que la variación conjunta de las longitudes y anchuras de los sépalos no tiene una tendencia clara.

Vamos a ordenar ahora los pares de variables numéricas de `iris` en orden decreciente de su correlación en valor absoluto, para saber cuáles están más correlacionadas. Para ello, 
en primer lugar creamos un *data frame* cuyas filas están formadas por pares diferentes de variables numéricas de `iris`, su correlación y el valor absoluto de ésta, y a continuación ordenamos las filas de este *data frame* en orden decreciente de estos valores absolutos.  Todo esto lo llevamos a cabo con el código siguiente, que luego explicamos:
```
> medidas=names(iris_num)
> n=length(medidas)  #En este caso, n=4
> indices=upper.tri(diag(n))
> medida1=matrix(rep(medidas, times=n), nrow=n, 
  byrow=FALSE)[indices]
> medida2=matrix(rep(medidas, times=n), nrow=n, 
  byrow=TRUE)[indices]
> corrs=as.vector(cor(iris_num))[indices]  
> corrs.abs=abs(corrs)
> corrs_df=data.frame(medida1, medida2, corrs, corrs.abs)
> corrs_df
       medida1      medida2      corrs corrs.abs
1 Sepal.Length  Sepal.Width -0.1175698 0.1175698
2 Sepal.Length Petal.Length  0.8717538 0.8717538
3  Sepal.Width Petal.Length -0.4284401 0.4284401
4 Sepal.Length  Petal.Width  0.8179411 0.8179411
5  Sepal.Width  Petal.Width -0.3661259 0.3661259
6 Petal.Length  Petal.Width  0.9628654 0.9628654
> corrs_df_sort=corrs_df[order(corrs_df$corrs.abs, 
   decreasing=TRUE), ]
> corrs_df_sort
       medida1      medida2      corrs corrs.abs
6 Petal.Length  Petal.Width  0.9628654 0.9628654
2 Sepal.Length Petal.Length  0.8717538 0.8717538
4 Sepal.Length  Petal.Width  0.8179411 0.8179411
3  Sepal.Width Petal.Length -0.4284401 0.4284401
5  Sepal.Width  Petal.Width -0.3661259 0.3661259
1 Sepal.Length  Sepal.Width -0.1175698 0.1175698
```
Vemos que el par de variables con mayor correlación en valor absoluto son `Petal.Length` y `Petal.Width`, como ya habíamos observado, seguidos por  `Petal.Length` y `Sepal.Length`.


Vamos a explicar el código. La función `upper.tri`, aplicada a una matriz cuadrada $M$, produce la matriz `triangular superior`  de valores lógicos del mismo orden que $M$, cuyas entradas $(i,j)$ con $i<j$ son todas  `TRUE`  y el resto todas  `FALSE`. Existe una función similar, `lower.tri`, para producir  matrices `triangulares inferiores`  de valores lógicos.
```
> upper.tri(diag(4))
      [,1]  [,2]  [,3]  [,4]
[1,] FALSE  TRUE  TRUE  TRUE
[2,] FALSE FALSE  TRUE  TRUE
[3,] FALSE FALSE FALSE  TRUE
[4,] FALSE FALSE FALSE FALSE
> lower.tri(diag(4))
      [,1]  [,2]  [,3]  [,4]
[1,] FALSE FALSE FALSE FALSE
[2,]  TRUE FALSE FALSE FALSE
[3,]  TRUE  TRUE FALSE FALSE
[4,]  TRUE  TRUE  TRUE FALSE
```
Ambas funciones disponen del parámetro `diag` que, igualado a `TRUE`, define también como `TRUE` las entradas de la diagonal principal.
```
> upper.tri(diag(4), diag=TRUE)
      [,1]  [,2]  [,3] [,4]
[1,]  TRUE  TRUE  TRUE TRUE
[2,] FALSE  TRUE  TRUE TRUE
[3,] FALSE FALSE  TRUE TRUE
[4,] FALSE FALSE FALSE TRUE
```


Si $M$ es una matriz y $L$ es una matriz de valores lógicos del mismo orden, `M[L]` produce el vector construido de la manera siguiente: de cada columna, se queda sólo con las entradas de $M$ cuya entrada correspondiente en $L$ es `TRUE`, y a continuación concatena estas columnas, de izquierda a derecha, en un vector. 
```
> M=matrix(1:16, nrow=4, byrow=T)
> M
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12
[4,]   13   14   15   16
> M[upper.tri(diag(4))] #Las entradas del triángulo superior, por columnas
[1]  2  3  7  4  8 12
```
Ahora, tenemos las matrices siguientes:
```
> matrix(rep(medidas, times=4), nrow=4, byrow=FALSE)
     [,1]           [,2]           [,3]           [,4]          
[1,] "Sepal.Length" "Sepal.Length" "Sepal.Length" "Sepal.Length"
[2,] "Sepal.Width"  "Sepal.Width"  "Sepal.Width"  "Sepal.Width" 
[3,] "Petal.Length" "Petal.Length" "Petal.Length" "Petal.Length"
[4,] "Petal.Width"  "Petal.Width"  "Petal.Width"  "Petal.Width" 
> matrix(rep(medidas, times=4), nrow=4, byrow=TRUE)
     [,1]           [,2]          [,3]           [,4]         
[1,] "Sepal.Length" "Sepal.Width" "Petal.Length" "Petal.Width"
[2,] "Sepal.Length" "Sepal.Width" "Petal.Length" "Petal.Width"
[3,] "Sepal.Length" "Sepal.Width" "Petal.Length" "Petal.Width"
[4,] "Sepal.Length" "Sepal.Width" "Petal.Length" "Petal.Width"
```
Por lo tanto, al aplicar estas matrices a la matriz de valores lógicos `upper.tri(diag(4))` obtenemos los nombres de las variables correspondientes a las filas y las columnas del triángulo superior, respectivamente, y al aplicar la matriz de correlaciones a esta matriz de valores lógicos, obtenemos sus entradas en este triángulo; en los tres vectores, las entradas siguen el mismo orden. Esto nos permite construir el *data frame* `corrs\_df` cuyas filas están formadas por pares diferentes de variables numéricas de `iris`, su correlación y, aplicando `abs` a esta última variable, su correlación en valor absoluto.

Finalmente, la función `order` ordena los valores del vector al que se aplica, en orden decreciente si se especifica el parámetro `decreasing=TRUE`. Cuando aplicamos un *data frame* a una de sus variables reordenada de esta manera, reordena sus filas según el orden de esta variable. En este caso hubiéramos conseguido lo mismo con la función `sort`, pero la función `order` se puede aplicar a más de una variable del \df: esto permite ordenar las filas del *data frame* en el orden de la primera variable de manera que, en caso de empate, queden ordenadas por la segunda variable,  y así sucesivamente.
\end{ejemplo}

%## Variables redundantes (Opcional)
%
%
% En una matriz de datos hay `variables redundantes`  cuando hay columnas que no
%aportan información nueva a la que aportan las otras columnas. 
%Un ejemplo de redundancia de variables se da cuando una columna
%${x}_{\bullet i}$ es combinación lineal de otras columnas
%${x}_{\bullet i_1}, \ldots , {x}_{\bullet i_k}$.
%En este caso decimos que se da `redundancia por dependencia lineal` , y es la única que consideraremos en este curso, por lo que cuando hablemos de variables redundantes, nos referiremos realmente a  variables redundantes por dependencia lineal.
%En concreto, diremos que una matriz de datos `tiene $k$ variables redundantes`     cuando contiene $k$ columnas ${x}_{\bullet l_1}, \ldots, x_{\bullet l_k}$ que son combinaciones lineales del resto de variables, 
%$\{{x}_{\bullet  1}, \ldots, {x}_{\bullet p}\}-\{{x}_{\bullet l_1}, \ldots, x_{\bullet l_k}\}$.
%
%Por ejemplo, 
%en la matriz
%$$
%\left(\begin{array}{ccc}
%1 & -1 & 2\\
%3 & 0 & 7\\
%-2 & 4 & 1
%\end{array}\right)
%$$
%${x}_{\bullet  3}$ es redundante, puesto que
%$$
%\left(\begin{array}{c}
%2\\
%7\\
%1
%\end{array}\right)
%=2\left(\begin{array}{c}
%1 \\
%3 \\
%-2 
%\end{array}\right)
%+\left(\begin{array}{c}
% -1 \\
%0 \\
% 4 
%\end{array}\right)
%+\left(\begin{array}{c}
%1 \\
%1\\
%1
%\end{array}\right)
%$$
%Despejando en esta igualdad cada una de las otras dos columnas, vemos que también son redundantes, pero esta redundancia se debe a la misma relación. Por tanto, no podemos decir que esta matriz tenga tres variables redundantes, sólo tiene  una.
%En cambio la matriz de datos
%$$
%\left(\begin{array}{ccccc}
%1 & 4 & 3&-5 & 4\\
%3 & 9 & 7& -13 & 8\\
%-2 & -2 & 0&4 & 1
%\end{array}\right)
%$$ 
%tiene dos variables redundantes, dadas por las relaciones lineales
%$$
%{x}_{\bullet 4}={x}_{\bullet 1}-2{x}_{\bullet 2}+2\cdot \mathbf{1}_3, \quad
%{x}_{\bullet 5}={x}_{\bullet 3}+\mathbf{1}_3
%$$
%(donde $\mathbf{1}_3$ indica el vector columna formado por tres unos).
%Observad que, en estas relaciones, ${x}_{\bullet 4}$ y ${x}_{\bullet 5}$ dependen de ${x}_{\bullet 1}$, ${x}_{\bullet 2}$ y ${x}_{\bullet 3}$, pero 
%ni ${x}_{\bullet 4}$ depende de ${x}_{\bullet 5}$ ni viceversa.
%
%
%La propiedad siguiente de la matriz de covarianzas nos da una manera de detectar el número de variables redundantes de una matriz de datos.
%
%\begin{teorema}
%Sea $\mathbf{S}$ la matriz de covarianzas de una matriz de datos ${X}$ de $p$  variables. Entonces, el número de variables redundantes de ${X}$ es igual a los dos valores siguientes:
%
%*  A la multiplicidad de 0 como valor propio de $\mathbf{S}$.
%* (Cuando $n\geq p$) A $p$ menos el rango de $\mathbf{S}$.
%
%En particular, si $|\mathbf{S}|\neq 0$, entonces ${X}$ no contiene ninguna variable redundante, y si $|\mathbf{S}|=0$, entonces ${X}$ contiene al menos una variable redundante.
%\end{teorema}
%Como la matriz de covarianzas muestrales $\widetilde{\mathbf{S}}$ de ${X}$ es un múltiplo escalar de  $\mathbf{S}$, este resultado también vale para $\widetilde{\mathbf{S}}$, lo que facilita su aplicación con `R`.
%
%\begin{ejemplo}
%Continuemos con la matriz del Ejemplo \@ref(mult:ex0), 
%$$
%{X}=\begin{pmatrix}
%1&-1&3\\
%1&0&3\\
%2&3&0\\
%3&0&1
%\end{pmatrix}
%$$
%Para comprobar si tiene variables redundantes, vamos a calcular el determinante de su matriz de covarianzas muestrales (que es la más fácil de calcular con `R`):
%```
%> X
%  V1 V2 V3
%1  1 -1  3
%2  1  0  3
%3  2  3  0
%4  3  0  1
%> det(cov(X))
%[1] 0.1481481
%```
%Como este determinante es diferente de 0, concluimos que ${X}$ no contiene variables redundantes. 
%\end{ejemplo}
%
%
%\begin{ejemplo}
%¿Tiene la tabla de datos `iris` alguna variable numérica redundante? 
%```
%> det(cov(iris_num))
%[1] 0.00191273
%```
%La respuesta es, de nuevo, negativa.
%\end{ejemplo}
%
%
%\begin{ejemplo}\label{mult:ex2}
%Consideremos la tabla de datos siguiente:
%$$
%{X}=
%\left(\begin{array}{cccc}
%1 & 0 & -1 \\
%1 & 2 & 1 \\
%1 & 1 & 0 \\
%0 & 3 & 0\
%\end{array}\right)
%$$
%Deseamos saber si contiene variables redundantes. 
%```
%> X=matrix(c(1, 0, -1, 1, 2, 1, 1, 1, 0, 0, 3, 0), nrow=4, byrow=TRUE)
%> S=cov(X)
%> det(S)
%[1] 0
%> qr(S)$rank
%[1] 2
%```
%Obtenemos que el rango de su matriz de covarianzas es 2, lo que implica que ${X}$ contiene exactamente  una variable redundante.
%\end{ejemplo}
%
%

## Representación gráfica de datos multidimensionales
\label{sec:grmulti}

 La representación gráfica de tablas de datos multidimensionales tiene la dificultad de las dimensiones; para dos o tres variables es  sencillo visualizar las relaciones entre las mismas, pero para más variables ya no nos bastan nuestras tres dimensiones espaciales y tenemos que usar algunos trucos, tales como representaciones gráficas conjuntas de pares de variables.

Cuando tenemos una tabla de datos formada por dos variables numéricas, la manera más sencilla de representarlos gráficamente es mediante la función `plot` aplicada a la matriz de datos  o al *data frame*. Con esta función obtenemos un gráfico de los puntos definidos por las filas de la tabla: en el contexto de la estadística multidimensional, se le llama el `diagrama de dispersión`  (*scatter plot*) de los datos.

A modo de ejemplo, si extrajéramos de la tabla `iris` una subtabla conteniendo sólo las longitudes y anchuras de los pétalos y quisiéramos visualizar las relación entre estas dimensiones, podríamos dibujar su diagrama de dispersión de la manera siguiente:
```
> iris.pet=iris[ ,c("Petal.Length","Petal.Width")]
> plot(iris.pet, pch=20, xlab="Largo", ylab="Ancho")
```
El resultado es la Figura \@ref(fig:iris1), que muestra una clara tendencia positiva: cuanto más largos son los pétalos, más anchos tienden a ser. Esto se corresponde con la correlación de 0.9628654 que hemos obtenido en el Ejemplo \ref{ex:irismult). 

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{irisplot1}
\end{center}
\caption{Diagrama de dispersión  de las longitudes y anchuras de los pétalos  de las flores representadas en la tabla `iris`.}\label{fig:iris1}
\end{figure}

Para tablas de datos de tres columnas numéricas, podemos usar con un fin similar la instrucción `scatterplot3d` del paquete homónimo, que dibuja un diagrama de dispersión tridimensional. Como `plot`, se puede aplicar a un *data frame* o a una matriz; por ejemplo, para representar gráficamente las tres primeras variables numéricas de `iris`, podríamos hacer lo siguiente:
\bigskip

```
> #Instalamos y cargamos el paquete scatterplot3d
...
> scatterplot3d(iris[ , 1:3], pch=20)
```
Obtendríamos la Figura \@ref(fig:iris2). Podéis consultar la Ayuda de la instrucción para saber cómo modificar su apariencia: cómo ponerle un título, etiquetar los ejes, usar colores, cambiar el estilo del gráfico, etc.
\vspace*{-3ex}

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{irisplot2}
\end{center}
\caption{Diagrama de dispersión tridimensional de las tres primeras columnas de la tabla `iris`.}\label{fig:iris2}
\end{figure}

Una representación gráfica muy popular de las tablas de datos de tres o más columnas numéricas son las matrices formadas por los diagramas de dispersión de todos sus pares de columnas. Si la tabla de datos es un *data frame*, esta matriz de diagramas de dispersión  se obtiene simplemente aplicando la función `plot` al \df; por ejemplo,
```
> plot(iris[ , 1:4])
```
produce el gráfico de la izquierda de  la Figura \@ref(fig:iris3). En este gráfico, los cuadrados en la diagonal indican  a qué variables corresponden cada fila y cada columna, de manera que podamos identificar fácilmente qué variables compara cada diagrama de dispersión; así, en el diagrama de la primera fila y segunda columna de esta figura, las abscisas corresponden a anchuras de sépalos y las ordenadas a longitudes de sépalos. Observad que la nube de puntos no muestra una tendencia clara y en todo caso ligeramente negativa, lo que se corresponde con la correlación entre estas variables  de $-0.11$ que hemos obtenido en el Ejemplo \ref{ex:irismult).

Podemos usar los parámetros usuales de `plot` para mejorar el gráfico resultante; por ejemplo, podemos usar colores para distinguir las flores según su especie: 
```
> plot(iris[ , 1:4], col=iris$Species)
```
produce el gráfico de la derecha de  la Figura \@ref(fig:iris3).

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{irisplot3}\ 
\includegraphics[width=0.45\linewidth]{irisplot4}
\end{center}
\caption{Matrices de diagramas de dispersión  de la tabla `iris`; en la de la derecha, las especies se distinguen por medio de colores.}\label{fig:iris3}
\end{figure}

La matriz de diagramas de dispersión  de una tabla de datos multidimensional también se puede calcular con la función `pairs`: así,  `pairs(iris[, 1:4])` produce exactamente el mismo gráfico que `plot(iris[, 1:4])`. La ventaja de `pairs` es que se puede aplicar a una matriz para obtener la matriz de diagramas de dispersión de sus columnas, mientras que `plot` no. 



El paquete `car` incorpora la función `spm` que genera matrices de diagramas de dispersión enriquecidos con información descriptiva  de las variables de la tabla de datos. Por ejemplo, 
```
> #Instalamos y cargamos el paquete car
> ...
> spm(iris[ , 1:4])
```
produce el gráfico de la izquierda de la Figura \@ref(fig:iris5). Observaréis para empezar que en los cuadrados de la diagonal ha dibujado unas curvas: se trata de la curva de densidad de la variable correspondiente de la que ya hablábamos en la Sección \ref{sec:hist). La información gráfica contenida en estos cuadrados de la diagonal se puede modificar con el parámetro `diagonal`: podemos pedir, por ejemplo, que dibuje un histograma de cada variable (con `diagonal="histogram"`) o su *boxplot* (con `diagonal="boxplot"`). Así, 
```
> spm(iris[ , 1:4], diagonal="boxplot")
```
produce el gráfico de la derecha de la Figura \@ref(fig:iris5).



\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{irisplot5}\
\includegraphics[width=0.45\linewidth]{irisplot6}\
\end{center}
\caption{Matrices de diagramas de dispersión de la tabla `iris` producidos con `spm`.}\label{fig:iris5}
\end{figure}

Asimismo, observaréis que los diagramas de dispersión de la matriz producida con `spm` contienen curvas. La línea recta verde es la recta de regresión por mínimos cuadrados y, sin entrar en detalle sobre su significado exacto, las curvas rojas continuas representan la tendencia de los datos.


## Guía rápida



* `sapply(`\df`,``función` `)` aplica la `función`  a las columnas de un *data frame*

* `scale` sirve para aplicar una transformación lineal a una matriz o a un *data frame* Sus parámetros son:

*   `center`: especifica  el vector que restamos a sus columnas.

*  `scale`: especifica  el vector por el que a continuación dividimos sus columnas.


* `cov`, aplicada a dos vectores, calcula su covarianza muestral; aplicada a un *data frame* o a una matriz, calcula su matriz de covarianzas muestrales.
Dispone del parámetro `use`:

* Igualado a `"{`pairwise.complete.obs"}, calcula la covarianza de cada par de columnas  teniendo en cuenta sólo sus observacions completas (las filas en las que ninguna de las dos tiene un `NA`), independientemente del resto de la tabla.
* Igualado a `"{`complete.obs"}, calcula las covarianzas de las columnas teniendo en cuenta sólo las filas completas de toda la matriz.


* `cor`, aplicada a dos vectores, calcula su correlación; aplicada a un *data frame* o a una matriz, calcula su matriz de correlaciones. Dispone del mismo parámetro `use`  que `cov`. 

* `cov2cor`, aplicada a la matriz de covarianzas, calcula la matriz de correlaciones.

* `upper.tri`, aplicada a una matriz cuadrada $M$, produce la matriz  triangular superior de valores lógicos del mismo orden que $M$. Con el parámetro `diag=TRUE` se impone que el triángulo de valores `TRUE` incluya la diagonal principal.


* `lower.tri`, aplicada a una matriz cuadrada $M$, produce la matriz  triangular inferior de valores lógicos del mismo orden que $M$. Dispone del mismo  parámetro `diag=TRUE`.

* `order` ordena el primer vector al que se aplica, desempatando empates mediante el orden de los vectores subsiguientes a los que se aplica; el parámetro `decreasing=TRUE` sirve para especificar  que sea en orden decreciente. 

* `plot`, aplicado a un *data frame* de dos variables numéricas, dibuja su diagrama de dispersión; 
aplicado a un *data frame* de más de dos variables numéricas, produce la matriz formada por los diagramas de dispersión de todos sus pares de variables.

* `pairs` es equivalente a `plot` en el sentido anterior, y se puede aplicar a matrices.

* `scatterplot3d`, del paquete del mismo nombre,  dibuja diagramas de dispersión tridimensionales. 



## Ejercicio

 El fichero [http://aprender.uib.es/Rdir/NotasMatesI14.txt](http://aprender.uib.es/Rdir/NotasMatesI14.txt)  recoge las notas medias (sobre 100) obtenidas, en las diferentes actividades de evaluación de la asignatura Matemáticas I del grado de Biología en el curso 2013/14, por parte de los estudiantes que fueron considerados <<presentados>> en la primera convocatoria. Estas actividades consistieron en:

* Dos controles (columnas `Control1` y `Control2`).
* Talleres de resolución de problemas (columna `Talleres`).
* Ejercicios para resolver en casa (columna `Casa`).
* Cuestionarios en línea sobre los contenidos de la asignatura y sobre `R` 
 (columnas `TestsCont` y `TestsR`, respectivamente).

Cargad este fichero en un *data frame*.


[(a)]
* Calculad el vector de medias y el vector de desviaciones típicas de esta tabla de datos. ¿Cuáles son las actividades de evaluación cuyas notas presentan mayor y menor variabilidad? 

* Calculad las matrices de covarianzas y de correlaciones de esta tabla de datos. 

* ¿Qué variable tiene la mayor correlación media con las otras variables? ¿Cuál  tiene la menor?

* Ordenad los pares de variables de esta tabla por su correlación. ¿Cuáles son los dos pares con mayor correlación positiva?
 ¿Cuáles son los dos pares con menor correlación negativa?
 
* Comprobad en esta tabla de datos que su matriz de correlaciones es igual a la matriz de covarianzas de su tabla tipificada.

* Dibujad una matriz de diagramas de dispersión de estas notas. ¿Se pueden ver en este diagrama los 
 dos pares de actividades de evaluación con mayor correlación y los dos pares con menor correlación que habéis encontrado en el apartado (d)?
 



# Datos cuantitativos agrupados {#chap:cut}


 En nuestro lenguaje cotidiano, solemos agrupar datos cuantitativos sin que seamos conscientes de ello. Cuando decimos, por ejemplo, que la edad de alguien es de 18 años, no queremos decir que nació justo hoy hace 18 años, sino que ya ha cumplido los 18 años, pero aún no ha cumplido los 19; es decir, que agrupamos todas las edades que caen dentro del intervalo $[18,19)$ en una misma clase, que llamamos <<18 años>>. Del mismo modo, que alguien mida 1.72 no significa que esta sea su altura exacta, con la precisión del grueso de un cabello, sino que su altura pertenece a un intervalo de valores en torno a 1.72 metros que identificamos con <<1.72>>. Bajo  la calificación de <<aprobado>> agrupamos todas las notas mayores o iguales que 5 y menores que 7. Y estamos seguros de que se os ocurren otros ejemplos. 

Cuando trabajamos en estadística con datos cuantitativos, puede haber varios motivos por los que nos interese agruparlos. Una posibilidad es que 
queramos estudiar la distribución de una cierta variable (pongamos, la altura) en una muestra  de individuos, y que los valores que pueda tomar esta variable sean muy heterogéneos; en esta situación,  lo normal sería que obtuviéramos muy pocas repeticiones, por lo que las frecuencias de los valores individuales serían muy bajas y por lo tanto muy similares. Esto daría lugar  a un diagrama de barras difícil de interpretar. 

Veamos un ejemplo: consideremos la siguiente muestra de 30 alturas de estudiantes:
$$
\begin{array}{l}
1.71, 1.62, 1.72, 1.76, 1.78, 1.73, 1.67, 1.64, 1.63, 1.68, 1.68, 1.70,
1.67, 1.56, 1.66, 1.57, 1.69,\\
 1.68, 1.67, 1.75, 1.61, 1.60, 1.74, 1.70,
1.65, 1.55, 1.82, 1.70, 1.69, 1.81.
\end{array}
$$
El diagrama de barras de sus frecuencias (tomando como posibles niveles todas las alturas entre su mínimo y su máximo, redondeadas a cm) es la Figura \@ref(fig:Alturas).(a).  Todas la barras tienen alturas entre 0 y 3, y salvo una mayor presencia de los valores centrales (entre 1.67 y 1.70), no hay mucho más que salte a la vista en este gráfico.

En situaciones como esta, es recomendable dividir los posibles valores de la variable en  intervalos y contar cuántos datos caen dentro de cada intervalo: habitualmente, las frecuencias que se obtienen de esta manera son más fáciles de interpretar que las de los datos individuales. Así, siguiendo con nuestro ejemplo de las alturas, el diagrama de barras de la Figura \@ref(fig:Alturas).(b)  representa sus frecuencias cuando las agrupamos en intervalos de 5 cm. La distribución de estas alturas es mucho más fácil de entender mediante este gráfico que con el primero.

\begin{figure}[htb]
\abovecaptionskip=-1ex
\begin{center}
\begin{tabular}{cc}
\includegraphics[width=0.45\linewidth]{exAlturas1.pdf} &
\includegraphics[width=0.45\linewidth]{exAlturas2.pdf}\\[-0.5cm]
(a) & (b)
\end{tabular}
\end{center} 
\caption{Diagramas de barras de un mismo conjunto de alturas: (a) con los datos sin agrupar; (b) con los datos agrupados en intervalos de 5 cm.}\label{fig:Alturas}
\end{figure}



Otro motivo por el que puede ser conveniente agrupar datos es la imposibilidad física de medir  de manera exacta algunas magnitudes continuas como alturas, pesos o tiempos; esto hace que los datos obtenidos sean sólo aproximaciones o redondeos de los valores reales y que cada medida diferente represente todo un intervalo de posibles valores. 


En general, hay tres situaciones concretas en las cuales conviene agrupar datos cuantitativos en intervalos de valores, también llamados  `clases` :

* Cuando los datos son continuos y no se pueden medir de manera exacta: su redondeo ya define un  agrupamiento.

* Cuando los datos son discretos, pero con un número muy grande de posibles valores: números de aminoácidos en proteínas, números de bases en cadenas de ADN\ldots  

* Cuando tenemos muchos datos y nos interesa estudiar las frecuencias de sus valores; hay autores que consideran que `muchos` , en este contexto, significa  `30 o más` .



## Cómo agrupar datos

 El paso previo al estudio de unos datos agrupados es, naturalmente, agruparlos. El proceso es el siguiente:
[(1)]
* Se decide el número de intervalos que se van a usar.
* Se decide su amplitud.
* Se calculan los extremos de los intervalos.
* Finalmente, en algunas aplicaciones, se calcula un valor representativo de cada intervalo, llamado su `marca de clase` .

No hay una manera de agrupar datos mejor que otra; por ejemplo, para estudiar las calificaciones de un curso podemos agruparlas en Suspenso, $[0,5)$, Aprobado, $[5,7)$ Notable, $[7,9)$, y Sobresaliente, $[9,10]$, o podemos redondear por defecto las notas a su parte entera y usar  los intervalos $[0,1)$, $[1,2)$, \ldots, $[9,10]$. Podría ser que cada uno de estos agrupamientos saque a la luz características diferentes del conjunto de datos.



La función básica de `R` para estudiar datos agrupados, `hist`, implementa todo el proceso: si le entramos  el vector de datos y el número de intervalos, o el método para determinarlo (véase más adelante), agrupará los datos en, más o menos, el número de clases que le hemos especificado,  sin ningún control por nuestra parte sobre los intervalos que produce. Para un análisis somero de los datos, esto suele ser más que suficiente, pero para una descripción más cuidadosa es conveniente que seamos nosotros quienes controlemos el proceso de agrupamiento, y en particular que calculemos los extremos de los intervalos, en lugar de dejárselos calcular a `R`.
En esta sección explicamos `nuestra receta`  para agrupar datos y calcular marcas de clase; no es ni mejor ni peor que otras, pero es la que os recomendamos que uséis, sobre todo en el test si queréis obtener las respuestas correctas.

Lo primero que tenemos que hacer  es establecer  el número $k$ de clases en las que vamos a  dividir el conjunto de datos, al que denotaremos en lo que sigue por $x$. Podemos decidir este número de clases en función de nuestros intereses concretos, o podemos usar alguna de las reglas que se han propuesto con este fin; las más populares son las siguientes, donde $n$ denota el número de datos en la muestra:^[  Recordad en lo que sigue que $\lceil x \rceil$ denota el menor entero que es mayor o igual que $x$, y que con `R` se calcula mediante la función `ceiling`.] \indR{ceiling}


* `Regla de la raíz cuadrada` \index{regla de agrupamiento!de la raíz cuadrada}: $k= \big\lceil \sqrt{n}\big\rceil $.

* `Regla de Sturges` \index{regla de agrupamiento!de Sturges}: $k= \big\lceil 1+\log_{2}(n)\big\rceil.$

* `Regla de Scott` \index{regla de agrupamiento!de Scott}: Se determina primero la `amplitud teórica`  $A_S$ de las clases mediante la fórmula $$A_S= 3.5\cdot \widetilde{s}\cdot n^{-\frac{1}{3}}$$ (donde $\widetilde{s}$ es la desviación típica muestral del conjunto de datos), y entonces se toma $$k=\left\lceil
\frac{\max(x) -\min(x)}{A_S}\right\rceil.$$

* `Regla de Freedman-Diaconis` \index{regla de agrupamiento!de Freedman-Diaconis}: Se determina primero la `amplitud teórica`  $A_{FD}$ de las clases por medio de la fórmula $$A_{FD}= 2 \cdot (Q_{0.75}-Q_{0.25}) \cdot n^{-\frac{1}{3}}$$ (recordad que $Q_{0.75}-Q_{0.25}$ es el rango intercuartílico), y entonces se toma de nuevo $$k= \left\lceil
\frac{\max(x) -\min(x)}{A_{FD}}\right\rceil.$$

Como podéis ver, las dos primeras sólo dependen de $n$, mientras que las  dos últimas tienen  en cuenta, de maneras diferentes, su dispersión; no hay una regla mejor que las otras y, además, números de clases diferentes pueden revelar  características diferentes de los datos.
Las tres últimas reglas están implementadas en las funciones `nclass.Sturges`, `nclass.scott` y `nclass.FD` de `R`, respectivamente.


\begin{ejemplo}\label{ex:alerg}
Mucha gente manifiesta reacciones alérgicas sistémicas a las picaduras de insecto; estas reacciones varían entre pacientes, no sólo en lo que se refiere a la gravedad de la reacción, sino también en el tiempo que tarda en manifestarse. En un estudio se midió,  en 40 pacientes que experimentaron una reacción alérgica a una picadura de abeja, 
el tiempo de inicio de esta reacción desde la picadura, y se obtuvieron los datos siguientes, 
que expresamos en minutos:
$$
\begin{array}{l}
10.5, 11.2, 9.9,  15.0, 11.4, 12.7, 16.5, 10.1, 12.7, 11.4, 11.6, 6.2,  7.9, 8.3, 10.9, 8.1, 3.8, 10.5, \\ 
11.7, 8.4,   12.5, 11.2, 9.1,  10.4, 9.1,   13.4, 12.3, 5.9,   11.4, 8.8, 7.4,  8.6, 13.6, 14.7, 11.5, 11.5, \\ 
10.9,  9.8,  12.9, 9.9.
\end{array}
$$

Según las diferentes reglas que hemos explicado, los números de intervalos en los que tendríamos que dividir estos datos son los siguientes:

* `Regla de la raíz cuadrada` : $k= \lceil \sqrt{40} \rceil =\lceil 6.3245
\rceil=7$.

* `Regla de Sturges` : $k= \lceil 1+\log_{2}(40)
\rceil= \lceil 6.321928\rceil=7$.

* `Regla de Scott` : Mediante
```
> alergia=c(10.5,11.2,9.9,15.0,11.4,12.7,16.5,10.1,12.7,11.4,11.6,
  6.2,7.9,8.3,10.9,8.1,3.8,10.5,11.7,8.4,12.5,11.2,9.1,10.4,9.1,
  13.4,12.3,5.9,11.4,8.8,7.4,8.6,13.6,14.7,11.5,11.5,10.9,9.8,
  12.9,9.9)
> sd(alergia)
[1] 2.533609
> diff(range(alergia))
[1] 12.7
```
vemos que la desviación típica muestral de estos datos es $\widetilde{s}=2.533609$ y su rango, 12.7; por lo tanto, $A_{S}= 3.5\cdot 2.533609 \cdot 40^{-\frac{1}{3}}= 2.592911$ y 
$k=\lceil {12.7}/{2.592911}\rceil=\lceil 4.89797\rceil=5$.

* `Regla de Freedman-Diaconis` : Mediante
```
> IQR(alergia)
[1] 2.825
```
obtenemos que $Q_{0.75}-Q_{0.25}=2.825$; por lo tanto, $A_{FD}= 2\cdot 2.825 \cdot 40^{-\frac{1}{3}}=1.65207$ y 
$k= \lceil {12.7}/{1.65207}\rceil=\lceil 7.687\rceil=8$.

Como podéis ver, reglas diferentes pueden dar valores diferentes, y puede que no.

Con `R`, hubiéramos podido calcular directamente los tres últimos números de clases de la manera siguiente:
```
> nclass.Sturges(alergia)
[1] 7
> nclass.scott(alergia)
[1] 5
> nclass.FD(alergia)
[1] 8
```
\end{ejemplo}

Una vez determinado el número $k$ de clases, tenemos que decidir su amplitud; la forma más sencilla, y que adoptaremos por defecto, es tomar todos los intervalos de la misma amplitud.^[ Pero no es la única forma posible de hacerlo, naturalmente. Recordad, por ejemplo,  el agrupamiento de las calificaciones en Suspenso, Aprobado, Notable y Sobresaliente, que representan intervalos de notas de amplitudes diferentes.]  Para calcular esta amplitud, $A$, dividiremos el rango de los datos entre el número $k$ de clases y redondearemos por exceso a un valor de la precisión de la medida: si medimos edades con una precisión de años, redondearemos este cociente por exceso a años, si medimos alturas con una precisión de centímetros, redondearemos por exceso a centímetros, etc.
En el caso improbable de que el cociente del rango entre el número de clases dé un valor exacto en la precisión de la medida, tomaremos como $A$
este cociente más una unidad de precisión; así, por ejemplo, si hemos medido unas alturas en metros con una precisión de centímetros y obtenemos que el cociente del rango entre $k$ da un número exacto de centímetros, tomaremos como amplitud $A$ este cociente más 1 cm.

\begin{ejemplo}
Seguimos con el Ejemplo  \@ref(ex:alerg); vamos a continuar el proceso de agrupamiento de los datos en $k=7$ clases. Recordemos que el rango del conjunto de datos en cuestión es 12.7 y que los datos están expresados en minutos con una precisión de una cifra decimal; por lo tanto, la amplitud será el cociente $12.7/7=1.8143$ redondeado por exceso a  una cifra decimal: $A=1.9$.
\end{ejemplo}

Ahora hemos de calcular los extremos de los intervalos. En este curso, tomaremos estos intervalos siempre cerrados a la izquierda y abiertos a la derecha, y los denotaremos por
$$
[L_1,L_2),[L_2,L_3),\ldots, [L_k,L_{k+1}).
$$
Sin entrar en detalles, el motivo por el que tomamos los intervalos de esta forma y no al revés (abiertos por la izquierda y cerrados por la derecha, que es como los construye `R` por defecto) es porque así es como se usan en Teoría de Probabilidades al definir la distribución de una variable aleatoria discreta, y también en muchas situaciones cotidianas (calificaciones, edades\ldots). 
En todo caso, queremos haceros notar que, con la regla que explicamos a continuación, los extremos de los intervalos nunca van a coincidir con valores del conjunto de datos: si la usáis, tanto dará si consideráis los intervalos abiertos o cerrados en sus extremos.

Los extremos $L_1,\ldots,L_{k+1}$ de estos intervalos se calculan de la manera siguiente: tomamos como extremo izquierdo $L_1$ del primer intervalo el valor 
$$
L_1=\mbox{mín}(x)-\frac{1}{2}\cdot \mbox{precisión;} 
$$
es decir, si la precisión son las unidades en las que hemos medido los datos, $L_1=\mbox{mín}(x)-0.5$; si la precisión son décimas de unidad, $L_1=\mbox{mín}(x)-0.05$; etc. A partir de este extremo inferior, cada uno de los extremos siguientes se obtiene sumando la amplitud al anterior: 
$L_2=L_1+A$, $L_3=L_{2}+A$ y así sucesivamente, hasta llegar a $L_{k+1}=L_{k}+A$.
Por consiguiente, estos extremos forman una progresión aritmética de paso $A$:
$$
L_i=L_1+(i-1)A,\quad i=2,\ldots,k+1.
$$
Como decíamos, de esta manera se garantiza que los extremos de los intervalos nunca coincidan con valores del conjunto de datos: por ejemplo, si los datos están expresados con una sola cifra decimal, estos extremos tienen todos un 5 en su segunda cifra decimal.

\begin{ejemplo}
Continuemos con el Ejemplo \@ref(ex:alerg) y $k=7$; hemos visto que tenemos que tomar $A=1.9$. El valor mínimo del conjunto de datos es 3.8:
```
> min(alergia)
[1] 3.8
```
Además, los datos están expresados con una precisión de décimas de unidad.
El extremo inferior del primer intervalo será, entonces, $L_1=3.8-0.05=3.75$, y a partir de aquí obtendremos el resto de extremos mediante una progresión aritmética de paso 1.9:
$$
\begin{array}{l}
L_1=3.75\\
L_2=3.75+1.9=5.65\\ 
L_3=3.75+2\cdot 1.9 = 7.55\\ 
L_4= 3.75+3\cdot 1.9 = 9.45\\ 
L_5= 3.75+4\cdot 1.9 = 11.35\\ 
L_6= 3.75+5\cdot 1.9 = 13.25\\
L_7= 3.75+6\cdot 1.9 = 15.15\\
 L_8= 3.75+7\cdot 1.9 = 17.05
\end{array}
$$
Los intervalos son, por lo tanto,
$$
\begin{array}{c}
[3.75,5.65),\ [5.65,7.55),\ [7.55,9.45),\ [9.45, 11.35),\ [11.35 ,13.25),\\{}
[13.25,15.15),\ [15.15,17.05).
\end{array}
$$
\end{ejemplo}

Finalmente, hemos de determinar la `marca de clase`  $X_i$ de cada intervalo $[L_i,L_{i+1})$; se trata de  un valor  del intervalo que usaremos para identificar la clase y para calcular algunos estadísticos. Como regla general, en este curso marcaremos el punto medio del intervalo, 
$$
X_i=\frac{L_{i}+L_{i+1}}{2};
$$ 
de esta manera, el error máximo que se comete al describir cualquier elemento  del intervalo por medio de su marca de clase es mínimo e igual a la mitad de la amplitud del intervalo. 

Como todos los intervalos tienen la misma amplitud $A$, la diferencia entre dos puntos medios consecutivos será también $A$, y por consiguiente las marcas de clase formarán de nuevo una progresión aritmética de paso $A$:
$$
X_1=\frac{L_1+L_2}{2}\quad \mbox{ y }\quad X_i=X_1+(i-1)A, \quad i=2,\ldots,k.
$$

\begin{ejemplo}
Continuemos con el Ejemplo \@ref(ex:alerg) para $k=7$.
Las marcas de clase serán los puntos medios de los intervalos que hemos determinado en el ejemplo anterior; como hemos visto, formarán  una progresión aritmética de origen el punto medio del primer intervalo y paso la amplitud de las clases:
$$
\begin{array}{l}
X_1=(3.75+5.65)/2=4.7\\
X_2= 4.7 +1.9= 6.6\\
X_3= 4.7 + 2\cdot 1.9 = 8.5\\
X_4= 4.7 + 3\cdot 1.9= 10.4\\
X_5= 4.7 + 4\cdot 1.9= 12.3\\
X_6=4.7 + 5\cdot 1.9= 14.2\\
X_7= 4.7 + 6\cdot 1.9= 16.1
\end{array}
$$
\end{ejemplo}

\begin{ejemplo}
Volvamos a la situación inicial del Ejemplo \@ref(ex:alerg), y esta vez vamos a agrupar los datos siguiendo la regla de Scott. 
Ya  calculamos en su momento que, con esta regla, tenemos que usar  $k=5$ intervalos. Como el rango de los datos es 12.7 y $12.7/5=2.54$, redondeando por exceso este cociente a una décima obtenemos que la amplitud de los intervalos ha de ser  $A=2.6$.

Calculemos los extremos de los intervalos: el extremo inferior del primero es, de nuevo, $L_1=3.8-0.05=3.75$, y a partir de este valor, los otros extremos se obtienen sumando consecutivamente la amplitud hasta llegar a $L_6$:
```
> L=3.75+2.6*(0:5)
> L
[1]  3.75  6.35  8.95 11.55 14.15 16.75
```
Los intervalos son, por lo tanto,
$$
[3.75, 6.35),\ [6.35,8.95),\ [8.95,11.55),\ [11.55, 14.15),\ [14.15 ,16.75).
$$

La marca de clase del primer intervalo es su punto medio: 
$$
X_1=\frac{3.75+ 6.35}{2}= 5.05.
$$
A partir de este valor, las otras marcas se obtienen sumando consecutivamente la amplitud hasta llegar a $X_5$:
```
> X=5.05+2.6*(0:4)
> X
[1]  5.05  7.65 10.25 12.85 15.45
```


También podríamos haber calculado estas marcas de clase definiéndolas directamente como los puntos medios de los intervalos:
```
> X=(L[1:(length(L)-1)]+L[2:length(L)])/2
> X
[1]  5.05  7.65 10.25 12.85 15.45
```
Observad que, en esta última construcción, `L[1:(length(L)-1)]` es el vector $L_1,L_2,\ldots,L_k$ y
`L[2:length(L)]` es el vector $L_2,L_3,\ldots,L_{k+1}$, por lo que 

`(L[1:(length(L)-1)]+L[2:length(L)])/2` 

define el vector 
$$
\frac{L_1+L_2}{2},\frac{L_2+L_3}{2},\ldots,\frac{L_k+L_{k+1}}{2}
$$
formado por las marcas de clase.
\end{ejemplo}


Una vez agrupados los datos, ya podemos empezar a estudiarlos. Una primera posibilidad es 
considerar las clases como los niveles de una variable ordinal y 
calcular sus frecuencias; así, la `frecuencia
absoluta` \index{frecuencia!para datos acumulados} de una clase será el número de datos originales que pertenecen a esta clase, la `frecuencia absoluta acumulada`  de una clase será el número de datos originales que pertenecen a esta clase o a alguna de las anteriores, etc.
La manera usual de representar las frecuencias de un conjunto de datos agrupados es la mostrada en la Tabla \@ref(t:19.1), donde $X_j$ indica la marca de clase, $n_j$ la frecuencia absoluta de la clase, $N_j$ su frecuencia absoluta acumulada, $f_j$ su frecuencia relativa y $F_j$ su frecuencia relativa acumulada. Recordad que $N_k$ será igual al número total de datos recogidos y $F_k$ siempre valdrá 1.

\begin{table}[htb]
\begin{center}
\abovecaptionskip=5pt
\begin{tabular}{lccccc}
\hline intervalos & $X_j$ &
$n_j$ & $N_j$ & $f_j$ & $F_j$
\\\hline $[L_1,L_2)$ & $X_1$ & $n_1$ & $N_1$ & $f_1$ & $F_1$ \\
$[L_2,L_3)$ & $X_2$ & $n_2$ & $N_2$ & $f_2$ & $F_2$ \\ \quad\ $\vdots$ &
$\vdots$ &
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\ $[L_k,L_{k+1})$ & $X_k$ &
$n_k$ &
$N_k$ & $f_k$ & $F_k$\\ \hline
\end{tabular}
\caption{Modelo de tabla de frecuencias para datos agrupados.}\label{t:19.1}
\end{center}
\end{table}  



\begin{ejemplo}\label{ex:table1}
Continuemos con el Ejemplo \@ref(ex:alerg); recordemos que los datos son
$$
\begin{array}{l}
10.5, 11.2, 9.9,  15.0, 11.4, 12.7, 16.5, 10.1, 12.7, 11.4, 11.6, 6.2,  7.9, 8.3, 10.9, 8.1, 3.8, 10.5, \\ 
11.7, 8.4,   12.5, 11.2, 9.1,  10.4, 9.1,   13.4, 12.3, 5.9,   11.4, 8.8, 7.4,  8.6, 13.6, 14.7, 11.5, 11.5, \\ 
10.9,  9.8,  12.9, 9.9.
\end{array}
$$
Las frecuencias
de este conjunto de datos para su agrupamiento en 7 clases  se muestran en la Tabla \@ref(t:19.2). Para construir esta tabla, primero hemos calculado las frecuencias absolutas de cada clase: sólo hay 1 valor dentro de $[3.75, 5.65)$, por lo que $n_1=1$; hay 3 valores dentro de $[5.65, 7.55)$, por lo que $n_2=3$; etc. A partir de estas frecuencias absolutas, hemos calculado el resto de la manera usual.
\end{ejemplo}
\begin{table}[htb]
\begin{center}
\abovecaptionskip=5pt
\begin{tabular}{lrrrrr}
  \hline
intervalos & $X_j$ & $n_j$ & $N_j$ & $f_j$ & $F_j$ \\ 
  \hline
$[3.75, 5.65)$ & 4.7 &   1 &   1 & 0.025 & 0.025 \\ 
$[5.65, 7.55)$ & 6.6 &   3 &   4 & 0.075 & 0.100 \\ 
$[7.55, 9.45)$ & 8.5 &   8 &  12 & 0.200 & 0.300 \\ 
$[9.45, 11.35)$ & 10.4 &  11 &  23 & 0.275 & 0.575 \\ 
$[11.35, 13.25)$ & 12.3 &  12 &  35 & 0.300 & 0.875 \\ 
$[13.25, 15.15)$ & 14.2 &   4 &  39 & 0.100 & 0.975 \\ 
$[15.15, 17.05)$ & 16.1 &   1 &  40 & 0.025 & 1.000 \\ 
   \hline
\end{tabular}
\caption{Frecuencias de los datos del Ejemplo \@ref(ex:alerg) agrupados en 7 clases.}\label{t:19.2)
\end{center}
\end{table}  
 
 %%%%%%% 
\begin{ejemplo}\label{ex:fruitals}
Supongamos que los siguientes valores son números de árboles frutales afectados por la mosca de la fruta en 50 terrenos rústicos de las mismas dimensiones:
$$
\begin{array}{l}
8, 11, 11, 8, 9, 10, 16, 6, 12, 19, 13, 6, 9, 13, 15, 9, 12,
16, 8, 7, 14, 11, 15, 6, 14, 14, 17, 11, 6,\\ 9, 10,
 19, 12, 11, 12,  6, 15, 16, 16, 12, 13, 12, 12, 8, 17, 13, 7, 12, 14, 12.
\end{array}
$$
Para estudiar estos valores, vamos a agruparlos; usaremos la regla de Freedman-Diaconis.^[  Si os preguntáis por qué, la respuesta es\ldots\ ¿por qué no? Ya lo hemos dicho, no hay una regla mejor que las otras. En todo caso, se puede comprobar que esta regla suele dar un mayor número de clases.] 
```
> fruta=c(8,11,11,8,9,10,16,6,12,19,13,6,9,13,15,9,12,16,8,7,14,
  11,15,6,14,14,17,11,6,9,10,19,12,11,12,6,15,16,16,12,13,12,12,
  8,17,13,7,12,14,12)
> nclass.FD(fruta)
[1] 5
> diff(range(fruta))/5
[1] 2.6
> min(fruta)
[1] 6 
```


Por consiguiente, usaremos 5 clases. Como hemos dado las medidas con una precisión de unidades, 
para calcular su amplitud $A$  hemos de redondear por exceso a unidades el cociente  entre el rango de la variable y el número de clases; este cociente vale 2.6, y por lo tanto $A=3$.^[  Recordad que, si la precisión hubiera sido de décimas de unidad, como este cociente ha dado exactamente 2.6, hubiéramos tenido que tomar como amplitud el cociente más una unidad de precisión: 2.7.] 

El extremo inferior de la primera clase será $6-0.5=5.5$, y a partir de aquí calculamos los 5 extremos siguientes sumando sucesivamente la amplitud:
```
> 5.5+3*(0:5)
[1]  5.5  8.5 11.5 14.5 17.5 20.5
```
Por consiguiente, los intervalos son
$$
[5.5, 8.5),\ [8.5,11.5),\ [11.5, 14.5),\ [14.5, 17.5),\ [17.5, 20.5).
$$

Las marcas de clase serán los puntos medios de estos intervalos, que calcularemos sumando múltiplos consecutivos de la amplitud al primer punto medio:
```
> (5.5+8.5)/2+3*(0:4)
[1]  7 10 13 16 19
```
Es decir,
$$
X_1=7,\  X_2=10, \ X_3= 13,\  X_4= 16,\  X_5= 19.
$$

Finalmente, contamos cuántos datos pertenecen a cada clase (serán las frecuencias absolutas) y a partir de aquí calculamos el resto de frecuencias y obtenemos la Tabla \@ref(t:19.3). Lo que nos interesa ahora es que `R` calcule esta tabla por nosotros.
\end{ejemplo} 
\begin{table}[htb]
\abovecaptionskip=5pt
 \begin{center}
\begin{tabular}{lccccc}
\hline
intervalos  & $X_j$ & $n_j$ & $N_j$ &  $f_j$ &  $F_j$ \\ \hline 
$[5.5,8.5)$  & \ 7  & 11 & 11 & 0.22 &  0.22 \\ 
$[8.5,11.5)$ & 10  & 11  & 22  & 0.22  & 0.44 \\
$[11.5,14.5)$ & 13 & 17  & 39  & 0.34  & 0.78 \\ 
$[14.5,17.5)$ & 16 & \ 9  & 48 & 0.18  & 0.96\\
$[17.5,20.5)$ & 19   & \ 2  & 50 & 0.04  & 1.00 \\ \hline
\end{tabular}
\caption{Frecuencias de los datos del Ejemplo \@ref(ex:fruitals) agrupados según la regla de Freedman-Diaconis.}\label{t:19.3)
\end{center}
\end{table} 




## Agrupamiento de datos con `R`

 Al agrupar un conjunto de datos con `R`, lo que hacemos es codificarlos, 
convirtiendo la variable cuantitativa en un factor cuyos niveles son las clases en las que hemos agrupado los valores y asignando cada dato a su clase. Las etiquetas de estos niveles pueden ser de diferentes tipos, en función de los intereses o el gusto del usuario; a modo de ejemplo, supongamos que agrupamos los valores de una variable cuantitativa en los intervalos
$$
[0.5,3.5),[3.5,6.5),[6.5,9.5).
$$
Las etiquetas que se usan para identificar estos intervalos suelen ser las siguientes:
\begin{description}
* [Codificación 1.] Los intervalos mismos: $[0.5,3.5),[3.5,6.5),[6.5,9.5)$.

* [Codificación 2.] Las marcas de clase, que para cada intervalo sería su punto medio: $2,5,8$.
* [Codificación 3.] El número de orden de cada intervalo: $1,2,3$.
\end{description}
Naturalmente, en la práctica podemos usar cualquier otra codificación que se nos ocurra.


La función básica de `R` para agrupar un vector de datos numéricos y codificar 
sus valores  con las clases a las que pertenecen es\indR{cut}

`cut(`$x$`, breaks=\ldots, labels=\ldots, right=\ldots)`,

donde:

* $x$ es el vector numérico.

* El parámetro `breaks`\indRp{cut}{breaks} puede ser un vector numérico formado por los extremos de los intervalos en los que queremos agrupar los datos y que habremos calculado previamente. También podemos igualar este parámetro a un número $k$, en cuyo caso  `R`   agrupa los datos en $k$ clases; para ello, divide el intervalo comprendido entre los valores mínimo y máximo de $x$ en $k$ intervalos y, a continuación, desplaza ligeramente  a la izquierda el extremo inferior del primero  y a la derecha el extremo superior del último.^[  Por consiguiente, estos intervalos no tienen todos la misma amplitud, y además puede pasar que algún extremo intermedio coincida con algún dato del conjunto.]  

* El parámetro `labels`\indRp{cut}{labels} es un vector con las etiquetas de los intervalos. Su valor por defecto, el que utiliza si no lo especificamos, es la 
codificación 1: usa como etiquetas los mismos intervalos.^[  Aunque puede que escriba sus extremos redondeados, para que muestren todos un número máximo de cifras significativas: por defecto, 3.]  Si especificamos `labels=FALSE`, 
obtenemos la codificación 3: los intervalos se identifican por medio de números naturales correlativos empezando por 1. Para usar como etiquetas las marcas de clase 
o cualquier otro vector, hay que entrarlo  como valor de este parámetro.

* El parámetro `right`\indRp{cut}{right=FALSE} es un parámetro lógico que permite indicar qué tipo de intervalos queremos. Si usamos intervalos cerrados por la izquierda y abiertos por la derecha, tenemos que especificar `right=FALSE`, que `no es el valor por defecto` .

* Hay otro parámetro que a veces es útil, `include.lowest`\indRp{cut}{include.lowest}. Combinado con `right=FALSE`, `include.lowest=TRUE` impone que el último intervalo sea cerrado: $[L_k,L_{k+1}]$. Usualmente lo tomaremos abierto a la derecha, que es el efecto global de `right=FALSE`; pero en algunos agrupamientos *ad hoc* puede que $L_{k+1}$ coincida con el máximo de la variable numérica y entonces es necesario
usar `include.lowest=TRUE` para no excluirlo: véase el Ejemplo \@ref(ex:notes) más adelante.

Podéis consultar la Ayuda de la función para conocer otros parámetros que os puedan ser de utilidad y para saber cómo se pueden especificar otros tipos de intervalos.

\begin{ejemplo}\label{ex:cut}
En un experimento hemos recogido los datos siguientes:
$$
10,9,8 ,7,3,5,6,8,9,5,2,1,3,1,1.
$$
Vamos a agruparlos en los intervalos
$$
[0.5,4.5), [4.5,8.5), [8.5,12.5).
$$
Son $k=3$ intervalos de amplitud $A=4$.
```
> #Creamos un vector x con los datos
> x=c(10,9,8,7,3,5,6,8,9,5,2,1,3,1,1)
> #Definimos un vector L con los extremos de los intervalos
> L=0.5+4*(0:3)
> #Definimos x_int como el resultado de la codificación en intervalos empleando como etiquetas los intervalos
> x_int=cut(x, breaks=L, right=FALSE)
> x_int
 [1] [8.5,12.5) [8.5,12.5) [4.5,8.5)  [4.5,8.5)  [0.5,4.5) 
 [6] [4.5,8.5)  [4.5,8.5)  [4.5,8.5)  [8.5,12.5) [4.5,8.5) 
[11] [0.5,4.5)  [0.5,4.5)  [0.5,4.5)  [0.5,4.5)  [0.5,4.5) 
Levels: [0.5,4.5) [4.5,8.5) [8.5,12.5)
> #Definimos x_MC como el resultado de la codificación en intervalos empleando como etiquetas las marcas de clase
> MC=(L[1]+L[2])/2+4*(0:2)  #Las marcas de clase
> x_MC=cut(x, breaks=L, labels=MC, right=FALSE)
> x_MC
 [1] 10.5 10.5 6.5  6.5  2.5  6.5  6.5  6.5  10.5 6.5  2.5  2.5 
[13] 2.5  2.5  2.5 
Levels: 2.5 6.5 10.5
> #Definimos x_Num como el resultado de la codificación en intervalos empleando como etiquetas 1, 2, 3
> x_Num=cut(x, breaks=L, labels=FALSE, right=FALSE)
> x_Num
[1] 3 3 2 2 1 2 2 2 3 2 1 1 1 1 1
```


El resultado de `cut` ha sido, en cada caso, una lista con los elementos del vector original codificados con las etiquetas de las clases a las que pertenecen.
Podemos observar  que las dos primeras aplicaciones de `cut` han producido factores (cuyos niveles son los intervalos y las marcas de clase, respectivamente, en ambos casos ordenados de manera natural), mientras que aplicándolo con `labels=FALSE`  hemos obtenido un vector.


Antes de continuar, ¿que habría pasado si hubiéramos pedido a `R` que cortase los datos en 3 grupos?
```
> x
 [1] 10  9  8  7  3  5  6  8  9  5  2  1  3  1  1
> cut(x, breaks=3, right=FALSE)
 [1] [7,10)    [7,10)    [7,10)    [4,7)     [0.991,4) [4,7)    
 [7] [4,7)     [7,10)    [7,10)    [4,7)     [0.991,4) [0.991,4)
[13] [0.991,4) [0.991,4) [0.991,4)
Levels: [0.991,4) [4,7) [7,10)
```


`R` ha repartido los datos en tres intervalos de longitud 3, y ha desplazado ligeramente a la izquierda el extremo izquierdo del primer intervalo. Fijaos en que, según el resultado que muestra `R`, $10\in [7,10)$. Aunque así escrito resulte contradictorio, la realidad es que `R` ha tomado como  extremo derecho del último intervalo el valor $10.009$, tal y como se explica en la Ayuda de `cut`, pero lo ha escrito redondeado a 10.
\end{ejemplo}

Una vez agrupados los datos y codificados con las etiquetas de las clases, ya podemos calcular las tablas de frecuencias absolutas, relativas y acumuladas de los datos agrupados. Una posibilidad es usar las funciones `table`, `prop.table` y `cumsum` tal como lo hacíamos en las Lecciones \@ref(chap:edqual) y \@ref(chap:ord). Otra posibilidad es usar la función `hist`, a la que dedicaremos la Sección \@ref(sec:hist). Esta función sirve para dibujar el `histograma`  de la variable cuantitativa agrupada (una especie de diagrama de barras para las clases del agrupamiento), pero internamente da lugar a una `list`  cuya componente  `count` es el vector de frecuencias absolutas de las clases. Por consiguiente, para calcular estas frecuencias absolutas, podemos usar la instrucción

`hist(`$x$`, breaks=\ldots, right=FALSE, plot=FALSE)\$count`.

En esta instrucción, es conveniente igualar el parámetro `breaks` al vector de los extremos de los intervalos (porque `cut` y `hist` usan métodos diferentes para agrupar los datos cuando se especifica sólo el número de clases); el significado de `right=FALSE` (y, si es necesario, `include.lowest=TRUE`) es el mismo que en `cut`; y `plot=FALSE` impide que se dibuje el histograma. Por ahora es interesante también saber que el resultado de `hist` incluye la componente `mids` que contiene el vector de puntos medios de los intervalos, nuestras marcas de clase.

\begin{ejemplo}\label{ex:notes}
Supongamos que tenemos las 50 calificaciones siguientes, obtenidas por los estudiantes de una asignatura:
\vspace*{-1.5ex}
\begin{quote}
5.1, 1.1, 6.4,5.3, 10,  5.4,  1.9,  3.1,  5.1,  0.8,  9.6,  6.6,  7.0, 9.6, 10,  1.2,  
4.2,  8.8,  2.4,  1.8,  5.6,  6.8,  6.7, 
 2.2,  8.6,  3.9, 5.6,  5.9,  8.4,  4.9, 0.7,  
8.2,  3.7,  4.8,  5.8,  3.3,  9.7,  7.8, 9.3,  4.5,  6.2,  3.9,  4.7, 6.2,  6.3,
 9.4,
9.3,  2.3,  8.5,  1.4.
\end{quote}
\vspace*{-1.5ex}

 Vamos a agruparlas en Suspenso,  Aprobado,  Notable,   y  Sobresaliente, y calcularemos las frecuencias de estas clases. Observad que las clases no tienen la misma amplitud, y que además la última ha de ser cerrada a la derecha (ha de contener los dieces), por lo que tendremos que usar `include.lowest=TRUE`.
```
> Notas=c(5.1,1.1,6.4,5.3,10,5.4,1.9,3.1,5.1,0.8,9.6,6.6,7.0,9.6,
  10,1.2,4.2,8.8,2.4,1.8,5.6,6.8,6.7,2.2,8.6,3.9,5.6,5.9,8.4,4.9,
  0.7,8.2,3.7,4.8,5.8,3.3,9.7,7.8,9.3,4.5,6.2,3.9,4.7,6.2,6.3,9.4,
  9.3,2.3,8.5,1.4)
> Notas_cut=cut(Notas, breaks=c(0,5,7,9,10),
  labels=c("Suspenso","Aprobado","Notable","Sobresaliente"),
  right=FALSE, include.lowest=TRUE)
 [1] Aprobado      Suspenso      Aprobado      Aprobado     
 [5] Sobresaliente Aprobado      Suspenso      Suspenso     
 [9] Aprobado      Suspenso      Sobresaliente Aprobado     
[13] Notable       Sobresaliente Sobresaliente Suspenso     
[17] Suspenso      Notable       Suspenso      Suspenso     
[21] Aprobado      Aprobado      Aprobado      Suspenso     
[25] Notable       Suspenso      Aprobado      Aprobado     
[29] Notable       Suspenso      Suspenso      Notable      
[33] Suspenso      Suspenso      Aprobado      Suspenso     
[37] Sobresaliente Notable       Sobresaliente Suspenso     
[41] Aprobado      Suspenso      Suspenso      Aprobado     
[45] Aprobado      Sobresaliente Sobresaliente Suspenso     
[49] Notable       Suspenso     
Levels: Suspenso Aprobado Notable Sobresaliente
> table(Notas_cut)  #Frecuencias absolutas 
Notas_cut
     Suspenso      Aprobado       Notable Sobresaliente 
           20            15             7             8 
> cumsum(table(Notas_cut))  #Frecuencias absolutas acumuladas
     Suspenso      Aprobado       Notable Sobresaliente 
           20            35            42            50 
> prop.table(table(Notas_cut))  #Frecuencias relativas 
Notas_cut
     Suspenso      Aprobado       Notable Sobresaliente 
         0.40          0.30          0.14          0.16 
> cumsum(prop.table(table(Notas_cut))) #Frecuencias rel. acum.
     Suspenso      Aprobado       Notable Sobresaliente 
         0.40          0.70          0.84          1.00 
```

También podríamos haber obtenido estas frecuencias usando la función `hist` para calcular el vector de frecuencias absolutas y luego operando con este vector para obtener el resto:
```
> frec_abs=hist(Notas, breaks=c(0,5,7,9,10), right=FALSE, 
  include.lowest=TRUE, plot=FALSE)$count  #Frecuencias absolutas
> frec_abs
[1] 20 15  7  8
> cumsum(frec_abs) #Frecuencias absolutas acumuladas
[1] 20 35 42 50
> frec_abs/length(Notas) #Frecuencias relativas 
[1] 0.40 0.30 0.14 0.16
> cumsum(frec_abs/length(Notas)) #Frecuencias relativas acumuladas 
[1] 0.40 0.70 0.84 1.00
```

Ahora podemos construir un *data frame* que contenga las frecuencias de estas calificaciones con la estructura de la Tabla \@ref(t:19.1).  Como ya explicamos en el Ejemplo \ref{ex:dados),
si calculamos las frecuencias absolutas con `table`, no es conveniente usar el resultado como columna del \df:  
es mejor utilizar el vector que se obtiene al aplicar `as.vector`\indR{as.vector} al resultado de   `table`, y así no se generan columnas espurias con los nombres de los niveles.
```
> intervalos=c("[0,5)","[5,7)","[7,9)","[9,10]")
> calificaciones=c("Suspenso","Aprobado","Notable","Sobresaliente")
> marcas=c(2.5,6,8,9.5) #Marcas de clase
> f.abs=as.vector(table(Notas_cut)) #Frecuencias absolutas
> f.abs.cum=cumsum(f.abs)  #Frecuencias absolutas acumuladas
> f.rel=f.abs/length(Notas) #Frecuencias relativas
> f.rel.cum=cumsum(f.rel) #Frecuencias relativas acumuladas
> tabla.frec=data.frame(intervalos, calificaciones, marcas, f.abs, 
   f.abs.cum, f.rel, f.rel.cum)  #Construimos el data frame
> tabla.frec
  intervalos calificaciones marcas f.abs f.abs.cum f.rel f.rel.cum
1      [0,5)       Suspenso    2.5    20        20  0.40      0.40
2      [5,7)       Aprobado    6.0    15        35  0.30      0.70
3      [7,9)        Notable    8.0     7        42  0.14      0.84
4     [9,10]  Sobresaliente    9.5     8        50  0.16      1.00
```

También hubiéramos podido usar 
```
> Hist_notas=hist(Notas, breaks=c(0,5,7,9,10), right=FALSE, 
  include.lowest=TRUE, plot=FALSE)
> f.abs=Hist_notas$count  
> marcas=Hist_notas$mids  
```
y usar el vector `f.abs` como arranque para calcular las columnas de frecuencias del *data frame* y el vector `marcas` como columna de marcas de clase.
\end{ejemplo}

\begin{ejemplo}
Continuemos con el Ejemplo  \@ref(ex:cut); vamos a calcular  las diferentes frecuencias para la codificación `x\_{`int}:\indR{table}\indR{prop.table}\indR{cumsum)
```
> table(x_int)
x_int
 [0.5,4.5)  [4.5,8.5) [8.5,12.5) 
         6          6          3 
> prop.table(table(x_int))
x_int
 [0.5,4.5)  [4.5,8.5) [8.5,12.5) 
       0.4        0.4        0.2 
> cumsum(table(x_int))
 [0.5,4.5)  [4.5,8.5) [8.5,12.5) 
         6         12         15 
> cumsum(prop.table(table(x_int)))
 [0.5,4.5)  [4.5,8.5) [8.5,12.5) 
       0.4        0.8        1.0 
```


Ahora, vamos a construir un *data frame* que contenga la tabla de frecuencias de esta variable agrupada:
```
> intervalos=levels(x_int)
> marcas=MC  #Las hemos calculado en el Ejemplo 11.8
> f.abs=as.vector(table(x_int))
> f.abs.cum=cumsum(f.abs)
> f.rel=f.abs/length(x)
> f.rel.cum=cumsum(f.rel)
> tabla.frec=data.frame(intervalos, marcas, f.abs, f.abs.cum,
   f.rel, f.rel.cum)
> tabla.frec
  intervalos marcas f.abs f.abs.cum f.rel f.rel.cum
1  [0.5,4.5)    2.5     6         6   0.4       0.4
2  [4.5,8.5)    6.5     6        12   0.4       0.8
3 [8.5,12.5)   10.5     3        15   0.2       1.0
```
\end{ejemplo}

Podemos automatizar el cálculo de esta tabla de frecuencias, usando las dos funciones siguientes.
La primera sirve en el caso en que vayamos a tomar todas las clases de la misma amplitud;
sus parámetros son: $x$, el vector con los datos; $k$, el número de clases; $A$, su amplitud; y $p$, la precisión de los datos ($p=1$ si la precisión son unidades, $p=0.1$ si la precisión son décimas de unidad, etc.).\label{page:tabla_frec}
```
> Tabla_frec_agrup=function(x,k,A,p){
    L=min(x)-p/2+A*(0:k)
    x_int=cut(x, breaks=L, right=FALSE)
    intervalos=levels(x_int)
    marcas=(L[1]+L[2])/2+A*(0:(k-1))
    f.abs=as.vector(table(x_int))
    f.rel=f.abs/length(x)
    f.abs.cum=cumsum(f.abs)
    f.rel.cum=cumsum(f.rel)
    tabla_x=data.frame(intervalos, marcas, f.abs, f.abs.cum, f.rel, f.rel.cum)
    tabla_x
  }
```
Si de las clases conocemos de entrada sus extremos, podemos usar la función siguiente; 
sus parámetros son: $x$, el vector con los datos; $L$, el vector de extremos de clases; y $V$, un valor lógico, que ha de ser `TRUE` si queremos que el último intervalo sea cerrado, y `FALSE` en caso contrario. Impondremos además que el valor por defecto de $V$ sea `FALSE`. Para ello,  especificamos el parámetro mediante `V=FALSE` dentro de los paréntesis de `function`.
```
> Tabla_frec_agrup_L=function(x,L,V=FALSE){
    x_int=cut(x, breaks=L, right=FALSE, include.lowest=V)
    intervalos=levels(x_int)
    marcas=(L[1:(length(L)-1)]+L[2:length(L)])/2
    f.abs=as.vector(table(x_int))
    f.rel=f.abs/length(x)
    f.abs.cum=cumsum(f.abs)
    f.rel.cum=cumsum(f.rel)
    tabla_x=data.frame(intervalos, marcas, f.abs, f.abs.cum, f.rel, f.rel.cum)
    tabla_x
  }
```

\begin{ejemplo}
Volviendo al Ejemplo \@ref(ex:alerg), vamos a calcular, para el agrupamiento en 7 clases,  su tabla  de frecuencias en forma de *data frame* usando la función `Tabla\_{`frec\_{}agrup}. Ya sabemos que $k=7$ y $A=1.9$ y que los datos están expresados con una precisión de décimas de unidad. Obtendremos la Tabla \@ref(t:19.2).
```
> alergia=c(10.5,11.2,9.9,15.0,11.4,12.7,16.5,10.1,12.7,11.4,11.6,
  6.2,7.9,8.3,10.9,8.1,3.8,10.5,11.7,8.4,12.5,11.2,9.1,10.4,9.1,
  13.4,12.3,5.9,11.4,8.8,7.4,8.6,13.6,14.7,11.5,11.5,10.9,9.8,
  12.9,9.9)
> Tabla_frec_agrup(alergia, 7, 1.9, 0.1)
   intervalos marcas f.abs f.abs.cum f.rel f.rel.cum
1 [3.75,5.65)    4.7     1         1 0.025     0.025
2 [5.65,7.55)    6.6     3         4 0.075     0.100
3 [7.55,9.45)    8.5     8        12 0.200     0.300
4 [9.45,11.3)   10.4    11        23 0.275     0.575
5 [11.3,13.2)   12.3    12        35 0.300     0.875
6 [13.2,15.1)   14.2     4        39 0.100     0.975
7   [15.1,17)   16.1     1        40 0.025     1.000
```
Observad que, como advertíamos en su momento, ha escrito los extremos de los intervalos redondeados para que tengan como máximo 3 cifras. Esto se puede resolver usando en la función  `cut` el parámetro `dig.lab`, que permite especificar el número máximo de cifras significativas en los extremos de las etiquetas. 
```
> L=3.75+1.9*(0:7)
> L
[1]  3.75  5.65  7.55  9.45 11.35 13.25 15.15 17.05
> cut(alergia, breaks=L, right=FALSE)
 [1] [9.45,11.3) [9.45,11.3) [9.45,11.3) [13.2,15.1) [11.3,13.2)
 [6] [11.3,13.2) [15.1,17)   [9.45,11.3) [11.3,13.2) [11.3,13.2)
[11] [11.3,13.2) [5.65,7.55) [7.55,9.45) [7.55,9.45) [9.45,11.3)
[16] [7.55,9.45) [3.75,5.65) [9.45,11.3) [11.3,13.2) [7.55,9.45)
[21] [11.3,13.2) [9.45,11.3) [7.55,9.45) [9.45,11.3) [7.55,9.45)
[26] [13.2,15.1) [11.3,13.2) [5.65,7.55) [11.3,13.2) [7.55,9.45)
[31] [5.65,7.55) [7.55,9.45) [13.2,15.1) [13.2,15.1) [11.3,13.2)
[36] [11.3,13.2) [9.45,11.3) [9.45,11.3) [11.3,13.2) [9.45,11.3)
7 Levels: [3.75,5.65) [5.65,7.55) [7.55,9.45) ... [15.1,17)
> cut(alergia, breaks=L, right=FALSE, dig.lab=4)
 [1] [9.45,11.35)  [9.45,11.35)  [9.45,11.35)  [13.25,15.15)
 [5] [11.35,13.25) [11.35,13.25) [15.15,17.05) [9.45,11.35) 
 [9] [11.35,13.25) [11.35,13.25) [11.35,13.25) [5.65,7.55)  
[13] [7.55,9.45)   [7.55,9.45)   [9.45,11.35)  [7.55,9.45)  
[17] [3.75,5.65)   [9.45,11.35)  [11.35,13.25) [7.55,9.45)  
[21] [11.35,13.25) [9.45,11.35)  [7.55,9.45)   [9.45,11.35) 
[25] [7.55,9.45)   [13.25,15.15) [11.35,13.25) [5.65,7.55)  
[29] [11.35,13.25) [7.55,9.45)   [5.65,7.55)   [7.55,9.45)  
[33] [13.25,15.15) [13.25,15.15) [11.35,13.25) [11.35,13.25)
[37] [9.45,11.35)  [9.45,11.35)  [11.35,13.25) [9.45,11.35) 
7 Levels: [3.75,5.65) [5.65,7.55) [7.55,9.45) ... [15.15,17.05)
```


Por lo tanto, si quisiéramos permitir que los extremos de las etiquetas tuvieran más de 3 cifras significativas, bastaría redefinir la función `Tabla\_{`frec\_{}agrup} añadiéndole un parámetro `dig.lab`, que tuviera valor por defecto 3, y que se entrara a la función `cut`.
```
> Tabla_frec_agrup=function(x,k,A,p,dig.lab=3){
    L=min(x)-p/2+A*(0:k)
    x_int=cut(x, breaks=L, right=FALSE,dig.lab=dig.lab)
    intervalos=levels(x_int)
    marcas=(L[1]+L[2])/2+A*(0:(k-1))
    f.abs=as.vector(table(x_int))
    f.rel=f.abs/length(x)
    f.abs.cum=cumsum(f.abs)
    f.rel.cum=cumsum(f.rel)
    tabla_x=data.frame(intervalos, marcas, f.abs, f.abs.cum, f.rel, f.rel.cum)
    tabla_x
  }
```

\end{ejemplo}



\begin{ejemplo}
Vamos a calcular la tabla de frecuencias de los datos del Ejemplo \@ref(ex:fruitals) usando la función `Tabla\_{`frec\_{}agrup}. Ya habíamos decidido que $k=5$ y que en este caso la amplitud era $3$. Los datos estaban expresados en unidades. Obtendremos la Tabla \@ref(t:19.3).
```
> fruta=c(8,11,11,8,9,10,16,6,12,19,13,6,9,13,15,9,12,16,8,7,14,
  11,15,6,14,14,17,11,6,9,10,19,12,11,12,6,15,16,16,12,13,12,12,
  8,17,13,7,12,14,12)
> Tabla_frec_agrup(fruta, 5, 3, 1)
   intervalos marcas f.abs f.abs.cum f.rel f.rel.cum
1   [5.5,8.5)      7    11        11  0.22      0.22
2  [8.5,11.5)     10    11        22  0.22      0.44
3 [11.5,14.5)     13    17        39  0.34      0.78
4 [14.5,17.5)     16     9        48  0.18      0.96
5 [17.5,20.5)     19     2        50  0.04      1.00
```
\end{ejemplo}


\begin{ejemplo}
Vamos a volver a calcular la tabla de frecuencias de las notas del Ejemplo \@ref(ex:notes), usando  esta vez una de nuestras funciones: como las clases tienen amplitudes diferentes y la última es cerrada, usaremos la función `Tabla\_{`frec\_{}agrup\_{}L) con $V$ igual a `TRUE`. 
```
> Notas=c(5.1,1.1,6.4,5.3,10,5.4,1.9,3.1,5.1,0.8,9.6,6.6,7.0,9.6,
  10,1.2,4.2,8.8,2.4,1.8,5.6,6.8,6.7,2.2,8.6,3.9,5.6,5.9,8.4,4.9,
  0.7,8.2,3.7,4.8,5.8,3.3,9.7,7.8,9.3,4.5,6.2,3.9,4.7,6.2,6.3,9.4,
  9.3,2.3,8.5,1.4)
> Tabla_frec_agrup_L(Notas,c(0,5,7,9,10),TRUE)
  intervalos marcas f.abs f.abs.cum f.rel f.rel.cum
1      [0,5)    2.5    20        20  0.40      0.40
2      [5,7)    6.0    15        35  0.30      0.70
3      [7,9)    8.0     7        42  0.14      0.84
4     [9,10]    9.5     8        50  0.16      1.00
```
\end{ejemplo}

## Estadísticos para datos agrupados

 
Si tenemos una muestra de datos numéricos, para calcular sus estadísticos es conveniente usar los datos `brutos` , sin agrupar, ya que al agruparlos perdemos información; pero hay ocasiones en que los datos se obtienen ya agrupados: por ejemplo, mediante encuestas en las que se pida marcar un grupo de edad o una franja salarial en una lista de intervalos prefijados. En este tipo de situaciones, sigue siendo posible calcular los estadísticos de la muestra obtenida y usarlos como aproximaciones de los estadísticos de los datos <<reales>>, que en realidad no conocemos.

La media $\overline{x}$, la varianza $s^2$, la varianza muestral $\tilde{s}^2$, la desviación típica $s$ y la desviación típica muestral $\tilde{s}$\index{media!para datos agrupados}\index{desviación típica!para datos agrupados}\index{varianza!para datos agrupados} de un conjunto de datos agrupados se calculan con las mismas fórmulas que para los datos sin agrupar, excepto que sustituimos cada clase por su marca y la contamos con su frecuencia. Supongamos, en concreto, que tenemos $k$ clases, sus respectivas marcas son $X_1,\ldots,X_k$ y sus respectivas frecuencias absolutas son $n_1,\ldots,n_k$, de manera que la longitud total de la muestra es
 $n=\sum_{i=1}^k n_i$; entonces
$$
\overline{x}=\frac{\sum_{i=1}^k n_iX_i}{n},\
s^2=\frac{\sum_{i=1}^k n_iX^2_i}{n}-\overline{x}^2,\
\tilde{s}^2=\frac{n}{n-1}\cdot s^2,\
s=\sqrt{s^2},\
\tilde{s}=\sqrt{\widetilde{s}^2}.
$$
Por lo que se refiere  a la moda, se sustituye por el `intervalo modal` \index{intervalo modal}, que es la clase con mayor frecuencia (absoluta o relativa). Si se desea un valor numérico, se toma su marca de clase.



\begin{ejemplo}\label{ex:demografia}
Hemos descargado de la web del Instituto Nacional de Estadística^[  En concreto, del `url`  [http://www.ine.es/jaxi/tabla.do?path=/t20/e243/e01/a1981/l0/&file=01006.px&type=pcaxis&L=0](http://www.ine.es/jaxi/tabla.do?path=/t20/e243/e01/a1981/l0/&file=01006.px&type=pcaxis&L=0) .]  una tabla con la población censal española de 1981 por grupos quinquenales de edad  y la hemos guardado en el fichero en formato CSV

[http://aprender.uib.es/Rdir/cens81.csv](http://aprender.uib.es/Rdir/cens81.csv) 

Este fichero contiene dos columnas: una con los grupos de edad y otra con las poblaciones.
Vamos a usar estos datos agrupados para calcular algunos estadísticos de la distribución de la población española por edades en ese año.

Lo primero que hacemos es importarlo en un \df; para ello podemos usar la función `read.csv` o la función `read.table` con `header=TRUE` y \verb+sep=","+. Como la variable de grupos de edad tiene todos sus valores diferentes y no la usaremos para clasificar otros valores, la importaremos como un vector de palabras con
`stringsAsFactors=FALSE`. Como las etiquetas de los grupos de edad contienen la palabra ``años'', para garantizar que las eñes se importan de manera correcta es conveniente incluir \verb?encoding="utf8"?.
```
> tabla=read.csv("http://aprender.uib.es/Rdir/cens81.csv", 
  stringsAsFactors=FALSE, encoding="utf8")
> str(tabla)
'data.frame':	18 obs. of  2 variables:
 $ Edades   : chr "De 0 a 4 años" "De 5 a 9 años" "De 10 a 14 años" "De 15 a 19 años" ...
 $ Población: int 3075352 3308049 3302328 3263312 2942178 2537428 2455314 2245806 2056009 2361225 ...
> tabla
             Edades Población
1     De 0 a 4 años   3075352
2     De 5 a 9 años   3308049
3   De 10 a 14 años   3302328
4   De 15 a 19 años   3263312
5   De 20 a 24 años   2942178
6   De 25 a 29 años   2537428
7   De 30 a 34 años   2455314
8   De 35 a 39 años   2245806
9   De 40 a 44 años   2056009
10  De 45 a 49 años   2361225
11  De 50 a 54 años   2265091
12  De 55 a 59 años   2038002
13  De 60 a 64 años   1596543
14  De 65 a 69 años   1445606
15  De 70 a 74 años   1213807
16  De 75 a 79 años    852180
17  De 80 a 84 años    461960
18 De 85 y más años    263171
```
Hay que tener en cuenta que, en esta tabla, la clase <<De 0 a 4 años>> representa el intervalo de edades $[0,5)$, la clase <<De 5 a 9 años>> representa el intervalo de edades $[5,10)$, y así sucesivamente.

Para calcular las diferentes medidas estadísticas, hemos de asignar a cada grupo de edades un valor numérico como marca de clase: para los 17 primeros grupos, de amplitud 5, tomaremos su edad media, y para el último, de amplitud indeterminada, tomaremos 90 como marca. Añadiremos estas marcas al *data frame* anterior como una nueva variable.
```
> tabla$marcas=c(2.5+5*(0:16),90)
> head(tabla)
           Edades Población marcas
1   De 0 a 4 años   3075352    2.5
2   De 5 a 9 años   3308049    7.5
3 De 10 a 14 años   3302328   12.5
4 De 15 a 19 años   3263312   17.5
5 De 20 a 24 años   2942178   22.5
6 De 25 a 29 años   2537428   27.5
```
Ahora ya podemos calcular los estadísticos:
```
> Total=sum(tabla$Población)  #Población total
> Total
[1] 37683361
> Edad.media=sum(tabla$Población*tabla$marcas)/Total  #Media
> Edad.media 
[1] 33.95994
> Edad.varianza=sum(tabla$Población*tabla$marcas^2)/Total 
    -Edad.media^2 #Varianza
> Edad.varianza
[1] 505.2943
> Edad.desv.tip=sqrt(Edad.varianza)  #Desviación típica
> Edad.desv.tip
[1] 22.47875
> Int.modal=tabla$Edades[which(tabla$Población
    ==max(tabla$Población))]  #Intervalo modal
> Int.modal
[1] "De 5 a 9 años"
```


Por lo tanto, con los datos de los que disponemos, podemos afirmar que la edad media de los españoles censados en 1981 era de unos 34 años, con una desviación típica de unos 22.5 años, y que el grupo de edad más numeroso era el de los niños y niñas de 5 a 9 años.
\end{ejemplo}

Se han propuesto muchos métodos para aproximar la mediana y los otros cuantiles de una variable cuantitativa agrupada a partir de las tablas de frecuencias de sus clases. Aquí explicaremos una de las más sencillas, y la ilustraremos con el ejemplo anterior; para empezar, vamos a completar el *data frame* con las frecuencias absolutas acumuladas, relativas y relativas acumuladas:
```
> tabla$FA.acum=cumsum(tabla$Población)
> tabla$FR=round(tabla$Población/Total, 3)
> tabla$FR.acum=round(tabla$FA.acum/Total, 3)
> tabla
             Edades Población marcas  FA.acum    FR FR.acum
1     De 0 a 4 años   3075352    2.5  3075352 0.082   0.082
2     De 5 a 9 años   3308049    7.5  6383401 0.088   0.169
3   De 10 a 14 años   3302328   12.5  9685729 0.088   0.257
4   De 15 a 19 años   3263312   17.5 12949041 0.087   0.344
5   De 20 a 24 años   2942178   22.5 15891219 0.078   0.422
6   De 25 a 29 años   2537428   27.5 18428647 0.067   0.489
7   De 30 a 34 años   2455314   32.5 20883961 0.065   0.554
8   De 35 a 39 años   2245806   37.5 23129767 0.060   0.614
9   De 40 a 44 años   2056009   42.5 25185776 0.055   0.668
10  De 45 a 49 años   2361225   47.5 27547001 0.063   0.731
11  De 50 a 54 años   2265091   52.5 29812092 0.060   0.791
12  De 55 a 59 años   2038002   57.5 31850094 0.054   0.845
13  De 60 a 64 años   1596543   62.5 33446637 0.042   0.888
14  De 65 a 69 años   1445606   67.5 34892243 0.038   0.926
15  De 70 a 74 años   1213807   72.5 36106050 0.032   0.958
16  De 75 a 79 años    852180   77.5 36958230 0.023   0.981
17  De 80 a 84 años    461960   82.5 37420190 0.012   0.993
18 De 85 y más años    263171   90.0 37683361 0.007   1.000
```


Llamaremos `intervalo crítico para la mediana` \index{intervalo crítico} al primer intervalo donde la frecuencia  relativa acumulada sea mayor o igual que $0.5$. 
En este caso, el intervalo crítico es la clase <<De 30 a 34 años>>, es decir, $[30,35)$.

Sean $[L_c, L_{c+1})$ este intervalo crítico; $N_{c-1}$, la frecuencia absoluta acumulada del intervalo anterior al crítico (si el intervalo crítico es el primero, tomamos $N_{c-1}=0$); $n_c$, la frecuencia absoluta del intervalo crítico; $A_c=L_{c+1}-L_c$, su amplitud; y $n$, el número total de datos.
Entonces, la fórmula siguiente nos da una `aproximación`  $M$ para la mediana\index{mediana!para datos agrupados} de los datos <<reales>> a partir de los datos agrupados:$$
M=L_{c}+A_c\cdot \frac{\frac{n}{2}- N_{c-1}}{n_c}.
$$
La justificación de esta fórmula es la siguiente: lo que hacemos es unir con una recta las frecuencias absolutas acumuladas en $L_c$ y en $L_{c+1}$, y aproximar  la mediana por medio de la abscisa del punto sobre esta recta cuya ordenada es $n/2$ (véase la Figura  \@ref(fig:median)).
\begin{figure}[htb]
\begin{center}
 \begin{picture}(200,170)(-40,-40)
\put(-20,0){\line(1,0){180}} % l'eix x
\put(0,-20){\line(0,1){140}} % l'eix y
      
\multiput(30,0)(0,2){15}{$\scriptstyle\cdot$}
\multiput(150,0)(0,2){55}{$\scriptstyle\cdot$}
\multiput(90,0)(0,2){35}{$\scriptstyle \cdot$}
\multiput(0,29)(2,0){15}{$\scriptstyle\cdot$}
\multiput(0,109)(2,0){75}{$\scriptstyle\cdot$}
\multiput(0,69)(2,0){45}{$\scriptstyle\cdot$}

\put(28,-10){\small $L_c$}
\put(146,-10){\small $L_{c+1}$}
\put(88,-10){\small $M$}
\put(-24,28){\small $N_{c-1}$}
\put(-24,68){\small $n/2$}
\put(-24,108){\small $N_c$}
\thicklines
    \put(30,30){\line(3,2){120}}
      \end{picture}
\end{center}
\caption{Aproximación lineal de la mediana a partir de las frecuencias de los datos agrupados.}\label{fig:median}
\end{figure}

En nuestro ejemplo, $n=37683361$, $L_c=30$, $A_c=5$, $N_{c-1}=18428647$ y $n_c=2455314$; por lo tanto,
$$
M=30+5\cdot\frac{0.5\cdot 37683361-18428647}{2455314}= 30.8411.
$$
Esto nos permite  estimar que, en 1981, aproximadamente la mitad de la población española tenía menos de 30.84 años.


En general, este método permite aproximar el cuantil $Q_p$ de los datos <<reales>> a partir de los datos agrupados\index{quantil!para datos agrupados} con la fórmula siguiente:
$$
Q_{p} =L_c + A_c \cdot \frac{p\cdot n-N_{c-1}}{n_c},
$$
donde ahora el intervalo crítico $[L_c,L_{c+1})$ es el primer intervalo con frecuencia relativa acumulada mayor o igual que $p$
y el resto de valores se definen relativos a este intervalo crítico.
De este modo,  en nuestro ejemplo, el intervalo crítico para $Q_{0.25}$ es <<De 10 a 14 años>>, y en este caso $L_c=10$, $A_c=5$, $N_{c-1}=6383401$ y $n_c=3302328$, por lo que
$$
Q_{0.25}=10+5\cdot\dfrac{0.25\cdot 37683361-6383401}{3302328}= 14.59894.
$$
En cuanto al tercer cuantil, $Q_{0.75}$, el intervalo crítico es <<De 50 a 54 años>>, por lo que $L_c=50$, $A_c=5$, $N_{c-1}=27547001$ y $n_c=2265091$, y, por consiguiente,
$$
Q_{0.75}=50+5\cdot\dfrac{0.75\cdot 37683361-27547001}{2265091}=51.57945.
$$



## Histogramas
\label{sec:hist}




 Los datos agrupados se describen gráficamente por medio de unos diagramas de barras específicos llamados `histogramas` \index{histograma}, donde se dibuja sobre cada clase una barra cuya área  representa la frecuencia de dicha clase. Veamos un ejemplo.

\begin{ejemplo}\label{ex:11.15}
Supongamos que tenemos los datos
$$
10,9,8,1,9,8,2,5,7,3,5,6,1,3,7,8,9,8,5,6,2,4,1,3,5,4,6,7,10,8,5,4,2,7,8
$$
y que los agrupamos en los intervalos
$$
[0.5,4), [4,7.5), [7.5,11).
$$
Calculemos las frecuencias absolutas de estas clases:
```
> x=c(10,9,8,1,9,8,2,5,7,3,5,6,1,3,7,8,9,8,5,6,2,4,1,3,5,4,6,7,
  10,8,5,4,2,7,8)
> L=c(0.5,4,7.5,11)
> x_int=cut(x,breaks=L,right=FALSE)
> table(x_int)
x_int
 [0.5,4)  [4,7.5) [7.5,11) 
       9       15       11 
```

La Figura \@ref(fig:20.1).(a) muestra un histograma de las frecuencias absolutas de estos datos con este agrupamiento.
Podéis comprobar que el producto de la base por la altura de cada barra es igual a la frecuencia de la clase correspondiente,  que hemos escrito dentro de la barra para facilitar su lectura. Como todas las clases tienen la misma amplitud,   las alturas de estas barras son proporcionales a las frecuencias de sus clases (son estas frecuencias divididas por la amplitud) y las representan correctamente, de forma que habríamos podido marcar sin ningún problema las frecuencias sobre el eje vertical, como hemos hecho en la Figura \@ref(fig:20.1).(b).

\begin{figure}[htb]
\abovecaptionskip=-1ex
\begin{center}
\begin{tabular}{cc}
\includegraphics[width=0.45\linewidth]{histx1.jpg} &
\includegraphics[width=0.45\linewidth]{histx3.jpg}\\[-0.5cm]
(a) & (b)
\end{tabular}
\end{center} 
\caption{Histogramas del Ejemplo \@ref(ex:11.15): (a) Histograma real; (b) Histograma con las frecuencias marcadas en el eje de ordenadas.\label{fig:20.1})
\end{figure}

Pero si las amplitudes de las clases no son iguales, las alturas de las barras en un histograma no representan correctamente las frecuencias de las clases. A modo de ejemplo, supongamos que los datos anteriores son notas y que  las agrupamos en suspensos, aprobados, notables y sobresalientes:
$$
[0,5),  [5,7), [7,9), [9,10].
$$
Recordad que, en este caso, el último intervalo ha de ser cerrado.
```
> L2=c(0,5,7,9,10)
> x_int2=cut(x,breaks=L2,right=FALSE,include.lowest=TRUE) 
> table(x_int2)
x_int2
   [0,5)    [5,7)    [7,9)   [9,10] 
      12        8       10        5 
```
En la Figura \@ref(fig:20.3) podéis ver un histograma de frecuencias absolutas de estos datos con este agrupamiento. Comprobaréis que las alturas de las barras son las necesarias para que el área de cada barra sea igual a la frecuencia de la clase correspondiente; como las bases son de amplitudes diferentes, estas alturas no son proporcionales a las frecuencias de las clases, por lo que no tiene sentido marcar las frecuencias en el eje vertical; ¡el 12 de la primera barra estaría por debajo del 5 de la última!
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histx2.jpg}
\end{center} 
\caption{Histograma del Ejemplo \@ref(ex:11.15) con clases de diferentes amplitudes.\label{fig:20.3})
\end{figure}


También se usan histogramas para representar frecuencias acumuladas de datos agrupados; en este caso, y a diferencia del anterior, las alturas representan las frecuencias independientemente de la base. El motivo es que estas alturas tienen que ir creciendo. Así, los histogramas de frecuencias absolutas acumuladas de nuestros datos para los dos agrupamientos anteriores serían los mostrados en la Figura \@ref(fig:20.4).
\end{ejemplo}
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histx4.pdf}\
\includegraphics[width=0.45\linewidth]{histx5.pdf}
\end{center} 
\caption{Histogramas de frecuencias acumuladas de los datos del Ejemplo \@ref(ex:11.15) para dos agrupamientos diferentes.\label{fig:20.4})
\end{figure}



La Figura \@ref(fig:20.5) muestra la estructura básica de dos histogramas, el izquierdo para las frecuencias absolutas y el derecho para las frecuencias absolutas acumuladas.
En un histograma, el eje de las abscisas representa los datos, donde marcamos los extremos de las clases, y se dibuja una barra sobre cada clase; esta barra tiene un significado diferente según el tipo de histograma, pero en general representa la frecuencia de su clase:

* En los histogramas de frecuencias absolutas, la altura de cada barra  es la necesaria para que el área de la barra sea igual a la frecuencia absoluta de la clase. Si todas las clases tienen la misma amplitud, esto implica que las alturas de las barras sean proporcionales a las frecuencias de las clases  y que, por tanto, las representen bien; si las clases no son todas de la misma amplitud, estas alturas ya no representan las frecuencias. Tanto en un caso como en otro, para facilitar la comprensión del histograma es conveniente indicar de alguna manera las frecuencias  que representan las barras; este consejo se extiende a los histogramas de frecuencias relativas.

* En los histogramas de frecuencias relativas, la altura de cada barra es la necesaria para que el área de la barra sea igual a la frecuencia relativa de la clase; en particular, la suma de las áreas de las barras ha de ser igual a 1. En este contexto, llamamos a las alturas de las barras `densidades`. 

* En los histogramas de frecuencias acumuladas (absolutas o relativas), las alturas de las barras son iguales a las frecuencias acumuladas de la clases, independientemente de su amplitud.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histgen1.pdf}\ 
\includegraphics[width=0.45\linewidth]{histgen2.pdf}
\end{center} 
\caption{Estructura básica de un histograma de frecuencias absolutas (izquierda) y absolutas acumuladas (derecha).\label{fig:20.5}}
\end{figure}


De este modo, en el histograma de la izquierda de la Figura \@ref(fig:20.5), el área de la barra sobre cada clase $[L_j,L_{j+1})$ es igual  a la frecuencia absoluta $n_j$ de esta clase; es decir, el producto de la altura $h_j$ de la barra por la amplitud $L_{j+1}-L_j$ es lo que representa la frecuencia, no la altura de la barra. En cambio, en el histograma de la derecha, la barra sobre cada clase $[L_j,L_{j+1))$ tiene una altura igual a la frecuencia absoluta acumulada $N_j$ de esta clase.


Una observación: en la práctica, no es conveniente que en un histograma aparezcan clases con frecuencia nula, excepto cuando represente  dos poblaciones muy diferentes y separadas, sin individuos <<intermedios>>. Si aparecen clases vacías, conviene usar un número menor de clases o unir las clases vacías con alguna de sus adyacentes, aunque de esta última manera rompamos la regla básica de usar clases de la misma amplitud.

La función para dibujar histogramas con `R` es `hist`. Su estructura básica es\indR{hist}

`hist(`$x$`, breaks=\ldots, freq=\ldots, right=\ldots, \ldots)`,

donde:

* $x$ es el vector formado por los datos que queremos representar.

* El parámetro `breaks`\indRp{hist}{breaks} es similar al de la función `cut`: con él podemos establecer los valores de los extremos de los intervalos o el número de intervalos; incluso se puede indicar, entre comillas, el método para calcular el número de clases: `"Scott"`, `"Sturges"`, etc. Tanto si entráis el número de clases como el método para calcularlo, `R` lo considerará sólo como una sugerencia, por lo que no siempre obtendréis el número deseado de intervalos;  además, el método que usa para calcular los intervalos es diferente del usado en `cut`; por todo ello, os recomendamos que, si queréis tener algún control sobre la producción del  histograma,  especifiquéis  los extremos.

* El parámetro `freq`\indRp{hist}{freq} es un parámetro lógico: igualado a `TRUE` (que es el valor por defecto, por lo que en este caso no hace falta incluirlo), produce el histograma de frecuencias absolutas si los intervalos son todos de la misma longitud, y el de frecuencias relativas en caso contrario; igualado a `FALSE`, produce siempre el de frecuencias relativas.

* El parámetro `right`\indRp{hist}{right=FALSE} funciona como en `cut`: si queremos nuestros intervalos cerrados a la izquierda y abiertos a la derecha, tenemos que especificar `right=FALSE`.

* Como ya pasaba en `cut`, se tiene que añadir `include.lowest=TRUE` si se ha entrado `right=FALSE` y  el máximo del conjunto de datos coincide con el extremo superior del último intervalo.

* Aparte, podéis usar los parámetros usuales de la función `plot` para poner un título, cambiar las etiquetas de los ejes, colorear las barras, etc.  Recordad también el parámetro `plot`, que ha salido hace unas páginas: igualado a `FALSE`, calcula el histograma, pero no lo dibuja.

Podéis consultar el resto de parámetros en la Ayuda de `hist`. 

  
\begin{ejemplo}\label{ex:frut-hist}
Seguimos con el Ejemplo \@ref(ex:fruitals), sobre árboles frutales afectados por la mosca de la fruta; 
vamos a producir el histograma por defecto de los datos para dos agrupamientos diferentes: el que dábamos en  dicho ejemplo, en tres clases de amplitud 3, y el que los agrupa en las clases
$$
[5,8), [8,12),[12,14), [14,20),
$$
de amplitudes diferentes. Los resultados son los de la Figura \@ref(fig:20.6):
```
> fruta=c(8,11,11,8,9,10,16,6,12,19,13,6,9,13,15,9,12,16,8,7, 
  14,11,15,6,14,14,17,11,6,9,10,19,12,11,12, 6,15,16,16,12,
  13,12,12,8,17,13,7,12,14,12)
> L1=5.5+3*(0:5)
> hist(fruta, breaks= L1, right=FALSE)
> L2=c(5,8,12,14,20)
> hist(fruta, breaks= L2, right=FALSE)
```
\end{ejemplo}
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histfruita1.pdf}\
\includegraphics[width=0.45\linewidth]{histfruitax.pdf}
\end{center} 
\caption{Dos histogramas de los datos del Ejemplo \@ref(ex:frut-hist).\label{fig:20.6})
\end{figure}

Como podéis ver, `hist`  ha dibujado los ejes y las barras, pero en el eje horizontal no ha marcado los extremos de las clases; por lo que refiere al eje vertical, en el histograma con las clases de las mismas amplitudes, ha marcado las frecuencias absolutas, pero en el otro ha marcado las densidades, lo que dificulta su comprensión.
Además, fijaos en los títulos: `hist` titula por defecto los histogramas  <<Histogram of>> seguido del nombre del vector de datos, lo que no es muy adecuado si no estáis escribiendo en inglés.

Por suerte, el resultado de `hist` contiene mucha información escondida, que podemos usar para mejorar estos histogramas. 
```
> h=hist(fruta, breaks=L1, right=FALSE, plot=FALSE) #Para que no lo dibuje; sería el histograma de la izquierda de la Fig. 10.7
> h
$breaks
[1]  5.5  8.5 11.5 14.5 17.5 20.5

$counts
[1] 11 11 17  9  2

$density
[1] 0.07333333 0.07333333 0.11333333 0.06000000 0.01333333

$mids
[1]  7 10 13 16 19

$xname
[1] "fruta"

$equidist
[1] TRUE

attr(,"class")
[1] "histogram"
```
En concreto:

* La componente \verb?breaks?\indRp{hist}{\$breaks} contiene el vector de extremos de los intervalos: $L_0,L_1,\ldots,L_k$, $L_{k+1}$.

* La componente \verb?mids?\indRp{hist}{\$mids} contiene el vector de puntos medios de los intervalos (que usamos como marcas de clase): $X_1,X_2, \ldots,X_k$.

* La componente \verb?counts?\indRp{hist}{\$counts} contiene el vector de frecuencias absolutas de los intervalos:
$n_1,n_2,\ldots,n_k$.

* La componente \verb?density?\indRp{hist}{\$density} contiene el vector de las densidades de los intervalos. 
Estas densidades son las alturas de las barras del histograma de frecuencias relativas; por lo tanto, la densidad de cada intervalo es su frecuencia relativa dividida por su amplitud.

Podemos servirnos de  toda esta información para mejorar el histograma producido por defecto.

Por ejemplo, para histogramas de frecuencias absolutas, podéis usar la función siguiente; sus parámetros son: $x$, el vector de datos, y $L$, el vector de extremos de los intervalos.
```
> hist_abs=function(x,L){
h=hist(x, breaks=L, right=FALSE, freq=FALSE,
    axes=FALSE, col="lightgray",
    main="Histograma de frecuencias absolutas",
    xlab="Intervalos y marcas de clase",
    ylab="Frecuencias absolutas")
axis(1, at=L)
text(h$mids, h$density/2, labels=h$counts, col="blue")
}
```


Si la aplicamos a los valores de `fruta` y `L1` anteriores,
```
> hist_abs(fruta, L1)
```
produce la Figura \@ref(fig:20.7).
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histfruita3.pdf}
\end{center} 
\caption{Histograma de frecuencias absolutas producido con la función `hist\_{`abs}.\label{fig:20.7}}
\end{figure}

Algunos comentarios\indRp{hist}{main} sobre la manera como hemos definido esta función, para que la podáis modificar:

* El parámetro `axes=FALSE` especifica que no se dibujen los ejes; alternativamente, hubiéramos podido usar  los dos parámetros \verb?xaxt="n"? e \verb?yaxt="n"?\indRp{hist}{yaxt}\indRp{hist}{xaxt}, que especifican, respectivamente,  que no se dibuje el eje de abscisas y que no se dibuje el eje de ordenadas, y que són más útiles cuando se quiere eliminar un solo eje, como haremos en los histogramas de frecuencias relativas. 

* La instrucción `axis(`$i$`, at=\ldots)`\indR{axis}\indRp{axis}{at} dibuja el eje correspondiente al valor de $i$ ($i=1$, el de abscisas; $i=2$, el de ordenadas) con marcas en los lugares indicados por el vector definido mediante `at`; por lo tanto, la instrucción
\verb?axis(1, at=L)? 
añade un eje de abscisas (que no habíamos dibujado) con marcas en los extremos de las clases.

* Con `freq=FALSE` en realidad hemos dibujado un histograma de frecuencias relativas, pero como hemos omitido el eje de ordenadas, tanto da; en cambio, esto nos ha servido para poder añadir,  con la función `text`, la frecuencia absoluta de cada clase, sobre el punto medio de su intervalo (los valores \verb?h$mids?) y a media altura de su barra correspondiente (con `freq=FALSE`, estas alturas son siempre los valores \verb?h$density?). 

Naturalmente, podéis adaptar a vuestro gusto esta función `hist\_abs` o las otras que daremos: podéis cambiar el título, cambiar los colores, etc. A modo de ejemplo,  si usáis muchas clases, es probable que las barras queden muy estrechas y no tenga sentido escribir en su interior las frecuencias absolutas. Si todas las clases son de la misma amplitud, podéis representar estas frecuencias en el eje de ordenadas: para ello, en la definición de `hist\_{`abs} basta con sustituir, en la función `hist`,
`freq=FALSE` por `freq=TRUE`
y `axes=FALSE` por `xaxt="n"` (y así dibujará el eje de ordenadas con marcas que representen frecuencias absolutas),  y eliminar la instrucción `text`. 
```
> hist_abs2=function(x,L){
h=hist(x, breaks=L, right=FALSE, freq=TRUE,
    xaxt="n", col="lightgray",
    main="Histograma de frecuencias absolutas",
    xlab="Intervalos y marcas de clase",
    ylab="Frecuencias absolutas")
axis(1, at=L)
}
```


Otra posibilidad para indicar las frecuencias absolutas de las barras es usar la función `rug`, que permite añadir al histograma una <<alfombra>> con marcas en todos los valores del vector; el grosor de cada marca es proporcional a la frecuencia del valor que representa. 
Así, por ejemplo,
```
> hist_abs(fruta, L1)
> rug(fruta)
```
produce el gráfico de la izquierda de la Figura \@ref(fig:20.7rug).
Observaréis que, en este histograma, es difícil deducir de la <<alfombra>> que la tercera clase tiene una frecuencia mayor que las dos primeras debido a un mayor número de empates. Si encontráis difícil ver los empates, la Ayuda de `rug` os recomienda combinar `rug` con la función `jitter`, que añade un poco de <<ruido>> a los datos de un vector, deshaciendo empates. Así,
```
> hist_abs(fruta, L1)
> rug(jitter(fruta))
```
produce el gráfico de la derecha de la Figura \@ref(fig:20.7rug).


\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histfruita3rug1.pdf}\
\includegraphics[width=0.45\linewidth]{histfruita3rug2.pdf}

\end{center} 
\caption{Histogramas de frecuencias absolutas con los valores representados en una <<alfombra>>.\label{fig:20.7rug}}
\end{figure}


Para dibujar histogramas de frecuencias absolutas acumuladas, podéis usar la  función:
```
> hist_abs.cum=function(x,L){
h=hist(x, breaks=L, right=FALSE, plot=FALSE)
h$density=cumsum(h$density)
plot(h, freq=FALSE, axes=FALSE, col="lightgray",
  main="Histograma de frecuencias absolutas acumuladas", 
  xlab="Intervalos", ylab="Frec. absolutas acumuladas")
axis(1, at=L)
text(h$mids, h$density/2, labels=cumsum(h$counts), col="blue")
}
```


Aplicándola a los valores de `fruta` y `L1` anteriores,
```
> hist_abs.cum(fruta,L1)
```
obtenemos la Figura \@ref(fig:20.9).
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histfruita5.pdf}
\end{center} 
\caption{Histograma de frecuencias absolutas acumuladas producido con la función `hist\_{`abs.cum}.\label{fig:20.9}}
\end{figure}

Con esta función producimos el histograma <<básico>> de los datos, sin dibujarlo, y a continuación
modificamos su componente `density` para que contenga las sumas acumuladas de la componente `density` del histograma original. Luego dibujamos el nuevo histograma resultante, aplicándole la función `plot`; los parámetros del gráfico se tienen que añadir a este `plot`, no al histograma original. Finalmente, completamos el gráfico añadiendo el eje de abscisas y las frecuencias acumuladas en el interior de las barras.

Pasemos a los histogramas de frecuencias relativas. En ellos, es costumbre superponer una curva que estime la `densidad`  de la
distribución de la variable definida por la característica que medimos. 

La densidad de una variable es una curva tal que el área comprendida entre el eje de abscisas y la curva sobre un intervalo es igual a la fracción de individuos de la población que caen dentro de ese intervalo. Visualmente, 
imaginemos que vamos aumentando el tamaño de la muestra  y que agrupamos los datos
en una familia cada vez mayor de intervalos;  si el rango de los datos se mantiene más o menos constante, la amplitud de los
intervalos del histograma irá decreciendo; cuando el tamaño del conjunto de datos tiende a infinito, 
los intervalos tienden a ser puntos y, las barras, a ser líneas verticales. Los extremos superiores de estas líneas dibujarán una curva: ésta es la densidad de la variable.

La densidad más famosa es la llamada `campana de Gauss` , y  corresponde a una variable que tenga una `distribución normal`  
(véase la Figura \@ref(fig:norm)). Hay muchas variables que suelen tener distribuciones  normales: características morfológicas y fisiológicas de individuos de una especie, calificaciones en exámenes, errores de medida\ldots\ 
En cada caso, la forma concreta de la campana depende de dos parámetros: el valor medio $\mu$ de la variable y su desviación típica $\sigma$.
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.6\linewidth]{normal}
\end{center} 
\caption{Campana de Gauss.\label{fig:norm}}
\end{figure}



Hay muchos métodos  para estimar la densidad de la distribución a partir de una muestra; la manera más sencilla de hacerlo con `R` es usar la función `density`. Cuando aplicamos esta función, con sus parámetros por defecto, a un vector númerico, produce una `list` que incluye los vectores `x` e `y` de primeras y segundas coordenadas de una secuencia de puntos $(x,y)$ sobre la curva densidad estimada.^[  Explicar el método que usa esta función `density` para estimar la densidad cae fuera del nivel de este curso. Los curiosos pueden consultar el artículo de la *Wikipedia* [http://en.wikipedia.org/wiki/Kernel_density_estimation](http://en.wikipedia.org/wiki/Kernel_density_estimation)  y luego la Ayuda de la función.]  Aplicando `plot`, con \verb?type="l"?, o `lines` (si hay que añadirla a un gráfico anterior) al resultado de `density`, obtenemos el gráfico de esta curva.
```
> str(density(fruta))
List of 7
 $ x        : num [1:512] 1.69 1.73 1.78 1.82 1.86 ...
 $ y        : num [1:512] 0.000326 0.000356 0.000388 0.000424 0.000462 ...
 $ bw       : num 1.44
 $ n        : int 50
 $ call     : language density.default(x = fruta)
 $ data.name: chr "fruta"
 $ has.na   : logi FALSE
 - attr(*, "class")= chr "density"
> plot(density(fruta), type="l", xlab="Número de árboles",
  ylab="Densidad", main="Densidad de la variable \"fruta\"")
```
La instrucción del `plot` produce la Figura \@ref(fig:dens)
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{densfruta.pdf}
\end{center} 
\caption{Densidad estimada de los datos del Ejemplo  \@ref(ex:fruitals).\label{fig:dens})
\end{figure}


Para dibujar un histograma de frecuencias relativas más informativo que el que produce `R` por defecto y que incluya la estimación de la densidad, podéis usar la función siguiente:
```
> hist_rel=function(x,L){
h=hist(x, breaks=L, right=FALSE, plot=FALSE)
t=round(1.1*max(max(density(x)[[2]]),h$density),2)
plot(h, freq=FALSE, col="lightgray",
 main="Histograma de frec. relativas y curva de densidad estimada",
 xaxt="n", ylim=c(0,t), xlab="Intervalos", ylab="Densidades")
axis(1, at=L)
text(h$mids, h$density/2,
  labels=round(h$counts/length(x),2), col="blue")
lines(density(x), col="red", lwd=2)
}
```


Si la aplicamos a los valores de `fruta` y `L1` anteriores, 
```
> hist_rel(fruta, L1)
```
obtenemos la Figura  \@ref(fig:20.8).
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histfruita4.pdf}
\end{center} 
\caption{Histograma de frecuencias relativas producido con la función `hist\_{`rel}.\label{fig:20.8}}
\end{figure}



En los histogramas de frecuencias relativas acumuladas, se puede superponer una curva que estime la `función de distribución`  de la variable definida por la característica que medimos; esta función de distribución de una variable nos da, en cada punto, la fracción de individuos de la población que caen a la izquierda de este punto, es decir, la frecuencia relativa acumulada por la variable sobre la población en ese punto. En general, la función de distribución en un valor determinado es igual al área de la región, a la izquierda de la vertical definida por dicho valor, delimitada por la función de densidad y el eje de abscisas.

Para dibujar un histograma de frecuencias relativas acumuladas que incluya la función de distribución estimada, podéis usar la función siguiente:

```
> hist_rel.cum=function(x,L){
h=hist(x, breaks=L, right=FALSE, plot=FALSE)
h$density=cumsum(h$counts)/length(x) #calculamos las f. relativas
plot(h, freq=FALSE, main="Histograma de frec. rel. acumuladas\n y 
  curva de distribución estimada", xaxt="n", col="lightgray",
  xlab="Intervalos", ylab="Frec. relativas acumuladas")
axis(1, at=L)
text(h$mids, h$density/2,
  labels=round(h$density,2), col="blue")
dens.x=density(x)
dens.x$y=cumsum(dens.x$y)*(dens.x$x[2]-dens.x$x[1]) 
lines(dens.x,col="red",lwd=2)
}
```


Aplicándola a los valores de `fruta` y `L1` anteriores,
```
> hist_rel.cum(fruta,L1)
```
obtenemos la Figura \@ref(fig:20.10).

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histfruita7.pdf}
\end{center} 
\caption{Histograma de frecuencias relativas acumuladas producido con la función `hist\_{`rel.cum}.\label{fig:20.10}}
\end{figure}

Veamos otro ejemplo.

\begin{ejemplo}
Consideremos los datos de tiempos de inicio de reacción alérgica a una picadura del Ejemplo \@ref(ex:alerg). Queremos dibujar los histogramas de frecuencias relativas y relativas acumuladas para el agrupamiento según la regla de Sturges. Por completitud, empezaremos de cero.


```
> alergia=c(10.5,11.2,9.9,15.0,11.4,12.7,16.5,10.1,12.7,11.4,11.6,
  6.2,7.9,8.3,10.9,8.1,3.8,10.5,11.7,8.4,12.5,11.2,9.1,10.4,9.1,
  13.4,12.3,5.9,11.4,8.8,7.4,8.6,13.6,14.7,11.5,11.5,10.9,9.8,
  12.9,9.9)
> nclass.Sturges(alergia)
[1] 7
> diff(range(alergia))
[1] 12.7
> 12.7/7
[1] 1.814286
> #Tomamos A=1.9
> L.al=min(alergia)-0.05+1.9*(0:7) 
> L.al
[1]  3.75  5.65  7.55  9.45 11.35 13.25 15.15 17.05
> #Usamos las funciones que hemos definido 
> hist_rel(alergia, L.al)
> hist_rel.cum(alergia, L.al)
```
y obtenemos los histogramas de la Figura \@ref(fig:20.11).
\end{ejemplo}
\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histalergia1.pdf}\
\includegraphics[width=0.45\linewidth]{histalergia2.pdf}
\end{center} 
\caption{Histogramas de frecuencias relativas de los datos del Ejemplo \@ref(ex:alerg}.\label{fig:20.11})
\end{figure}

Veamos un último ejemplo.

\begin{ejemplo}\label{ex:crab}
El fichero `datacrab.txt`, del cual hemos guardado una copia en 

[http://aprender.uib.es/Rdir/datacrab.txt](http://aprender.uib.es/Rdir/datacrab.txt) 

recoge los datos sobre hembras de límula del Atlántico %(Figura \@ref(fig:20.12))
analizadas en el artículo <<Satellite male groups in horseshoe crabs, *Limulus polyphemus*>> de H. J. Brockmann (`Ethology`  102 (1996), pp. 1--21). Una de las variables que incluye esta tabla de datos es la amplitud, *width*, de los especímenes analizados. 
Vamos a dibujar un histograma de las frecuencias relativas de estas amplitudes que incluya su curva de densidad estimada; para variar, agruparemos estas amplitudes usando la regla de Scott.  Aprovecharemos para calcular la tabla de frecuencias de este agrupamiento.

Empezamos importando esta tabla en un *data frame* y definiendo un vector con la variable correspondiente a la amplitud. 
```
> crab=read.table("http://aprender.uib.es/Rdir/datacrab.txt",
  header=TRUE)
> str(crab)
'data.frame':	173 obs. of  5 variables:
 $ input      : int  3 4 2 4 4 3 2 4 3 4 ...
 $ color.spine: int  3 3 1 3 3 3 1 2 1 3 ...
 $ width      : num  28.3 22.5 26 24.8 26 23.8 26.5 24.7 23.7 25.6 ...
 $ satell     : int  8 0 9 0 4 0 0 0 0 0 ...
 $ weight     : int  3050 1550 2300 2100 2600 2100 2350 1900 1950 2150 ...
> crw=crab$width
```
Observamos que las amplitudes están expresadas con una precisión de décimas de unidad.
A continuación, determinamos el número de clases, amplitud, etc. del agrupamiento de este vector `crw` siguiendo la regla de Scott.
```
> nclass.scott(crw)
[1] 10
> diff(range(crw))/10
[1] 1.25
> #Tomaremos A=1.3
> L.cr=min(crw)-0.05+1.3*(0:10)
> L.cr
 [1] 20.95 22.25 23.55 24.85 26.15 27.45 28.75 30.05 31.35 32.65 
[11] 33.95
> MC.cr=(L.cr[1]+L.cr[2])/2+1.3*(0:9)
> MC.cr
[1] 21.6 22.9 24.2 25.5 26.8 28.1 29.4 30.7 32.0 33.3
> crw_int=cut(crw, breaks=L.cr, right=FALSE)
```
Ahora calcularemos la tabla de frecuencias para este agrupamiento `crw\_{`int}. Usaremos la función 
`Tabla\_{`frec\_{}agrup} de la página \pageref{page:tabla_frec}.

```
> Tabla_frec_agrup(crw,10,1.3,0.1,dig.lab=4)
    intervalos marcas f.abs f.abs.cum       f.rel  f.rel.cum
1  [20.9,22.2)   21.6     2         2 0.011560694 0.01156069
2  [22.2,23.6)   22.9    14        16 0.080924855 0.09248555
3  [23.6,24.9)   24.2    27        43 0.156069364 0.24855491
4  [24.9,26.1)   25.5    44        87 0.254335260 0.50289017
5  [26.1,27.4)   26.8    34       121 0.196531792 0.69942197
6  [27.4,28.8)   28.1    31       152 0.179190751 0.87861272
7    [28.8,30)   29.4    15       167 0.086705202 0.96531792
8    [30,31.4)   30.7     3       170 0.017341040 0.98265896
9  [31.4,32.6)   32.0     2       172 0.011560694 0.99421965
10   [32.6,34)   33.3     1       173 0.005780347 1.00000000
```
Por lo que se refiere al histograma, 
```
> hist_rel(crw, L.cr)
```
produce la Figura \@ref(fig:20.13). 

 \begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histcrab1.pdf}
\end{center} 
\caption{Histograma de frecuencias relativas de los datos del Ejemplo \@ref(ex:crab).\label{fig:20.13})
\end{figure}

La curva de densidad que obtenemos en este gráfico tiene una forma de campana que nos recuerda la campana de Gauss. Para explorar este parecido, vamos a añadir al histograma la gráfica de la función densidad de una distribución normal de  media y  desviación típica la media y la desviación típica muestral del conjunto de datos original, respectivamente; esta función se define mediante

`dnorm(x, mu=``media` `, sd=``desviación típica` `)`.

Así,
```
> hist_rel(crw, L.cr)
> curve(dnorm(x, mean(crw), sd(crw)), col="purple", lty=3, lwd=2, add=TRUE)
> legend("topright", lwd=c(2,2), lty=c(1,2), col=c("red","purple"),
  legend=c("densidad estimada","densidad normal"))
```
produce la Figura \@ref(fig:20.13.n). Se observan una ligera diferencia entre la densidad estimada y la campana de Gauss en la zona central.

 \begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{histcrab2.pdf}
\end{center} 
\caption{Histograma de frecuencias relativas de los datos del Ejemplo \@ref(ex:crab) y campana de Gauss.\label{fig:20.13.n})
\end{figure}

 
 
 \end{ejemplo}


## Representación gráfica de datos multidimensionales agrupados
\label{sec:grmultiagrup}

 A veces querremos agrupar los datos de las variables  numéricas de una tabla de datos. Los  motivos serán los mismos que cuando se trata de una sola variable: por ejemplo, si los datos son aproximaciones de valores reales, o si son muy heterogéneos.  Cuando tenemos dos variables emparejadas agrupadas, se pueden representar gráficamente las frecuencias de sus pares de clases mediante un `histograma bidimensional` , que divide el conjunto de todos los pares de valores en rectángulos definidos por los pares de intervalos
e indica sobre cada rectángulo su frecuencia absoluta, por ejemplo mediante colores o intensidades de gris (dibujar barras verticales sobre las regiones es una mala idea, las de delante pueden ocultar las de detrás). Hay muchos paquetes de `R` que ofrecen funciones para dibujar histogramas bidimensionales;^[  Véase, por ejemplo, [http://www.everydayanalytics.ca/2014/09/5-ways-to-do-2d-histograms-in-r.html](http://www.everydayanalytics.ca/2014/09/5-ways-to-do-2d-histograms-in-r.html) .]  aquí explicaremos la función `hist2d` del paquete `gplots`. Su sintaxis básica es

`hist2d(`$x$`, `$y$`, nbins=\ldots, col=\ldots)`,

donde:

* $x$ e $y$ son los vectores de primeras y segundas coordenadas de los puntos. Si son las dos columnas de un *data frame* de dos variables, lo podemos entrar en su lugar.

* `nbins` sirve para indicar los números de clases: podemos igualarlo a un único valor, y tomará ese número de clases sobre cada vector, o a un vector de dos entradas que indiquen el número de clases de cada vector.
* `col` sirve para especificar los colores a usar. Por defecto, los rectángulos vacíos aparecen de color negro, y el resto se colorean con tonalidades de rojo, de manera que los tonos más cálidos indican  frecuencias mayores. 

Además, podemos usar los parámetros usuales de `plot` para poner un título, etiquetar los ejes, etc.

A modo de ejemplo, vamos a dibujar el histograma bidimensional de las longitudes y anchuras de los pétalos de las flores iris, agrupando ambas dimensiones en los números de clases que da la regla de Freedman-Diaconis (y que calcula la función `nclass.FD`):
```
> #Instalamos y cargamos el paquete gplots
...
> hist2d(iris$Petal.Length, iris$Petal.Width, nbins=c(nclass.FD(iris$Petal.Length), nclass.FD(iris$Petal.Width)))
```
Al entrar esta última instrucción, obtenemos (junto con una serie de información en la consola que no hemos copiado) la Figura \@ref(fig:hist2d1), que podéis comparar con el diagrama de dispersión de los mismos datos de la Figura \ref{fig:iris1).

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{hist2d1}
\end{center}
\caption{Histograma bidimensional de longitudes y anchuras de pétalos de flores iris.}\label{fig:hist2d1}
\end{figure}

En los histogramas bidimensionales con muchas regiones de diferentes frecuencias, es conveniente usar de manera adecuada los colores para representarlas. Una posibilidad es usar el paquete `RColorBrewer`, que permite elegir esquemas de colores bien diseñados. Las dos funciones básicas son:

* `brewer.pal(`$n$`, "``paleta predefinida` `")`,  que carga en un vector de colores (una `paleta` ) una secuencia de $n$ colores  de la `paleta predefinida`  en el paquete.  Los nombres y contenidos de todas las paletas predefinidas que se pueden usar en esta función se obtienen, en la ventana de gráficos, ejecutando la instrucción `display.brewer.all()`. Por ejemplo, la paleta de colores que se define con
```
> brewer.pal(11,"Spectral")
```
es la de la izquierda en la Figura \@ref(fig:pal1).



* `colorRampPalette(brewer.pal(\ldots))(`$m$`)`, produce una nueva paleta de $m$ colores  a partir del resultado de `brewer.pal`, interpolando nuevos colores. Luego se puede usar la función `rev` para invertir el orden de los colores, lo que es conveniente en los histogramas bidimensionales si queremos que las frecuencias bajas correspondan a tonos azules y las frecuencias altas a tonos rojos. Así,
la paleta de colores que se define con
```
> rev(colorRampPalette(brewer.pal(11,"Spectral"))(50))
```
es la de la derecha en la Figura \@ref(fig:pal1).



\begin{figure}[htb]
\abovecaptionskip=1pt
\begin{center}
\includegraphics[width=0.36\linewidth]{figpal1} \hspace*{1cm} \includegraphics[width=0.28\linewidth]{figpal2}
\end{center}
\caption{Paletas `brewer.pal(11,"Spectral")` y `rev(colorRampPalette(brewer.pal(11,"Spectral"))(50))`.}\label{fig:pal1}
\end{figure}

Vamos a usar esta última paleta en un histograma bidimensional de las alturas de padres e hijos recogidas por Karl Pearson que ya usamos en el Ejemplo \@ref(ex:reg2):
```
> df_pearson=read.table("http://aprender.uib.es/Rdir/pearson.txt", header=TRUE)
> hist2d(df_pearson, nbins=30,
   col=rev(colorRampPalette(brewer.pal(11,"Spectral"))(50)))
```
Obtenemos la Figura \@ref(fig:hist2dpearson).
\begin{figure}[htb]
\abovecaptionskip=1pt
\begin{center}
\includegraphics[width=0.45\linewidth]{fighist2d2}
\end{center}
\caption{Histograma bidimensional de las alturas de padres e hijos recogidas por Karl Pearson.}\label{fig:hist2dpearson}
\end{figure}

Para terminar, veamos como producir un gráfico conjunto de un histograma bidimensional y los dos histogramas unidimensionales.^[  Se trata de una adaptación del gráfico similar explicado en [http://www.everydayanalytics.ca/2014/09/5-ways-to-do-2d-histograms-in-r.html](http://www.everydayanalytics.ca/2014/09/5-ways-to-do-2d-histograms-in-r.html) , el cual a su vez  se inspira en un gráfico de la p. 62 de *Computational Actuarial Science with R* de Arthur Charpentier (Chapman and Hall/CRC, 2014).]  Considerad la función siguiente, cuyos parámetros son un *data frame* `df` de dos variables y un número `n` de clases, común para las dos variables:
```
> hist.doble=function(df,n){
  par.anterior=par()
  h1=hist(df[,1], breaks=n, plot=FALSE)
  h2=hist(df[,2], breaks=n, plot=FALSE)
  m=max(h1$counts, h2$counts)
  par(mar=c(3,3,1,1))
  layout(matrix(c(2,0,1,3),nrow=2,byrow=TRUE), 
     heights=c(1,3), widths=c(3,1))
  hist2d(df, nbins=n, 
     col=rev(colorRampPalette(brewer.pal(11,"Spectral"))(50)))
  par(mar=c(0,2,1,0))
  barplot(h1$counts, axes=FALSE, ylim=c(0, m), col="red")
  par(mar=c(2,0,0.5,1))
  barplot(h2$counts, axes=FALSE, xlim=c(0, m), col="red", 
     horiz=TRUE)
  par.anterior
}
```
Entonces,
```
> hist.doble(df_pearson,25)
```
produce la Figura \@ref(fig:hist2dcomplet).

\begin{figure}[htb]
\abovecaptionskip=1pt
\begin{center}
\includegraphics[width=0.45\linewidth]{fighist2dcomplet}
\end{center}
\caption{Histograma bidimensional con histogramas unidimensionales de las alturas de padres e hijos recogidas por Karl Pearson.}\label{fig:hist2dcomplet}
\end{figure}


Algunas explicaciones sobre el código, por si lo queréis modificar:

* Hemos <<simulado>> los histogramas mediante diagramas de barras de sus frecuencias absolutas, para poder dibujar horizontal el de la segunda variable.

* El parámetro `axes=FALSE` en los `barplot` indica que no dibuje sus ejes de coordenadas.

* La función `par` establece los parámetros generales básicos de los gráficos. Como con esta función los modificamos, guardamos los parámetros anteriores en `par.anterior` y al final los restauramos. 

* El parámetro `mar` de la función `par` sirve para especificar, por este orden, los márgenes inferior, izquierdo, superior y derecho  de la próxima figura, en números de líneas. 

* La instrucción `layout` divide la figura a producir en sectores con la misma estructura que la matriz de su primer argumento.
Dentro de esta matriz, cada entrada indica qué figura de las próximas se ha de situar en ese sector. Las alturas y amplitudes relativas de los sectores
se especifican con los parámetros `heights` y `widths`, respectivamente. Así, la instrucción

`layout(matrix(c(2,0,1,3),nrow=2,byrow=T), heights=c(1,3), widths=c(3,1))`

divide la figura en 4 sectores. Los sectores de la izquierda serán el triple de anchos que los de la derecha (`widths=c(3,1)`), y los sectores inferiores serán el triple de altos que los superiores (`heights=c(1,3)`). En estos sectores, `R` dibujará los próximos gráficos según el esquema definido por la matriz del argumento:
$$
\left(\begin{array}{cc}
\mbox{segundo} & \mbox{ninguno}\\
\mbox{primero} & \mbox{tercero}
\end{array}\right).
$$



## Guía rápida de funciones



* `nclass.Sturges` calcula el número de clases de un agrupamiento según la regla de Sturges.

* `nclass.scott` calcula el número de clases de un agrupamiento según la regla de Scott.

* `nclass.FD` calcula el número de clases de un agrupamiento según la regla de Freedman-Diaconis.

* `cut` sirve para agrupar un vector numérico y codificar  sus valores  con las clases a las que pertenecen. Algunos parámetros importantes:

* `breaks`: sirve para especificar los puntos de corte, o el número de clases.
* `labels`: sirve para especificar las etiquetas de las clases.
* `right=FALSE`: especifica que las clases son intervalos cerrados a la izquierda y abiertos a la derecha.
* `include.lowest=TRUE`: combinado con el anterior, impone que la última clase se tome  cerrada a ambos lados.
* `dig.lab`: permite especificar el número de cifras significativas en los extremos de las clases cuando se toma el valor por defecto de `labels`.



* `hist` dibuja un histograma de un vector numérico. Algunos parámetros importantes:

* `breaks`: sirve para especificar los puntos de corte, el número de clases, o el método para calcularlo; en estos dos últimos casos, no siempre se obtiene el número de clases especificado.

* `freq`:  igualado a `TRUE`, produce el histograma de frecuencias absolutas si los intervalos son todos de la misma amplitud, y el de frecuencias relativas en caso contrario; igualado a `FALSE`, produce siempre el de frecuencias relativas.

* `plot`: igualado a `FALSE`, impide que se dibuje el histograma.

* `right` y `include.lowest` tienen el mismo significado que en `cut`.

Internamente, el resultado de `hist` es una `list` que incluye los siguientes vectores:

* \verb?breaks?: los extremos de los intervalos.

* \verb?mids?: los puntos medios de los intervalos.

* \verb?counts?: las frecuencias absolutas de los intervalos.

* \verb?density?: las densidades de los intervalos. 


* `axis` añade a un gráfico un eje, con marcas en los lugares indicados por el vector entrado en el parámetro  `at`.

* `rug` permite añadir una <<alfombra>> a un histograma.

* `jitter` añade  <<ruido>> estocástico a los datos de un vector numérico.

* `density` calcula una secuencia de puntos sobre la curva de densidad estimada a partir de un vector numérico.

* `dnorm` define la curva de densidad de una distribución normal. Tiene los dos parámetros siguientes:

*  `mu`: la media.
* `sd`: la desviación típica.



* `hist2d`, del paquete `gplots`, dibuja histogramas bidimensionales. Dispone de los parámetros específicos siguientes:

* `nbins`: indica los números de clases.

* `col`: especifica la paleta de colores que ha de usar para representar las frecuencias. 


* `brewer.pal(`$n$`, "``paleta predefinida` `")`, del paquete `RColorBrewer`,  carga en una paleta de colores una secuencia de $n$ colores  de la `paleta predefinida`  en dicho paquete.  



* `colorRampPalette(brewer.pal(\ldots))(`$m$`)`, del paquete `RColorBrewer`,  produce una nueva paleta de $m$ colores  a partir del resultado de `brewer.pal`, interpolando nuevos colores. 

* `display.brewer.all()`, del paquete `RColorBrewer`, muestra los nombres y contenidos de todas las paletas predefinidas en dicho paquete. 


* `par` sirve para establecer los parámetros generales básicos de los gráficos. 

* `layout` divide en sectores la figura a producir, para que pueda incluir varios gráficos independientes simultáneamente.






## Ejercicio

 La tabla `lobsters.txt`, que hemos guardado en 

[http://aprender.uib.es/Rdir/lobsters.txt](http://aprender.uib.es/Rdir/lobsters.txt)  

está formada por los pesos de langostas capturadas en dos zonas; estos pesos están expresados en kg, con una precisión de 0.01~kg. Las separaciones entre columnas son espacios en blanco y tiene una primera fila con los nombres de las columnas.

Definid un *data frame* con esta tabla. Echadle un vistazo (y comprobad que se ha importado correctamente). Definid dos vectores con los pesos de las langostas de la zona~1 y de la zona~2, respectivamente.


[(a)]
* Agrupad los pesos de la zona 1 y de la zona 2 siguiendo la regla de Scott. 

* Para cada zona, y con este agrupamiento, construid un *data frame* que contenga la tabla de frecuencias agrupadas.

* Para cada zona, y con este mismo agrupamiento, dibujad el correspondiente histograma de frecuencias relativas incluyendo la curva de densidad estimada. Comparad los dos histogramas: ¿se observa alguna diferencia?



# Gráficos avanzados {chapt:grav}

 La capacidad que tiene {\tt R} para representar gráficamente datos es 
asombrosa y explicar todos los gráficos que puede producir  nos llevaría 
un curso entero. Por este motivo,  en esta lección nos limitaremos a daros una idea de sus capacidades gráficas, explicando unos cuantos gráficos avanzados que se pueden  producir con {\tt R} de manera sencilla, sin 
entrar en el detalle de los algoritmos que los 
generan.

## Nubes de palabras o de etiquetas (<<word clouds>>)

 Una `nube de palabras` , o `de etiquetas` , (*word cloud*) es un gráfico formado por las palabras de un texto, organizadas en forma de nube. Las palabras se representan en la nube de manera que a mayor frecuencia en el texto y, por tanto,  a mayor importancia  en este 
sentido, mayor sea su tamaño. Las frecuencias de las palabras  también se pueden  indicar por medio de una gradación de color. 

Para crear una nube de palabras con {\tt R}, necesitamos cargar los paquetes {\tt 
tm} (de {\sl text mining}), para tratar y manipular textos, y {\tt wordcloud}, para dibujar la nube de palabras. 
En primer lugar veremos cómo usar las funciones del paquete {\tt tm} con el fin de extraer la información de un documento que nos permitirá producir su nube de 
palabras.

La estructura principal para el manejo de documentos en el paquete {\tt tm} es el {\sl Corpus},  que representa una colección de textos. La 
implementación básica que lleva dicho paquete  de un {\sl Corpus}, y que es la que usaremos aquí, es el  <<*Corpus* volátil>>, 
{\sl VCorpus}, que viene a ser una representación 
volátil de  los  documentos en la memoria de {\tt R}. Decimos volátil 
porque una vez que el objeto de {\tt R} en cuestión es borrado, el corpus de los 
documentos también se borra de la memoria. Para cargar un conjunto de documentos en un {\sl VCorpus}, 
usamos la instrucción 

`nombre` ={\tt VCorpus(}`lugar` {\tt, readerControl=...)}

donde:

* El primer parámetro es el `lugar`  de donde {\tt R} tiene que cargar los 
documentos a analizar.  Si forman el contenido de un directorio, se especifica con {\tt DirSource("{}}`directorio` `"{`)}, mientras que, para cargar el código fuente de una página web, se tiene que usar {\tt URISource("{}}`url` `"{`)}.
Para conocer el resto de funciones que se pueden usar para entrar este `lugar` , podéis consultar la Ayuda de la función `Source`. En todas ellas se puede especificar con `encoding` la codificación de alfabeto; es conveniente hacerlo si los documentos contienen palabras acentuadas o caracteres especiales.

* El parámetro {\tt readerControl} es una `list` de dos componentes: {\tt reader} y {\tt language}.  La componente {\tt 
reader} indica la función que ha de usar `R` para leer y procesar los documentos contenidos en el `lugar`  especificado, que dependerá de su formato; aquí solo consideraremos el análisis de documentos en formato texto, que corresponde al valor por defecto de {\tt reader}, y por lo tanto podemos omitir esta componente en la `list` (si tenéis curiosidad, corresponde a `reader=readPlain`). Si queréis procesar otro tipo de documentos, os recomendamos que, al menos al principio,  primero los convirtáis en ficheros de texto ordinario.

Por su lado, el parámetro {\tt language} indica el idioma en que está  el  texto, o los textos, a procesar. Se ha de entrar igualado al código ISO 639-2
del idioma^[  Que podréis encontrar, por ejemplo, en la correspondiente entrada de la Wikipedia: [https://en.wikipedia.org/wiki/List_of_ISO_639-2_codes](https://en.wikipedia.org/wiki/List_of_ISO_639-2_codes) .]  entrecomillado: \verb?"en"?  para inglés, \verb?"spa"?  para español, \verb?"tlh"? para klingon, etc.


Vamos a desarrollar un ejemplo completo. Hemos guardado en un subdirectorio llamado <<Wordcloud>> del directorio de trabajo dos documentos:
un fichero `lomce.txt` con el texto de la Ley orgánica 8/2013, de 9 de diciembre, para la mejora de la calidad educativa, más conocida como LOMCE,^[  Copiado de 
[http://www.boe.es/diario_boe/txt.php?id=BOE-A-2013-12886](http://www.boe.es/diario_boe/txt.php?id=BOE-A-2013-12886) .]  que será el que analizaremos, y un fichero `introR.txt` con el primer párrafo de esta lección, que no analizaremos y simplemente nos servirá para ver el efecto de algunas transformaciones. Podéis encontrar estos dos documentos en el repositorio del curso.

Vamos a cargar estos dos documentos en un *VCorpus* llamado `Prueba`:
```
> #Instalamos y cargamos el paquete "tm"
...
> Prueba=VCorpus(DirSource("WordCloud", encoding="UTF-8"), 
   readerControl=list(language="spa"))
```
Hemos añadido \verb?encoding="UTF-8"? porque así es como hemos guardado los ficheros de texto en nuestro ordenador y como contienen letras acentuadas, mejor curarnos en salud. Como están en español, hemos especificado \verb?language="spa"? en `readerControl`, y en cambio no hemos especificado la componente `reader` de esta `list` porque se trata de ficheros de texto.

A continuación, vamos a inspeccionar el *Corpus* cargado. Aplicándole la función {\tt inspect}, obtenemos cuántos documentos contiene y, para cada uno, su número de caracteres y su formato.
```
> inspect(Prueba)
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 2

[[1]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 426

[[2]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 214361
```
De esta manera vemos que `R` ha incorporado al *VCorpus* los documentos por orden alfabético de su título: el primero es el corto, `introR.txt`, y el segundo, el largo, `lomce.txt`.

Con la instrucción {\tt writeLines(as.character(}`VCorpus` `[[``k` `]]))` obtenemos en la consola el contenido completo del $k$-ésimo texto de nuestro *VCorpus*. Veamos, por ejemplo, el contenido del texto corto:
```
> writeLines(as.character(Prueba[[1]]))
La capacidad que tiene R para representar gráficamente datos es  asombrosa.  Explicar todos los gráficos que puede producir R nos llevaría  un curso entero, por lo que, en este capítulo, nos limitaremos a explicar la versión básica de unos cuantos gráficos avanzados que podemos  producir con R de manera sencilla, para daros una idea de sus capacidades gráficas  y sin  entrar en detalles de los algoritmos que los  producen.
```


Una vez que hemos guardado una serie de documentos en un {\sl VCorpus}, tenemos que <<limpiarlos>>, en el sentido de eliminar, por ejemplo, signos de puntuación y palabras comunes sin ningún interés  para que no aparezcan en la nube de palabras. Esto se lleva a cabo aplicando la función `tm\_{`map} al {\sl VCorpus} y a una <<transformación>>. Veamos algunos ejemplos:

* Convertimos todas las letras en minúsculas, para que `R` no considere diferentes dos palabras simplemente por la grafía de sus letras:
```[style=item1]
> Prueba=tm_map(Prueba, tolower)
```

* Eliminamos los signos de puntuación:
```[style=item1]
> Prueba=tm_map(Prueba, removePunctuation)
```

* Eliminamos las palabras <<comodín>>: preposiciones, artículos, algunos tiempos verbales de ser, estar y haber, etc.\ (si entráis en la consola la instrucción `stopwords("{`spanish"{})} veréis la lista de las palabras que se eliminan):
```[style=item1]
> Prueba=tm_map(Prueba, removeWords, stopwords("spanish"))
```
En general, con `Prueba=tm\_{`map(Prueba, removeWords,} `vector` `)` podemos  borrar un `vector`  de palabras. Por ejemplo, vamos a eliminar también la palabra <<artículo>>, para evitar que aparezca en la nube de palabras de la LOMCE, y <<r>> (ya en minúsculas) para ver cómo desaparece del texto corto.
```[style=item1]
> Prueba=tm_map(Prueba, removeWords, c("artículo","r"))
```

* Eliminamos los espacios en blanco extra:
```[style=item1]
> Prueba=tm_map(Prueba, stripWhitespace)
```




Veamos como ha quedado el texto corto tras estas transformaciones:
```
> writeLines(as.character(Prueba[[1]]))
 capacidad representar gráficamente datos asombrosa explicar gráficos puede producir llevaría curso entero capítulo limitaremos explicar versión básica cuantos gráficos avanzados podemos producir manera sencilla daros idea capacidades gráficas entrar detalles algoritmos producen
```

Otras  transformaciones posibles que nosotros no hemos aplicado, son: `removeNumbers`, para eliminar los números, 
y, cargando el paquete `SnowballC`, la transformación `stemDocument` (con, en nuestro ejemplo, `language="spanish"`), que se queda sólo con las raíces de algunas palabras (y la nube de palabras que se produciría sería la de estas raíces: así, por ejemplo, en la de la LOMCE saldría <<alumn>> en lugar de <<alumnos>> y <<alumnas>>).


Ahora estamos en condiciones de construir la nube de palabras de la LOMCE. Para ello, usaremos la función {\tt wordcloud} del paquete homónimo. Veamos su aplicación a nuestro caso concreto, y luego comentamos algunos parámetros:
```
> #Instalamos y cargamos el paquete "wordcloud"
...
> wordcloud(Prueba[[2]], scale=c(3,0.5), max.words=100, 
          rot.per=0.25, colors=brewer.pal(8, "Dark2"))
```
Obtenemos el gráfico \@ref(LENGR), donde observamos que las palabras más repetidas y, por tanto, en este sentido más importantes, son 
<<educación>>, <<alumnos>>, <<alumnas>>, <<centros>>, etc.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.6\linewidth]{wdclomce}
\end{center}
\caption{Nube de palabras de la LOMCE.}
\label{LENGR}
\end{figure}

Como vemos, la función  {\tt wordcloud} se aplica al documento, en este caso {\tt 
Prueba[[2]]}, y
sus parámetros principales son los siguientes:

* `scale`: un vector de longitud 2 que sirve para indicar la escala, o los tamaños relativos, de las palabras. Su primera entrada indica el tamaño de la palabra más repetida y la segunda, el de la palabra menos repetida.

* `max.words`: el número máximo de palabras a mostrar. 

* `min.freq`:  la frecuencia mínima necesaria para que una palabra aparezca en el gráfico.

* `rot.per`: la proporción de palabras que se pueden mostrar giradas 90 grados.

* `colors`: la paleta de colores usados para representar las frecuencias, en orden creciente. Nosotros hemos usado una paleta del paquete `RColorBrewer` explicado en la Sección 11.5 (y que se carga automáticamente junto con el paquete `wordcloud`).

Algunos comentarios importantes:

* La posición de las palabras en la nube es aleatoria, de manera que puede variar en cada ejecución de la instrucción.

* `R` procura evitar solapamientos de palabras, y eso hace que, según cómo las vaya colocando, algunas no le quepan: en este caso os avisará con 
un `warning` para cada palabra omitida. Algunas posibles soluciones son volver a repetir el gráfico hasta que el azar produzca una combinación en la que quepan todas,  reducir el número de palabras en la nube o reducir el rango de tamaños de las palabras. Otra posibilidad es usar el parámetro 
`random.order=FALSE`, que añade las palabras en orden decreciente de frecuencia, con lo que si hay palabras que no incluya, serán las menos importantes.


* Si, al guardar la imagen, modificáis sus dimensiones, las palabras se recolocarán y puede que se superpongan (si reducís el gráfico) o se separen (si lo ampliáis). Procurad, al guardar la imagen, usar la opción <<*View plot after saving*>> para controlar el resultado final.



## Mapa de colores o <<heatmap>>

 Uno de los gráficos más usados en estadística multidimensional para representar la relación existente entre un conjunto de individuos o de variables es un `mapa de colores` , o *heatmap*. Por ejemplo, a partir de una tabla de datos, podemos producir un mapa de colores que represente las correlaciones de sus variables, para poder visualizar los pares de variables con mayor y menor relación lineal, o
un mapa de colores que represente las diferencias (en algún sentido) entre sus individuos, para poder visualizar qué individuos se parecen más o menos. En realidad, el principio es el mismo que cuando producíamos histogramas 2D en la Lección 11: se representan gráficamente las entradas de una matriz (en aquel caso, tablas de contingencia bidimensionales de variables agrupadas) de manera que el tamaño  de las entradas se simbolice mediante una gradación de colores. 

La función básica para producir mapas de colores es `heatmap`, y se aplica a una matriz.
Para ilustrar su funcionamiento, vamos a ver dos ejemplos sobre una misma tabla de datos, y aprovecharemos para explicar algunos de sus parámetros.

\begin{ejemplo}\label{MTCARS}
Consideremos la tabla de datos que lleva {\tt R} llamada {\tt mtcars}. Dicha tabla de datos contiene los valores de las 11 características siguientes (las variables) de 32 vehículos (las filas):
\begin{description}
  * [{\tt mpg}:] El consumo del vehículo en millas por galón de combustible.
  * [{\tt cyl}:] Su número de cilindros.
  * [{\tt disp}:] Su cilindrada.
  * [{\tt hp}:] Su número de caballos de potencia.
  * [{\tt drat}:] Su relación del eje trasero.
  * [{\tt wt}:] Su peso (en libras/1000).
  * [{\tt qsec}:] El tiempo que tarda en recorrer un cuarto de milla.
  * [{\tt vs}:] El tipo de motor: Motor en V (valor $0$) o en línea (valor $1$).
  * [{\tt am}:] El tipo de transmisión: $0$ automática, $1$ manual.
  * [{\tt gear}:] El número de marchas hacia adelante.
  * [{\tt carb}:] El número de carburadores.
\end{description}

Para estudiar los pares de variables que tienen más relación lineal, vamos a representar por medio de  un *heatmap* la matriz de los valores absolutos de las correlaciones de las variables no binarias 
(es decir, de todas menos `vs` y `am`, la octava y la novena respectivamente). Las instrucciones que usamos son las siguientes:
```
> mtcars2=mtcars[,-c(8,9)]  #Eliminamos las variables binarias
> round(abs(cor(mtcars2)),3)
       mpg   cyl  disp    hp  drat    wt  qsec  gear  carb
mpg  1.000 0.852 0.848 0.776 0.681 0.868 0.419 0.480 0.551
cyl  0.852 1.000 0.902 0.832 0.700 0.782 0.591 0.493 0.527
disp 0.848 0.902 1.000 0.791 0.710 0.888 0.434 0.556 0.395
hp   0.776 0.832 0.791 1.000 0.449 0.659 0.708 0.126 0.750
drat 0.681 0.700 0.710 0.449 1.000 0.712 0.091 0.700 0.091
wt   0.868 0.782 0.888 0.659 0.712 1.000 0.175 0.583 0.428
qsec 0.419 0.591 0.434 0.708 0.091 0.175 1.000 0.213 0.656
gear 0.480 0.493 0.556 0.126 0.700 0.583 0.213 1.000 0.274
carb 0.551 0.527 0.395 0.750 0.091 0.428 0.656 0.274 1.000
> heatmap(abs(cor(mtcars2)), Rowv=NA, Colv=NA, revC=TRUE) 
```


El gráfico obtenido es la Figura \@ref(COR.MTCARS), y podemos observar la correspondencia entre los colores de los cuadrados y las entradas de la matriz que representa: cuanto más rojo es el cuadrado correspondiente a un par de variables, menor es la entrada de la matriz y por lo tanto menos relación lineal existe entre ellas; y cuanto más claro,
mayor es la entrada de la matriz y por consiguiente su relación lineal. Así, podemos advertir en el gráfico que la variable {\tt cyl}, el número de cilindros del vehículo, tiene mucha relación lineal con la cilindrada  ({\tt disp}), el consumo ({\tt mpg}), la potencia ({\tt hp}), el peso ({\tt wt}) y  la relación del eje trasero ({\tt drat}); en cambio, la variable {\tt qsec} (tiempo que tarda el vehículo en recorrer $1/4$ de milla) sólo tiene relación lineal con la potencia, {\tt hp},
y el número de carburadores, {\tt carb}.

Antes de continuar, vamos a explicar los parámetros usados en la aplicación anterior de la función `heatmap`: con `Rowv=NA` y `Colv=NA` impedimos que se añadan al gráfico dendrogramas por filas y por columnas, respectivamente (véase la Sección \@ref(sec:dendr)), y con `revC=TRUE` hemos indicado que el orden de las variables de izquierda a derecha sea el mismo que de arriba abajo (por defecto, el orden de las filas se invierte).

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{cor_mtcars.pdf}
\end{center}
\caption{{\sl Heatmap} de la matriz de correlaciones de la tabla de datos {\tt mtcars}.}
\label{COR.MTCARS}
\end{figure}
\end{ejemplo}

La función {\tt corrplot} del paquete homónimo permite producir mapas de colores de matrices de correlaciones más completos:
```
> #Instalamos y cargamos el paquete "corrplot"
...
> corrplot(cor(mtcars2))
```


El resultado aparece en el gráfico de la izquierda de la Figura \@ref(COR2.MTCARS). En este caso hemos usado la matriz de correlaciones sin valor absoluto, porque no hace falta: los círculos más grandes indican una mayor correlación en valor absoluto y, por tanto, más relación lineal entre las variables involucradas, y los colores indican el signo de la correlación según el código descrito en la columna de la derecha.
Si además hubiéramos querido que apareciera el valor de la correlación para cada par de variables, hubiéramos podido utilizar las opciones siguientes:
```
> corrplot(cor(mtcars2), method="shade", shade.col=NA, 
   tl.col="black", tl.srt=45, addCoef.col="black")
```


Se obtiene el gráfico de la derecha de la misma Figura \@ref(COR2.MTCARS). El significado de los parámetros que hemos usado es el siguiente:
con \verb?method="shade"? y \verb?shade.col=NA? hemos indicado que queremos las celdas coloreadas homogéneamente, en vez de círculos; el parámetro `tl.col` especifica el color de las etiquetas de las filas y las columnas (por defecto es rojo, como en la anterior aplicación de `corrplot`);  el parámetro `tl.srt` especifica el ángulo de inclinación de las etiquetas de las columnas en grados (por defecto, son verticales); y con \verb?addCoef.col="black"? hemos indicado que incluya los valores de las correlaciones en las casillas, escritos en negro.
Os recomendamos consultar la Ayuda de la función para conocer el resto de parámetros disponibles. 



\begin{figure}[htb]
\begin{center}
\begin{tabular}{cc}
\includegraphics[width=0.45\linewidth]{cor_mtcars2-2.pdf} &
\includegraphics[width=0.45\linewidth]{cor_mtcars3-2.pdf}
\end{tabular}
\end{center}
\caption{Dos *heatmaps* de la matriz de correlaciones de la tabla de datos {\tt mtcars} usando  {\tt corrplot}.}
\label{COR2.MTCARS}
\end{figure}


\begin{ejemplo}\label{VEHICLES}
Ahora vamos a visualizar por medio de un  *heatmap* las diferencias entre los vehículos estudiados en la tabla `mtcars`. Las diferencias las cuantificaremos por medio de la distancia euclídea entre los vectores que definen las filas de la tabla de datos. Como en el ejemplo anterior, sólo vamos a considerar las variables numéricas, así que usaremos el *data frame*  `mtcars2`. A modo de ejemplo, las filas de los vehículos {\tt Mazda RX4} y {\tt Valiant} son
```
> mtcars2[c("Mazda RX4","Valiant"),]
           mpg cyl disp  hp drat   wt  qsec gear carb
Mazda RX4 21.0   6  160 110 3.90 2.62 16.46    4    4
Valiant   18.1   6  225 105 2.76 3.46 20.22    3    1
```
y su distancia euclídea es
$$
\sqrt{(21-18.1)^2+(6-6)^2+(160-225)^2+(110-105)^2+\cdots +(4-1)^2}=65.4565.
$$

Para hallar la matriz de distancias euclídeas entre las filas de la tabla de datos {\tt mtcars2} usamos la instrucción {\tt dist}:
```
> dist.mtcars=as.matrix(dist(mtcars2)) 
> round(dist.mtcars[1:4,1:4],2) #Submatriz de las 4 primeras filas y columnas
               Mazda RX4 Mazda RX4 Wag Datsun 710 Hornet 4 Drive
Mazda RX4           0.00          0.62      54.90          98.10
Mazda RX4 Wag       0.62          0.00      54.88          98.09
Datsun 710         54.90         54.88       0.00         150.99
Hornet 4 Drive     98.10         98.09     150.99           0.00
```

La función  `dist` calcula por defecto las distancias euclídeas entre las filas de una matriz o un *data frame* de variables numéricas. Para calcular alguna otra distancia, se ha de especificar con el parámetro `method`: consultad la Ayuda de la función para conocer  los posibles valores de este parámetro. En el código anterior, hemos usado la función {\tt as.matrix} para transformar el resultado de {\tt dist} en una matriz ya que esta última función produce un objeto de clase {\tt dist} y queremos que el resultado sea una matriz para poderle aplicar la función {\tt heatmap}. 

Dibujemos el {\sl heatmap} de las distancias entre vehículos; el  resultado es la Figura \@ref(VEH.MTCARS).

```
> heatmap(dist.mtcars, margins=c(9,9), symm=TRUE, Rowv=NA, Colv=NA, revC=TRUE)  
```
El parámetro `margins` especifica el ancho de los márgenes donde se escriben los nombres de las filas y las columnas y lo hemos adaptado para que quepan los nombres de los vehículos; 
el parámetro `symm=TRUE` indica a `R` que ha de considerar que la matriz es simétrica. El resto de los parámetros ya los hemos explicado antes. Esta función dispone de muchos más parámetros, que podéis consultar en su Ayuda.

La representación visual tiene el mismo significado que antes, pero referida a la matriz a la que hemos aplicado la función `heatmap`: cuanto más roja es la casilla, menor es la distancia entre los vehículos, y por lo tanto más parecidos son.
Así, por ejemplo, si observamos la columna del vehículo <<Mazda RX4>>, vemos que los vehículos más diferentes a él son  <<Cadillac Fleetwood>>, <<Lincoln Continental>> y <<Chrysler Imperial>>, ya que aparecen con un color más cercano al blanco, y los más parecidos son <<Mazda RX4 Wag>>, <<Merc 280>>, <<Merc 280C>>, <<Merc 230>>, <<Volvo 142E>>, <<Toyota Corona>>, 
<<Porsche 914-2>>, <<Merc 240D>>, etc.
\end{ejemplo}


\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.6\linewidth]{veh_mtcars.pdf}\\[-0.5cm]
\end{center}
\caption{*Heatmap* de la matriz de distancias de los vehículos de la tabla de datos {\tt mtcars}.}
\label{VEH.MTCARS}
\end{figure}


## Dendrogramas}\label{sec:dendr

 Dada una tabla de datos podemos construir una matriz de distancias entre los individuos representados en ella, aplicando una distancia concreta a cada par de filas; es lo que hicimos en el Ejemplo \@ref(VEHICLES), donde calculamos la distancia euclídea entre cada par de descripciones de tipo de coche.
Una vez construida dicha matriz de distancias, podemos ir agrupando los 
individuos de la tabla de datos usando algún  algoritmo de `agrupamiento` , o <<*clustering*>>, `jerárquico` . 

Muchos algoritmos de *clustering* jerárquico siguen una misma estrategia.
En un primer paso, se agrupan los dos individuos más parecidos (más cercanos según la distancia usada) en un grupo y se los sustituye por este grupo, al que se considera  un nuevo individuo <<virtual>>. A partir de aquí, en cada paso, se agrupan en un nuevo grupo los dos individuos (originales o <<virtuales>>) más cercanos y se los sustituye por el grupo que forman. El algoritmo termina cuando queda un único grupo.
Los diferentes algoritmos de este tipo, denominados genéricamente <<aglomerativos>>,  se distinguen básicamente según la manera como se define la distancia entre grupos a partir de las distancias entre sus individuos; aquí no entraremos en  detalle y nos limitaremos a usar el algoritmo que lleva implementado `R` por defecto (el llamado `método de enlace completo` : la distancia entre dos grupos es el máximo de las distancias entre sus elementos).^[  Para más información sobre algoritmos de  *clustering*, podéis consultar  [http://en.wikipedia.org/wiki/Cluster_analysis](http://en.wikipedia.org/wiki/Cluster_analysis) .]  

Un `dendrograma`  es entonces una representación gráfica del orden en el que se han ido realizando dichas agrupaciones y de las distancias entre los pares de individuos (originales y <<virtuales>>) que se han ido uniendo. Así podemos visualizar qué individuos se parecen más o si aparece de manera natural alguna clasificación de los individuos.

Veamos un
ejemplo detallado.
La tabla de datos `all.mammals.milk.1956` que lleva el paquete `cluster.datasets` contiene información sobre 5 variables numéricas relativas a la composición de  la leche materna de 25 especies de mamíferos. Las variables de esta tabla de datos son:
\begin{description}
* [{\tt name}:] El nombre del animal.
* [{\tt water}:] Porcentaje de agua en la leche.
* [{\tt protein}:] Porcentaje de  proteína.
* [{\tt fat}:] Porcentaje de grasa.
* [{\tt lactose}:] Porcentaje de  lactosa.
* [{\tt ash}:] Porcentaje de ceniza.
\end{description}
Démosle un vistazo.

```
> #Instalamos y cargamos el paquete "cluster.datasets"
...
> data(all.mammals.milk.1956)  
> AMM=all.mammals.milk.1956
> str(AMM)
'data.frame':	25 obs. of  6 variables:
 $ name   : chr  "Horse" "Orangutan" "Monkey" "Donkey" ...
 $ water  : num  90.1 88.5 88.4 90.3 90.4 87.7 86.9 82.1 81.9 81.6 ...
 $ protein: num  2.6 1.4 2.2 1.7 0.6 3.5 4.8 5.9 7.4 10.1 ...
 $ fat    : num  1 3.5 2.7 1.4 4.5 3.4 1.7 7.9 7.2 6.3 ...
 $ lactose: num  6.9 6 6.4 6.2 4.4 4.8 5.7 4.7 2.7 4.4 ...
 $ ash    : num  0.35 0.24 0.18 0.4 0.1 0.71 0.9 0.78 0.85 0.75 ...
> head(AMM)
       name water protein fat lactose  ash
1     Horse  90.1     2.6 1.0     6.9 0.35
2 Orangutan  88.5     1.4 3.5     6.0 0.24
3    Monkey  88.4     2.2 2.7     6.4 0.18
4    Donkey  90.3     1.7 1.4     6.2 0.40
5     Hippo  90.4     0.6 4.5     4.4 0.10
6     Camel  87.7     3.5 3.4     4.8 0.71
```

Para cuantificar la diferencia entre las composiciones de la leche de estos mamíferos, usaremos de nuevo la distancia euclídea entre sus vectores de valores de variables numéricas.
```
> dist.AMM=dist(AMM[,2:6])
> round(as.matrix(dist.AMM)[1:6,1:6],3)
      1     2     3     4     5     6
1 0.000 3.327 2.494 1.226 4.759 4.107
2 3.327 0.000 1.206 2.794 2.798 2.592
3 2.494 1.206 0.000 2.375 3.716 2.348
4 1.226 2.794 2.375 0.000 3.763 4.007
5 4.759 2.798 3.716 3.763 0.000 4.176
6 4.107 2.592 2.348 4.007 4.176 0.000
```
Hemos transformado el objeto `dist` en una matriz para poder consultar algunas entradas, pero lo mantenemos como objeto de tipo `dist` para construir su dendrograma.

Una vez se dispone de la matriz de distancias entre los individuos (en este caso, mamíferos), se calcula su *clustering* jerárquico aplicándole la función `hclust` y se convierte el resultado de esta función en un dendrograma usando `as.dendrogram`.
La función  `hclust` permite especificar el tipo de algoritmo de agrupamiento que queremos usar por medio del parámetro `method`; aquí usaremos el método por defecto. 
```
> dend.AMM=as.dendrogram(hclust(dist.AMM))
```

Y ahora ya podemos dibujar este dendrograma. Hay muchas opciones para hacerlo con `R`. La básica es aplicarle simplemente la función `plot`:
```
> plot(dend.AMM)
```
Obtenemos el gráfico de la izquierda de la Figura  \@ref(DENDRO1). En este gráfico, los grupos se representan mediante líneas horizontales y  las alturas representan distancias, de manera que la altura a la que se unen dos grupos es la distancia entre ellos. Así, este dendrograma nos muestra, por ejemplo, que la composición de la leche de los animales 24 y 25 (foca y delfín) es diferente de la del resto, formando un grupo propio que no se ha unido al resto de animales hasta el último paso. En cambio, la ballena (el 23), que comparte hábitat y dieta con ellos, se agrupa con el ciervo y el reno (21 y 22).
Por otro lado, cortando por una línea horizontal imaginaria a altura 30, podemos observar que se forman tres grupos muy claros.

En un dendrograma producido a partir de las distancias entre las filas de un *data frame*, los individuos se representan mediante los identificadores de las filas: en nuestro ejemplo, números. Si queremos los nombres de los animales como etiquetas, una posibilidad es modificar el *data frame* `AMM` usando como identificadores de las filas los nombres de los animales; y ya que estamos, podemos eliminar esta variable del *data frame* resultante:
```
> AMM.nombres=AMM
> rownames(AMM.nombres)=AMM.nombres$name
> AMM.nombres=AMM.nombres[,-1]
> head(AMM.nombres)
           water protein  fat lactose  ash
Horse       90.1     2.6  1.0     6.9 0.35
Orangutan   88.5     1.4  3.5     6.0 0.24
Monkey      88.4     2.2  2.7     6.4 0.18
Donkey      90.3     1.7  1.4     6.2 0.40
Hippo       90.4     0.6  4.5     4.4 0.10
Camel       87.7     3.5  3.4     4.8 0.71
> plot(as.dendrogram(hclust(dist(AMM.nombres))))
```
El resultado es el gráfico de la derecha de la Figura  \@ref(DENDRO1), donde ahora podemos leer (más o menos) los nombres de los animales sin tener que ir a consultar el *data frame* 

Aparte de los parámetros usuales de la función `plot`, dos parámetros interesantes cuando se aplica a un dendrograma son `horiz=TRUE`, que lo dibuja horizontal, y \verb?type="triangle"?, que dibuja las ramificaciones triangulares en vez de rectangulares.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{dendromam1}\
\includegraphics[width=0.45\linewidth]{dendromam2}\
\end{center}
\abovecaptionskip=-2ex
\caption{Dendrogramas de los mamíferos clasificados según la composición de su leche.}
\label{DENDRO1}
\end{figure}

Para tener más control sobre el aspecto de un dendrograma, por ejemplo cambiar sus etiquetas sin modificar el *data frame* original, escribirlas en un tamaño menor o mayor o colorear ramas o etiquetas a fin de añadir información al dendrograma,  lo más sencillo es utilizar algunas funciones específicas aportadas por diversos paquetes. Aquí vamos a explicar algunas funcionalidades del paquete `dendextend`.

A modo de ejemplo, una vez cargado este paquete, para cambiar directamente las etiquetas del dendrograma del *data frame* `AMM`, podemos usar de manera natural la función `labels`, que nos da las etiquetas de las hojas.
```
> Instalamos y cargamos el paquete "dendextend"
...
> L=labels(dend.AMM)
> L
 [1] 24 25 10  8 11 16  9 14  7 15  6 12  5  2  3  1  4 13 17 19 20
[22] 18 23 21 22
> labels(dend.AMM)=AMM$name[L]
> labels(dend.AMM)
 [1] "Seal"       "Dolphin"    "Cat"        "Buffalo"    "Fox"       
 [6] "Sheep"      "Guinea Pig" "Pig"        "Bison"      "Zebra"     
[11] "Camel"      "Llama"      "Hippo"      "Orangutan"  "Monkey"    
[16] "Horse"      "Donkey"     "Mule"       "Dog"        "Rabbit"    
[21] "Rat"        "Elephant"   "Whale"      "Deer"       "Reindeer"  
```

La función `labels` aplicada a un dendrograma nos da las etiquetas de las hojas de izquierda a derecha, y con el paquete `dendextend` nos permite también modificar estas etiquetas. Naturalmente, a cada etiqueta (en nuestro ejemplo, número de fila) le tenemos que hacer corresponder el nombre del animal que le toca: por eso usamos \verb?labels(dend.AMM)=AMM$name[L]? y no \verb?labels(dend.AMM)=AMM$name? a secas, que a la primera etiqueta del dendrograma (la 25) le asignaría el primer nombre de animal, correspondiente a la etiqueta 1. 

Ahora que ya hemos modificado las etiquetas del dendrograma, podemos modificar su apariencia de cara a representarlo gráficamente. Para ello podemos usar la función `set`, cuya sintaxis básica es

`set(``dendrograma` \verb?, what="?`característica` \verb?", ?`valor` `)`

Encontraréis la lista completa de las características que podemos usar en la Ayuda de la función.
Pero cuidado,  `set` no modifica el dendrograma permanentemente, solo temporalmente. Si queréis modificar el dendrograma, tenéis que usar

`dendrograma` `=set(``dendrograma` \verb?, what="?`característica` \verb?", ?`valor` `)`



Si queremos cambiar más de una característica de golpe, es muy cómodo usar la notación <<encadenada>> de funciones, en la que a un objeto se le van aplicando funciones una tras otra separándolas con el signo \verb?%>%?.^[  Esta notación no se puede usar en la instalación básica de `R`, solo en los paquetes, como `dendextend`, que la aceptan.] 
En este caso, no se entra el dendrograma dentro de `set`, sino al principio de la cadena.
Por ejemplo, para reducir el tamaño de letra de las etiquetas (para que así quepan en el gráfico) y escribirlas en rojo, podemos entrar el código siguiente:
```
> dend.AMM%>%
   set(what="labels_col", "red")%>% #Colores de las etiquetas
   set(what="labels_cex", 0.8)%>% #Tamaño de las etiquetas
   plot(main="Dendrograma con etiquetas coloreadas\n y reducidas")
```
El resultado es la Figura \@ref(DENDRO2). Observad la sintaxis: se toma el objeto `dend.AMM`, se le aplican las dos transformaciones, una tras otra, y al final se le aplica `plot` con los parámetros que deseemos.
No hemos modificado el dendrograma `dend.AMM`, solo su apariencia en el gráfico.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{dendromam3}
\end{center}
\caption{Dendrograma usando la función `set` de `dendextend`.}
\label{DENDRO2}
\end{figure}

La posibilidad de colorear las etiquetas, o las aristas, puede mejorar la comprensión del dendrograma, o incluso añadir información. Veamos dos aplicaciones:


* Para distinguir visualmente los principales grupos que se forman en el dendrograma, y por ejemplo usar un color en cada grupo,  podemos usar el parámetro `k` igualado al número de grupos que queremos reconocer.
Por ejemplo,
```[style=item1]
> dend.AMM%>%
   set(what="labels_cex", 0.8)%>%
   set(what="labels_col", c("red","blue","green"), k=3)%>%
   set(what="branches_k_color",c("red","blue","green"),k=3)%>% #Colores de las ramas
   plot(main="Dendrograma con 3 grupos resaltados")
```
produce el gráfico de la Figura \@ref(DENDRO3).

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{dendromam4}
\end{center}
\caption{Dendrograma con etiquetas y aristas coloreadas en 3 grupos.}
\label{DENDRO3}
\end{figure}


* Podemos clasificar los individuos representados en el dendrograma mediante un factor
y usar este factor para asignar colores a las etiquetas para así ver si los grupos que produce el dendrograma se corresponden con la clasificación según el factor. Como nuestro *data frame* `AMM` no tiene ninguna variable factor que podamos usar, vamos a añadirle una que represente la dieta principal del animal: C para carnívoro, H para   herbívoro, O para omnívoro, P para  piscívoro.

```[style=item1]
> AMM$diet=as.factor(c("H","O","O","H","H","H","H","H","H",
   "C","C","H","H","O","H","H","C","H","H","O","H","H","P",
   "P","P"))
> head(AMM)
         name water protein  fat lactose  ash diet
1       Horse  90.1     2.6  1.0     6.9 0.35    H
2   Orangutan  88.5     1.4  3.5     6.0 0.24    O
3      Monkey  88.4     2.2  2.7     6.4 0.18    O
4      Donkey  90.3     1.7  1.4     6.2 0.40    H
5       Hippo  90.4     0.6  4.5     4.4 0.10    H
6       Camel  87.7     3.5  3.4     4.8 0.71    H
> View(AMM) #Si queréis ver el dataframe completo en la ventana de ficheros
```
Ahora colorearemos las etiquetas del dendrograma según su dieta, y aprovecharemos para ver otra manera de usar `set`, definiendo un nuevo dendrograma `dend.AMM2` donde los cambios realizados sobre `dend.AMM` por las diferentes aplicaciones de `set` sean permanentes.
```[style=item1]
> dend.AMM2=dend.AMM%>%  
   set(what="labels_cex", 0.8)%>%   #Tamaño de etiquetas
   set(what="labels",AMM$name[L])%>%  #Nombres en las etiquetas
   set(what="labels_col",as.numeric(AMM$diet[L]))  #Colores según la dieta
> plot(dend.AMM2, main="Dendrograma de mamíferos clasificados
    \n según la dieta")
```
El resultado es la Figura \@ref(DENDRO4). Vemos que la similitud de la composición de la leche materna no tiene mucha correspondencia con la dieta.


\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{dendromam5}\
\end{center}
\caption{Dendrograma con las etiquetas coloreadas según un factor.}
\label{DENDRO4}
\end{figure}

Para más información sobre las posibilidades de `dendextend` y su interacción con otros paquetes que dibujan dendrogramas, consultad [https://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html](https://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html) . Por ejemplo, 
podemos modificar un dendrograma con `set` y luego 
aplicarle la función `circlize\_{`dendrogram} del paquete `circlize` para obtener una representación circular. Así, el código siguiente produce la Figura \@ref(DENDRO5). 
```
> #Instalamos y cargamos el paquete "circlize"
...
> circlize_dendrogram(dend.AMM2)
```

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{dendromam6}\
\end{center}
\caption{Dendrograma circular.}
\label{DENDRO5}
\end{figure}



## Gráficos de burbujas  o <<bubbles>>

 Hay situaciones en las que nos interesa resaltar la importancia de una variable dibujando figuras geométricas (círculos, cuadrados, etc.) de tamaño proporcional a la importancia del valor de la variable. Este tipo de gráficos se 
denominan `gráficos de burbujas` , o *bubbles*, y la función básica para producirlos es `symbols`. Su sintáxis básica es

`symbols(x, y, `*parámetro\_{*figura}`=z, ...)`

donde `x` e `y` son los vectores de primeras y segundas coordenadas de los centros de las figuras a dibujar, el
*parámetro\_{*figura} indica el tipo de figuras (`circles` para círculos, `squares` para cuadrados, `stars` para estrellas, etc.), y `z` es el vector de los tamaños <<lineales>> de las figuras: radio para los círculos, lado para los cuadrados, longitud del rayo para las estrellas, etc. Además se pueden usar los dos parámetros siguientes para añadir colores a las figuras:
\begin{description}
* [{\tt fg}:] el color de la frontera de los símbolos (por defecto, negro).
* [{\tt bg}:] su color de relleno.
\end{description}
Y finalmente, se pueden usar los parámetros usuales de `plot`; para más información, incluida la lista de figuras disponibles,
consultad la Ayuda de la función.

Veamos un ejemplo.
Consideremos la tabla de datos {\tt savings} que lleva el paquete {\tt faraway}. Dicha tabla de datos nos da los $5$ 
indicadores económicos siguientes de $50$ países durante el período 1960--1970:
\begin{description}
 * [{\tt sr}:]  la tasa de ahorro, <<*savings rate*>>, de cada país.
 * [{\tt pop15}:]  su porcentaje de población menor de $15$ años.
 * [{\tt pop75}:]  su porcentaje de población  mayor de $75$ años.
 * [{\tt dpi}:]  su renta per cápita  en dólares.
 * [{\tt ddpi}:]  su tasa  de crecimiento como porcentaje de su renta per cápita.
\end{description} 


Vamos a producir un gráfico de  burbujas de la tasa de ahorro de cada país en función de su renta per cápita, donde la 
variable <<burbuja>> será la tasa  de crecimiento; es decir, para cada país, dibujaremos una burbuja centrada en el punto de coordenadas (renta per cápita, tasa de ahorro) de diámetro proporcional a su tasa de crecimiento.
Además, colorearemos las 
burbujas según una escala de colores ocres que represente el porcentaje de la población menor de $15$ años: cuanto más oscura sea la burbuja, mayor es dicho porcentaje. El código para producir el gráfico, tras cargar los paquetes `faraway` (para tener acceso a los datos) y `RColorBrewer` (para poder definir la paleta de colores), es el siguiente:

```
> #Agrupamos los porcentajes de población menor de 15 años en 9 grupos
> porcentajes15=as.numeric(cut(savings$pop15, 9)) 
> #Definimos nuestra paleta en función de los valores de la variable anterior
> colores=brewer.pal(9,"YlOrBr")[porcentajes15]
> #Dibujamos el gráfico de burbujas
> symbols(savings$dpi, savings$sr, circles=savings$ddpi, 
   bg=colores, xlab="Renta per cápita", ylab="Tasa de ahorro") 
> #Escribimos el nombre de cada país en el centro de su burbuja       
> text(savings$dpi,savings$sr, rownames(savings), cex=0.75) 
```
 
El resultado es el gráfico de la izquierda de la Figura  \@ref(PAIS). A simple vista se puede observar, por ejemplo, que los Estados Unidos tienen la renta per cápita más alta, una tasa de ahorro entre 
moderada y baja, una tasa de crecimiento de la renta per cápita  baja y un porcentaje de población menor de $15$ años 
también  bajo; en cambio, Japón tiene una renta per cápita más baja, una tasa de ahorro y una tasa de crecimiento de 
la renta per cápita mucho más altas pero la población menor de $15$ años sigue siendo baja. También se observa que, en general,  el porcentaje de población menor de $15$ años en 
los países más desarrollados es mucho menor que en los países menos desarrollados. 

Este tipo de gráficos, tal cual los produce `R`, tienen un defecto: como los tamaños de las burbujas se indican por medio de una dimensión lineal, su área crece con el cuadrado de dicha dimensión; por ejemplo, 
en nuestro gráfico, la burbuja de un país con el doble de tasa de crecimiento que otro tiene un área cuatro veces mayor que la de este otro país. Como, instintivamente, comparamos áreas y no diámetros, 
esto puede llevar a confusión. La solución es sencilla: si queremos que las proporcionales a las tasas de crecimiento sean las áreas de los círculos, cuadrados, rectángulos, etc.,  y no sus amplitudes, 
basta entrar como dimensiones de las figuras sus raíces cuadradas. Así, sería mucho más preciso  usar el código siguiente, que produce el gráfico de la derecha de la Figura  \@ref(PAIS) y que, para nuestro gusto, representa mejor los datos.

```
> symbols(savings$dpi, savings$sr, circles=sqrt(savings$ddpi), 
   bg=colores, xlab="Renta per cápita", ylab="Tasa de ahorro") 
> text(savings$dpi,savings$sr, rownames(savings), cex=0.75) 
```



\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{Paisos.pdf}\
\includegraphics[width=0.45\linewidth]{Paisos2.pdf}
\end{center}
\caption{Gráficos de burbujas de la tasa de ahorro de los países en función de su renta per cápita, coloreadas según su porcentaje de población menor de $15$ años, y con los diámetros (izquierda) y las áreas (derecha) de las burbujas proporcionales a la tasa de crecimiento del país.}
\label{PAIS}
\end{figure}

## Gráficos de corrientes  o <<streamgraphs>>

 En los últimos 10 años se han puesto de moda un tipo de gráficos que sirven para visualizar cómo diversas cantidades varían conjuntamente a lo largo del tiempo: son los llamados `gráficos de corrientes` ,  o \textsl {streamgraphs}. Con `R` este tipo de gráficos se producen fácilmente con el paquete `streamgraph`, que aún no está disponible en el servidor de la CRAN,^[  Mayo de 2016. A lo mejor cuando leáis estas notas, sí.]   pero puede instalarse desde *GitHub*. Para ello no podemos emplear el instalador de paquetes de *RStudio* ni la función `install.packages`, sino la función específica `install\_{`github} del paquete `devtools`, aplicado al *url* del paquete (que tenemos que conocer). Así, para instalar y cargar el paquete
`streamgraph`, a día de hoy hay que ejecutar el código siguiente:
```
> #Instalamos y cargamos el paquete "devtools"
...
> install_github("hrbrmstr/streamgraph")
> library(streamgraph) #O activándolo en la ventana de paquetes 
```


Ahora que ya lo tenemos cargado,  vamos a producir un  *streamgraph* de los diferentes géneros de películas desde los años 30 hasta la actualidad. Para ello, usaremos la tabla de datos `movies`, con información de 58,788 películas, que lleva el paquete `ggplot2movies`.
```
> #Instalamos y cargamos el paquete "ggplot2movies"
...
> data(movies)
> str(movies)
Classes 'tbl_df', 'tbl' and 'data.frame':	58788 obs. of  24 variables:
 $ title      : chr  "$" "$1000 a Touchdown" "$21 a Day Once a Month" "$40,000" ...
 $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...
 $ length     : int  121 71 7 70 71 91 93 25 97 61 ...
 $ budget     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ rating     : num  6.4 6 8.2 8.2 3.4 4.3 5.3 6.7 6.6 6 ...
 $ votes      : int  348 20 5 6 17 45 200 24 18 51 ...
 $ r1         : num  4.5 0 0 14.5 24.5 4.5 4.5 4.5 4.5 4.5 ...
 $ r2         : num  4.5 14.5 0 0 4.5 4.5 0 4.5 4.5 0 ...
 $ r3         : num  4.5 4.5 0 0 0 4.5 4.5 4.5 4.5 4.5 ...
 $ r4         : num  4.5 24.5 0 0 14.5 14.5 4.5 4.5 0 4.5 ...
 $ r5         : num  14.5 14.5 0 0 14.5 14.5 24.5 4.5 0 4.5 ...
 $ r6         : num  24.5 14.5 24.5 0 4.5 14.5 24.5 14.5 0 44.5 ...
 $ r7         : num  24.5 14.5 0 0 0 4.5 14.5 14.5 34.5 14.5 ...
 $ r8         : num  14.5 4.5 44.5 0 0 4.5 4.5 14.5 14.5 4.5 ...
 $ r9         : num  4.5 4.5 24.5 34.5 0 14.5 4.5 4.5 4.5 4.5 ...
 $ r10        : num  4.5 14.5 24.5 45.5 24.5 14.5 14.5 14.5 24.5 4.5 ...
 $ mpaa       : chr  "" "" "" "" ...
 $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...
 $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...
 $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...
 $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...
 $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...
 $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...
```

De esta tabla de datos nos vamos a quedar solo con las variables `year` (año de estreno) y
`Action`, `Animation`, `Comedy`, `Drama`, `Documentary`, `Romance` y `Short`, variables binarias que indican si la película entra o no en cada una de las categorías siguientes: acción, animación, comedia, drama, documental, romántica y cortometraje, respectivamente.
```
> movies.small=movies[,c(2,18:24)]
> str(movies.small)
Classes 'tbl_df', 'tbl' and 'data.frame':	58788 obs. of  8 variables:
 $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...
 $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...
 $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...
 $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...
 $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...
 $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...
 $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...
```

Ahora hemos de modificar el *data frame* para poderlo usar como una serie temporal, donde para cada año y para cada categoría nos dé el correspondiente número de películas. La manera más sencilla es, en primer lugar, usar la función `gather`
del paquete `tidyr`, especializado en funciones para <<limpiar>> y reorganizar datos.
Con esta función podemos sustituir las variables binarias correspondientes a las categorías por 
una nueva variable factor (la llamaremos `genero`) cuyos valores sean los nombres de dichas variables   y añadir una nueva variable binaria (la llamaremos `valor`)  que da el valor de la variable binaria original.
La sintaxis es

`gather(`\df`, ``nuevo factor` `, ``nueva variable numérica` `, ``variables agrupadas` `)`

 De esta manera, en nuestro caso, cada fila de `movies.small` se convierte en 7 filas del nuevo *data frame*, una para cada variable <<agrupada>> en la nueva variable `genero`.  A continuación, observamos que menos del 0.1\% de las películas se filmaron antes de 1930, por lo que en nuestro *streamgraph* esos años van a aparecer muy delgados, así que los eliminamos.
```
> Instalamos y cargamos el paquete "tidyr"
...
> movies.agrup=gather(movies.small,genero,valor,-year) #-year indica "todas las variables menos year"
> str(movies.agrup)
Classes 'tbl_df', 'tbl' and 'data.frame':	411516 obs. of  3 variables:
 $ year  : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...
 $ genero: chr  "Action" "Action" "Action" "Action" ...
 $ valor : int  0 0 0 0 0 0 1 0 0 0 ...
> quantile(movies.agrup$year,0.001)
0.1% 
1930 
> movies.agrup=movies.agrup[movies.agrup$year>=1930,]
```

A continuación, para cada año y cada categoría, sumamos los valores de la variable `valor`: como son ceros y unos, esto nos dará, los números anuales de películas de cada categoría. Una posible manera de hacerlo es con el código siguiente (la suma de dos factores indica que agrupamos los datos por todas la combinaciones de un nivel de cada factor):
```
> sum.movies.agrup=aggregate(valor~year+genero, data=movies.agrup,
   FUN=sum)
> str(sum.movies.agrup)
'data.frame':	532 obs. of  3 variables:
 $ year  : int  1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 ...
 $ genero: chr  "Action" "Action" "Action" "Action" ...
 $ valor : int  4 5 5 6 8 17 9 14 8 17 ...
```

Y ahora ya estamos en disposición de dibujar el *streamgraph*. La función para hacerlo es

`streamgraph(`*data frame*\verb?, "?`factor` \verb?", "?`valores` \verb?", "?`tiempo` \verb?", interactive=...)? 

donde especificamos el `factor`  del *data frame* de cuyas variables queremos representar sus `valores`   a lo largo del `tiempo` . El parámetro `interactive` es muy interesante, pero por ahora lo declararemos como `FALSE`, puesto que vamos a producir un dibujo para incorporar a este pdf.
```
> streamgraph(sum.movies.agrup, "genero", "valor", "year",
   interactive=FALSE)
```
Obtenemos el gráfico de la Figura \@ref(Strgr). En este gráfico, la variable `tiempo`  (en nuestro caso, `year`) se representa en el eje horizontal, y las franjas de colores  corresponden, de abajo arriba, a los niveles ordenados del factor `genero`: la franja roja inferior a las películas de acción, la naranja inmediatamente superior a las de animación, y así hasta llegar a la franja azul de los cortometrajes. Su grueso, sobre cada año, representa el número de películas de cada género. 

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{strgr1}
\end{center}
\abovecaptionskip=-1ex

\caption{*Streamgraph* mostrando la evolución del número de películas por año y género.}
\label{Strgr}
\end{figure}

Por el momento, no se puede añadir fácilmente una leyenda al *streamgraph* producido en modo `interactive=FALSE`. Pero la gracia (que no podemos reproducir aquí pero sí que lo podéis hacer vosotros)
es producir el gráfico en modo interactivo, con `interactive=TRUE`. Entonces, al pasear el ratón sobre la figura nos muestra, en cada punto, qué categoría estamos consultando y el número de películas en ese año. Además, entrando 
```
> streamgraph(sum.movies.agrup, "genero", "valor", "year",
   interactive=TRUE)
>  sg_legend(streamgraph(sum.movies.agrup,"genero", 
   "valor", "year", interactive=TRUE), show=TRUE, 
    label="Género: ")
```
se añade a la figura un menú desplegable con los diferentes niveles del factor usado (en nuestro caso `genero`) que permite ver la evolución de ese nivel. Esta figura se puede guardar como imagen interactiva o como página web.
En la Figura \@ref(Strgr1) se puede ver una captura de pantalla del resultado.


\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{strgr2}
\end{center}
\abovecaptionskip=-1ex
\caption{Captura de pantalla del *streamgraph* anterior producido en modo interactivo.}
\label{Strgr1}
\end{figure}

## Guía rápida



* {\tt VCorpus}, del paquete `tm`, sirve para cargar un conjunto de documentos en un *VCorpus*. Sus dos parámetros son:

* `x`: indica el lugar de donde se han de cargar los documentos. Algunos posibles valores:
`DirSource("{`}`directorio` `"{`, encoding=...)} y `URISource("{`}`url` `"{`, encoding=...)}.

* `readerControl`: se ha de igualar a una `list` de dos componentes:  `reader`, que indica la función con la que se han de leer los documentos, y  `language`, que indica el idioma de los documentos. Si los ficheros son de texto, no  es necesario especificar la componente  `reader`.


* `inspect`, del paquete `tm`, nos da el número de documentos de un *VCorpus* y, de cada uno de ellos, su formato y su número de caracteres.

* `writeLines(as.character(``documento` `))` escribe el `documento`  en la consola.

* `tm\_{`map(}*VCorpus*`, ``transformación` `)`, del paquete `tm`, aplica la `transformación`  a todos los documentos del *VCorpus*. Algunas transformaciones:

* `tolower`: convierte todas las letras en minúsculas.

* `removePunctuation`: elimina los signos de puntuación.

* `removeWords`: elimina las palabras del vector que se especifique.

* `stripWhitespace`: elimina los espacios en blanco extra.

* `removeNumbers`: elimina los números.

* `stemDocument`: cargando el paquete `SnowballC`, se queda sólo con las raíces de algunas palabras.


* `stopwords`, del paquete `tm`, aplicada al nombre de un idioma, entrecomillado, produce una lista de palabras <<comodín>> de este idioma.

* `wordcloud`, del paquete homónimo, produce una nube de palabras del documento al que se aplica. Algunos parámetros destacables:

* `scale`: un vector de longitud 2 que sirve para indicar el tamaño relativo  de las palabras de mayor y menor frecuencia.

* `max.words`: el número máximo de palabras a mostrar.

* `min.freq`: la frecuencia mínima necesaria para que una palabra aparezca en el gráfico.

* `rot.per`: la proporción de palabras que se pueden mostrar giradas 90 grados.

* `colors`: la paleta de colores usada para representar las frecuencias.


%%%%%%%%%%%%%


* `heatmap` produce el mapa de colores, o *heatmap*, de la matriz a la que se aplica. Algunos parámetros importantes:

* `Rowv` y `Colv`: igualados a `NA`, impiden que se añadan dendrogramas de las filas y las columnas en los márgenes.

* `revC`: igualado a `TRUE` invierte el orden de las columnas.


* `corrplot`, del paquete homónimo, produce el   *heatmap* de la matriz de correlaciones a la que se aplica.
Algunos parámetros importantes:
 
* `method`: especifica la forma de las casillas; algunos valores posibles son `"{`circle"{}} (círculos, el valor por defecto),   `"{`square"{}} (cuadrados), `"{`shade"{}} (la casilla sombreada).

* `addshade`: cuando usamos `method="{`shade"{}}, permite especificar si queremos marcar las casillas correspondientes a correlación positiva o negativa (o ambas), mediante rectas de pendiente positiva o negativa.

* `shade.col`: permite especificar el color de las rectas anteriores; igualado a `NA`, no las añade.

* `tl.col`: el color de las etiquetas de filas y columnas.

* `tl.srt`: la inclinación de las etiquetas de filas y columnas.

* `addCoef.col`: igualado a un color, especifica que se escriban en cada casilla la entrada correspondiente de   la matriz en ese color.


* `dist`, aplicada a una matriz o a un *data frame* de variables numéricas, calcula la matriz de distancias entre sus  filas. El tipo de distancia se especifica con el parámetro `method` y por defecto es la euclídea.


%%%%%%%%%%

* `hclust` calcula un *clustering* jerárquico de una matriz de distancias calculada por medio de `dist`.
El parámetro `method` permite especificar el algoritmo concreto.

* `as.dendrogram` transforma el resultado de `hclust` en un dendrograma.

* `plot`, aplicado a un dendrograma, lo dibuja. En este contexto, aparte de los parámetros usuales, se dispone de varios parámetros específicos, entre los que destacamos:

* `type="{`triangle"{}}: dibuja las ramificaciones triangulares en vez de rectangulares.

* `horiz=TRUE`: dibuja el dendrograma horizontal.


* `labels`, aplicada a un dendrograma, nos da las etiquetas de sus hojas de izquierda a derecha y, si está cargado el paquete `dendextend`, permite también cambiar los nombres de estas etiquetas.

* `set(``dendrograma` \verb?, what="?`característica` \verb?", ?`valor` `)`, del paquete
 `dendextend`, permite modificar la `característica`  del `dendrograma` . Algunas características útiles:
 
* `labels`: los nombres de las etiquetas.
* `labels\_{`col}: los colores de las etiquetas.
* `labels\_{`cex}: el tamaño de las etiquetas.

La lista completa se puede consultar en la Ayuda de la función.

* \verb?%>%? permite indicar la aplicación sucesiva de funciones, cada una al resultado de la aplicación anterior. Así
\verb?x%>%f(Y)%>%g(Z)?
toma el objeto `x`, le aplica la función `f` con parámetros `Y` y al resultado le aplica la función `g` con parámetros `Z`; es decir, calcula `g(f(x,Y),Z)`. Esta notación solo está disponible en algunos paquetes (por ejemplo, `dendextend` y `streamgraph`).

* \verb?circlize_dendrogram?, del paquete `circlize`, dibuja un dendrograma en forma circular.

%%%%%%%%%%%

* `symbols(`$x$`, `$y$`, `*parámetro\_{*figura}`=`$z$`)` dibuja, en cada uno de los puntos de abscisa una entrada del vector $x$ y  ordenada  la correspondiente entrada del vector $y$, una figura del tipo especificado por el *parámetro\_{*figura} 
(`circles` para círculos, `squares` para cuadrados, `stars` para estrellas, etc.)
 de dimensión lineal la especificada por la  entrada correspondiente del vector $z$. Otros parámetros de interés, aparte de los usuales de la función `plot`:

 * `fg`: el color de la frontera de los símbolos.
 * `bg`: su color de relleno.


%%%%%%%%%%%%%%

* `install\_{`github("{}}`url` `"{`)}, del paquete `devtools`, instala un paquete del que conocemos su `url`  en *GitHub*.

* `gather`, del paquete `tidyr`, sustituye en un *data frame* un conjunto de variables numéricas por dos variables: un factor cuyos niveles son los nombres de las variables numéricas originales y una variable numérica nueva que da, para cada nivel de ese factor, el valor de la variable original. De esta manera, cada fila del *data frame* original se desdobla en tantas filas como variables hemos agrupado en el nuevo factor.

* `streamgraph`, del paquete homónimo, dibuja el *streamgraph* de tres variables de un \df: una variable temporal, un factor, y una variable que para cada valor de la variable temporal y para cada nivel del factor nos da un valor numérico. Dispone del parámetro `interactive`, que igualado a `FALSE` produce un gráfico estático e igualado a `TRUE` produce un gráfico interactivo.

* `sg\_{`legend}, del paquete `streamgraph`, aplicada a un *streamgraph* producido en modo interactivo y a los  parámetros `show=TRUE` y `label` igualado a un nombre que represente el factor del *streamgraph*, añade un menú desplegable con los diferentes valores del factor.








# Tests {#chap:tests}

\newcommand \retro[1]{\textcolor{blue}{#1}}

## Test de la Lección 1


[\bf (1)]

* ¿Cuánto vale $\dfrac{5\cdot \log_{3}(\sqrt{2})}{7\cdot \sqrt[5]{e^{-3}}}$, redondeado a 4 cifras decimales?
[(a)]
* $0.4106$  \retro{¡Correcto!}
* $0.1237$  \retro{¿No te habrás dejado los paréntesis del denominador?}
* $0.4511$ \retro{¿No te habrás dejado la base del logaritmo?}
* Ninguna de las anteriores   \retro{Sí que es una de las anteriores}


* ¿Cuál  de estas expresiones evalúa correctamente $1.5^{-3}-\dfrac{2^7}{7\sqrt{2}}(2+(-1)^6)$?
[(a)]
* \verb?1.5^(-3)-(2^7/(7*sqrt(2)))*(2+-1^6)?  \retro{No es lo mismo $-1^6$ que $(-1)^6$}
* \verb?1.5^(-3)-2^7/7*sqrt(2)*(2+(-1)^6)?   \retro{¿Te has dejado los paréntesis del denominador?}
* \verb?1.5^(-3)-(2^7/7*sqrt(2))*(2+(-1)^6)?   \retro{¿Te has dejado los paréntesis del denominador?}
* Ninguna de las anteriores  \retro{¡En efecto! El denominador y el -1 han de ir entre paréntesis; el resultado correcto es -38.49356}



* ¿Cuánto vale $\sin(37^{\mathrm{o}})$, redondeado a 4 cifras decimales?
[(a)]
* $-0.6435$   \retro{Pedimos el seno de 37 grados, no de 37 radianes}
* $0.6018$    \retro{¡En efecto!}
* $0.5901$  \retro{¿Cómo has transformado grados en radianes?}
* Ninguna de las anteriores  \retro{Sí que es una de las anteriores}


* ¿Qué número representa 3.3333e10?
[(a)]
* $3.3333\cdot e^{10}$   \retro{¿Qué significa la e en 3.3333e10?}
* $33.333$    \retro{¿Qué significa la e en 3.3333e10?}
* 33333000000  \retro{¡Muy bien!}
* 333330000000000    \retro{¿Has tenido en cuenta el punto decimal?}


* ¿Cuál es la última cifra decimal de $\sqrt{3}^e$ redondeado a 5 cifras decimales?
[(a)]
* 7  \retro{No has redondeado bien}
* 8   \retro{¡Correcto!}
* 2  \retro{¿No habrás usado print(...,5) para redondear a 5 cifras?}
* Ninguna de las anteriores  \retro{Sí que es una de las anteriores}







## Test optativo de la Lección 1


[\bf (1)]




* ¿Qué vale el módulo de $\dfrac{(2+3i)^2}{(5+i)(6-2i)}$,  redondeado a 2 cifras decimales?
[(a)]
*  $16.12$   \retro{¿No te habrás dejado los paréntesis del denominador?}
* $-0.2+0.35i$   \retro{Pedíamos el módulo, no el número complejo}
* $0.4$  \retro{¡Correcto!}
* $0.11$  \retro{¿No te habrás dejado el cuadrado del numerador?} 


* ¿Qué vale la parte real de  $(1.5-\sqrt{2}i)^{10}$,  redondeada a 3 cifras decimales?
[(a)]
*  402.188   \retro{¡En efecto!}
* 1386.579  \retro{Pedíamos la parte real, no el módulo}
* 57.665    \retro{La parte real de una potencia no es la potencia de la parte real}
* Ninguna de las anteriores   \retro{Sí que es una de las anteriores}



* ¿Qué vale el argumento de  $3-\frac{5}{7}i$, expresado en grados y  redondeado a 2 cifras decimales?
[(a)]
*    0.62 \retro{Has cometido dos errores: has especificado mal $3-\frac{5}{7}i$ y has dado el argumento en radianes}
*   35.54 \retro{¿Cómo has especificado $3-\frac{5}{7}i$? Esos paréntesis...}
*   0.23  \retro{Pedíamos el argumento en grados, no en radianes}
*  13.39  \retro{¡Correcto!}






%%%%%%%%%%%%%%%%%%%%%%%

## Test de la Lección 2

[(1)]

* Consideremos los pares de datos
$$
\begin{array}{l}
(1,-0.41),  (2,-3.8),  (3,-6.32), (4, -9.98), (5,-11.86), (6,-15.55),\\ (7,-18.2), (8, -21.74).
\end{array}
$$
Si denotamos su primera coordenada por $x$ y la segunda por $y$, ¿cuál es la recta de regresión por mínimos cuadrados de $y$ en función de $x$, redondeando sus coeficientes a 3 cifras decimales?
[(a)]
* $y=2.457-2.987 x$  \retro{¡Perfecto!}
* $y=2.457x-2.987$   \retro{Has intercambiado los coeficientes}
* $y=0.832-0.334x$  \retro{Pedíamos la recta de regresión de y en función de x}
* Ninguna de las anteriores  \retro{Sí que es una de las anteriores; ve con cuidado al copiar los datos}



* Consideremos los pares de puntos
$$
(1,4.35),  (2,6.05),  (3,7.54), (4, 7.55), (5,12.92), (6,14.2), (7,19.28), (8, 25.06).
$$
Si denotamos su primera coordenada por $x$ y la segunda por $y$, ¿qué vale el $R^2$ de la regresión  por mínimos cuadrados de $\ln(y)$ en función de $x$, redondeado a 4 cifras decimales?
[(a)]
* 0.9732  \retro{No has mirado el R-squared correcto}
* 0.9176  \retro{¿Has visto que pedíamos la regresión del logaritmo de y en función de x?}
* 0.977 \retro{¡Correcto!}
* Ninguna de las anteriores  \retro{Sí que es una de las anteriores; ve con cuidado al copiar los datos}



* Consideremos los pares de puntos
$$
(1,4.06),  (2,19.16),  (3,49.38), (4, 94.13), (5,167.54), (6,266.41), (7,388), (8, 541.88).
$$
Si denotamos su primera coordenada por $x$ y la segunda por $y$, ¿qué tipo de dependencia explica mejor $y$ como función de $x$?
[(a)]
* Lineal  \retro{Dibuja el gráfico en escala lineal: ¿están los puntos aproximadamente sobre una recta?}
* Exponencial  \retro{Dibuja el gráfico en escala semi-logarítmica: ¿están los puntos aproximadamente sobre una recta?}
* Potencial  \retro{¡Efectivamente! De hecho, el $R^2$ de la regresión lineal de log(y) en función de log(x) es 0.9993} 
* Las tres por igual \retro{Dibuja los gráficos en las diferentes escalas y comprueba que sólo en uno de ellos los puntos están aproximadamente sobre una recta}








## Test de la Lección 3


[(1)]


* ¿Cuál de las instrucciones siguientes crea un vector `Pueblos` formado por las palabras Palma, Inca, Manacor, Calvià?


[(a)]
*  \verb?Pueblos=c(Palma,Inca,Manacor,Calvià)?   \retro{¿Has probado a ejecutarla? Faltan las comillas}
* \verb?Pueblos=c("Palma","Inca","Manacor","Calvià")?    \retro{¡Perfecto!}
* \verb?Pueblos=c("Palma" "Inca" "Manacor" "Calvià")?  \retro{¿Has probado a ejecutarla? Faltan las comas separando las entradas del vector}
* \verb?Pueblos=scan("Palma","Inca","Manacor","Calvià")? \retro{¿Has probado a ejecutarla? Así no se usa scan}


* Si en la secuencia  de números enteros consecutivos que va de -7 a 20 cambiamos su penúltimo elemento por un 30, ¿qué vale la media aritmética del vector resultante, redondeada a 3 cifras decimales?

[(a)]
*   6.929   \retro{¡El penúltimo elemento, no el antepenúltimo!}
*  7.786  \retro{¡El penúltimo elemento, no el segundo!}
* 6.893  \retro{¡Correcto!}
*  6.5 \retro{Esta es la media del vector original, del que pedíamos}



* ¿Cuál de estas instrucciones define el vector de palabras  (a, b, a, b, a, b, a, b)?

[(a)]
*   \verb?rep(c(a,b), times=4)?   \retro{Esas comillas...}
*  \verb?rep(c(a,b), each=4)?  \retro{Esas comillas...}
* \verb?rep(c("a","b"), times=4)?  \retro{¡Muy bien!}
*  \verb?rep(c("a","b"), each=4)?  \retro{Ejecútala,  a ver si da lo que pedimos...}



* La secuencia $(2\cdot 3^n-4\cdot 2^n)_{n=1, ... , 500}$, ¿contiene algún término igual a 150000?

[(a)]
*  Sí  \retro{¿Seguro? ¿Para qué índice n?}
*  No  \retro{¡En efecto!}




* ¿Cuál es el primer $n\in \mathbb{N}$ tal que  $2\cdot 3^n-4\cdot 0.8^n\geq 10^6$? 

[(a)]
*  12    \retro{¡Correcto!}
*  13    \retro{Hay un n más pequeño que lo cumple}
*  14   \retro{Hay un n más pequeño que lo cumple}
* Ninguna de las anteriores  \retro{Sí que es una de las anteriores}




* ¿Qué vale el mínimo de la secuencia $(2\cdot 3^n-4\cdot 2.5^n)_{n=0, ... , 100}$?

[(a)]
*  3   \retro{¿Seguro que has calculado el mínimo, y no el exponente n correspondiente?}
*  4  \retro{¿Seguro que has calculado el mínimo, y no su posición en el vector?}
*  $-8.5$    \retro{¡En efecto!}
* Aproximadamente $-10^{100}$  \retro{Repasa cómo has definido el vector}


* ¿Cuál es el primer $n\in \mathbb{N}$ tal que $\displaystyle \sum\limits_{k=0}^n \frac{e^k}{k+1}\geq 10^6$?

[(a)]
*  17    \retro{¡Correcto!} 
*  18   \retro{Hay un n más pequeño que lo cumple}
*  1   \retro{¿No te habrás olvidado de los paréntesis de los denominadores?}
* No existe   \retro{Sí que existe}


* ¿Qué vale $\displaystyle\sum_{n=0}^{30} (n+(n-2)e^{-n})$, redondeado a 4 cifras decimales?

[(a)]
*   926.836   \retro{¿Te has dejado el paréntesis alrededor del n-2 al definir el vector?}
*   462.7567    \retro{¡Perfecto!} 
*   464.7567   \retro{¿Has empezado a sumar en n=1, en vez de en n=0?}
* Ninguna de las anteriores  \retro{Sí que es una de las anteriores}


* ¿Cuál de las instrucciones siguientes define un factor llamado F01 a partir del vector (0, 1, 0, 0, 1, 0), asignando al 0 y al 1 los niveles <<No>> y <<Sí>>, respectivamente?

[(a)]
*   \verb+F01=factor(c(0,1,0,0,1,0), labels=c(No,Sí))+   \retro{Ejecútala, a ver...  ¿No faltan unas comillas?}
*   \verb+F01=as.factor(c(0,1,0,0,1,0), labels=c("No","Sí"))+ \retro{Ejecútala, a ver...  ¿Seguro que hay que usar as.factor?} 
* \verb+F01=factor(c(0,1,0,0,1,0), labels=c("No","Sí"))+  \retro{¡Correcto!}
*   \verb+F01=factor(c(0,1,0,0,1,0), levels=c("No","Sí"))+   \retro{Ejecútala, a ver...  ¿Cómo se especifican los nombres de los niveles?}







## Test de la Lección 4

[(1)]

* ¿Cuál de las instrucciones siguientes construye la matriz
$\left(\begin{array}{ccc} 1 & 5 & 3\\ 2 & 3 & 9\end{array}
\right)$?
[(a)]
*  \verb!matrix(c(1,5,3,2,3,9), nrow=2)!  \retro{Éntrala y comprueba que no es cierto}
*  \verb!matrix(c(1,5,3,2,3,9), nrow=2, byrow=TRUE)!  \retro{¡Correcto!} 
*  \verb!matrix(c(1,5,3,2,3,9), ncol=3)!  \retro{Éntrala y comprueba que no es cierto}
*  \verb!matrix(c(1,5,3,2,3,9), nrow=2, bycol=FALSE)!   \retro{Éntrala y comprueba que no es cierto}



* ¿Cuál de las instrucciones siguientes construye la matriz
$\left(\begin{array}{ccc} 1 & 5 & 3\\ 2 & 3 & 9\end{array}
\right)$?

[(a)]
* \verb!rbind(c(1,5,3),c(2,3,9))!    \retro{¡Muy bien!} 
* \verb!cbind(c(1,5,3),c(2,3,9))!  \retro{Éntrala y comprueba que no es cierto}
* \verb!rbind(c(1,5,3,2,3,9), nrow=2)!    \retro{Éntrala y comprueba que no es cierto}
* \verb!rbind(c(1,2),c(5,3),c(3,9))! \retro{Éntrala y comprueba que no es cierto}


* ¿Cuál de las instrucciones siguientes nos da la octava columna de una matriz llamada $M$?

[(a)]
* \verb!M[8, ]!   \retro{Esto nos da la octava fila}
* \verb!M[ ,8]!   \retro{¡Excelente!} 
* \verb!M[8,8]!  \retro{Esto es la entrada (8,8)}
* \verb!M[8]!  \retro{Esto es la octava entrada de la matriz, recorriéndola por columnas}



* ¿Qué vale la suma de los inversos de las entradas de la tercera columna de la matriz definida mediante A=matrix(1:200, ncol=4), redondeada a 3 cifras decimales?

[(a)]
* 0.368  \retro{Esto es el resultado para la tercera fila}
* 5.878   \retro{Esta es la suma de los inversos de todas las entradas de la matriz} 
* 0.404  \retro{¡En efecto!} 
* 6275  \retro{Esta es la suma de las entradas de la tercera columna de A}







## Test optativo de la Lección 4

[(1)]

* ¿Qué vale la entrada $(1, 2)$ de $A\cdot (A+ A^t)\cdot A$, donde $A=\left(\begin{array}{cc} 1 & 3 \\ 2 & 4 \end{array}\right)$ y $A^t$ indica su traspuesta?

[(a)]
*  45   \retro{¿Cómo has multiplicado las matrices?}
* 108  \retro{¿Cómo has definido la matriz A?}
* 167  \retro{¡En efecto!} 
* La operación no se puede realizar    \retro{Sí que se puede realizar}


* Sea $A=\left(\begin{array}{cccc}
1 & 5 & 3\\ 2 & 3 & 9\\ 4 & 1 & 1\end{array}
\right)$. ¿Qué vale el determinante de $A^2+A$?

[(a)]
* $50592$  \retro{¿Cómo has definido el cuadrado de A?}
* $18090$   \retro{No confundas el determinante de una suma con la suma de los determinantes}
* $15544$      \retro{¡Muy bien!} 
* Ninguna de las  anteriores  \retro{Sí que es una de las anteriores}



* ¿Qué vale la entrada $(2, 3)$ de la inversa de la matriz $\left(\begin{array}{ccc} 1 & 5 & 3\\ 2 & 3 & 9\\ 4 & 1 & 1\end{array}\right)$, redondeada a 4 cifras decimales?


[(a)]
*  0.1111  \retro{¿Cómo has calculado la inversa?}
* 0.1418  \retro{¿Cómo has definido la matriz?}
* $-0.0224$  \retro{¡Correcto!}
* Esta inversa no existe \retro{Sí que existe}





* ¿Qué vale $y$ en la solución del sistema 
$$
\left.\begin{array}{r} x+5y+3z  = 1\\ 2x+3y+9z  =1\\ 4x+y+z  = 1\end{array}
\right\},
$$
redondeado a 4 cifras decimales?


[(a)]
*  0.0448  \retro{¿Cómo has definido la matriz del sistema?} 
* El sistema no tiene solución única   \retro{La solución es única}
* El sistema no tiene solución    \retro{Sí que tiene}
* 0.1493  \retro{¡Muy bien!}  



* ¿Cuál es la multiplicidad de 2 como valor propio de la matriz
$\left(\begin{array}{ccc}
2 & 4 & -6 \\ 0 & 0 & 3 \\ 0 & -2 & 5
\end{array}
\right)$?


[(a)]
*  No es valor propio  \retro{Sí que es valor propio}
* 1 \retro{¿Cuántas veces aparece 2 en la lista de vectores propios?}
* 2  \retro{¡Perfecto!}
* 3 \retro{¿Cuántas veces aparece 2 en la lista de vectores propios?}


* ¿Qué vale la segunda entrada del vector propio de valor propio $3$ que da 
`R` para la matriz $\left(\begin{array}{ccc}
-48 & 35 & -12\cr -134 & 95 & -32\cr -194 & 133 &-44
\end{array}
\right)$, redondeado a 4 cifras decimales?


[(a)]
*  0.5071  \retro{La pedimos del vector propio de valor propio 3, no -3}
* -0.1952 \retro{La pedimos del vector propio de valor propio 3, no del tercer vector propio}
* 0.169 \retro{¿Esta es la SEGUNDA entrada del vector propio de valor propio $3$?}
* Ninguna de las anteriores, porque 3 no es valor propio de $A$  \retro{¡Muy bien visto!}




## Test de la Lección 5

[(1)]

* ¿Cuál de las instrucciones o secuencias de instrucciones siguientes dibuja la gráfica de la función $y=x^3-3x^2+5$  para $x$ entre $-15$ y $15$, con el trazo de la curva el doble de grueso que su valor por defecto, y la titula  <<Una cúbica>>?


[(a)]
* \verb!plot(x^3-3*x^2+5,xlim=c(-15,15),lwd=2,main="Una cúbica")!   \retro{Éntrala y comprueba que no es cierto; plot no se puede aplicar así a una función}
* \verb!curve(x^3-3*x^2+5,xlim=c(-15,15),lwd=2,main="Una cúbica")!   \retro{¡Perfecto!}  
* \verb!curve(x^3-3x^2+5,xlim=c(-15,15), lwd=2,main="Una cúbica")!     \retro{Éntrala: R te explicará qué haces mal}
* \verb!f=function(x){x^3-3*x^2+5}; plot(f,xlim=c(-15,15),lwd=2,main=Una cúbica)! \retro{Éntrala: R te explicará qué haces mal}


* ¿Cuál de las instrucciones  siguientes dibuja un gráfico de los puntos $(n, n^2)$, para $n=0, ... , 10$, representados como cuadraditos llenos unidos por líneas de puntos?


[(a)]
* \verb!plot((0:10)^2,pch=15,type="o",lty="dotted")!  \retro{Estás dibujando los puntos (1,0), (2,1), (3,4)...}
* \verb!plot(0:10,0:10^2,pch=15,type="o",lty="dotted")!  \retro{Éntrala: R te  explicará qué haces mal}
* \verb!plot(0:10,(0:10)^2,pch=15,type="o",lty="dotted")!  \retro{¡En efecto!} 
* \verb!plot(n,n^2,xlim=c(0,10),pch=15,type="o",lty="dotted")! \retro{¿Quién es n?}



* ¿Cuál de las secuencias de instrucciones  siguientes dibuja un gráfico conjunto de las funciones $y=2x^2$ e $y=3x^3$, para $x$ entre $-20$ y $20$, con el eje de las ordenadas sin etiqueta y rango entre $-100$ y $250$, con la primera curva continua y la segunda discontinua?

[(a)]
*  \verb!curve(2*x^2,xlim=c(-20,20),ylim=c(-100,250));!\\ \verb!curve(3*x^3,ylab="",lty="dashed",add=TRUE)! \retro{Éntralas, y verás que el eje de ordenadas tiene etiqueta}
*  \verb!curve(2*x^2,xlim=c(-20,20),ylim=c(-100,250),ylab="");!\\ \verb!curve(3*x^3,lty="dashed")! \retro{Éntrala: ¿salen las dos curvas?}
*  \verb!curve(2*x^2,xlim=c(-20,20),ylim=c(-100,250),ylab="");!\\ \verb!curve(3*x^3,lty="dashed",add=TRUE)!  \retro{¡Correcto!}
*  \verb!plot(2*x^2,xlim=c(-20,20),ylim=c(-100,250),ylab="");!\\ \verb!curve(3*x^3,lty="dashed",add=TRUE)!  \retro{Éntrala y comprueba que no es cierto; plot no se puede aplicar así a una función}



\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\textwidth]{test1.pdf}
\end{center}
\caption{Gráfico de la pregunta 4 del modelo de test.}\label{fig:test1} 
\end{figure}



* La leyenda del gráfico de la Figura \@ref(fig:test1) ha sido producida por una de las instrucciones siguientes. ¿Cuál?

[(a)]
*   \verb!legend("topleft",!\\
\verb! legend=c(expression(2^x),expression(3^x),expression(4^x)),!\\
\verb! col=c("red","black","blue"),!\\
\verb! lwd=rep(2,3),lty=c("dashed","solid","dotted"))!  \retro{¡Muy bien!}
*  \verb!legend(0,0,!\\
\verb! legend=c(expression(2^x),expression(3^x),expression(4^x)),!\\
\verb! col=c("red","black","blue"),!\\
\verb! lwd=rep(2,3),lty=c("dashed","solid","dotted"))! \retro{La esquina superior izquierda no es la posición (0,0)}
*   \verb!legend("topleft",!\\
\verb! legend=c(expression(2^x),expression(3^x),expression(4^x)),!\\
\verb! col=c("black","red","blue"),!\\
\verb! lwd=rep(2,3),lty=c("solid","dashed","dotted"))!  \retro{Comprueba el orden de los colores}
* \verb!legend("topleft",!\\
\verb! legend=c("2^x","3^x","4^x"),lwd=rep(2,3),!\\
\verb! col=c("red","black","blue"),lty=c("dashed","solid","dotted"))! \retro{Compara los nombres de las curvas en la leyenda del gráfico: queríamos que aparecieran matemáticamente bien formateados}




* ¿Cuál de las instrucciones siguientes añade al gráfico activo los puntos  $(1,2)$ y $(3,4)$ representados como circulitos llenos?
[(a)]
*   \verb!points(c(1,3),c(2,4),pch=2)!  \retro{¿pch=2?}
*   \verb!points(c(1,2),c(3,4),pch=2,type="s")!  \retro{Compruébalo añadiéndola a un gráfico concreto, a ver...}
*   \verb!points(c(1,2),c(3,4),pch=20)!  \retro{Esto son los puntos (1,3) y (2,4)}
*   \verb!points(c(1,3),c(2,4),pch=20)!  \retro{¡Correcto!}



* ¿Cuál de las instrucciones siguientes añade al gráfico activo  la recta $y=3x+5$ representada como una línea discontinua?
[(a)]
*   \verb!abline(3,5,lty="dashed")!   \retro{Mira en qué orden se han de entrar los coeficientes de la recta}
* \verb!abline(5,3,lty="dashed")!  \retro{¡Pefecto!}
 *  \verb!abline(v=3,h=5,lty="dashed")!  \retro{¡Esto añade dos rectas!}
*   \verb!lines(3,5,lty="dashed")!  \retro{lines sirve para añadir rectas poligonales}



* ¿Cuál de las instrucciones siguientes añade  al gráfico activo  la recta vertical $x=2$ de color rojo?
[(a)]
*  \verb!abline(v=2,col="red")!  \retro{¡En efecto!}
*  \verb!abline(x=2,col="red")!      \retro{¿Qué parámetro se usa para especificar una recta vertical?}
*   \verb!lines(v=2,col="red")! \retro{lines sirve para añadir rectas poligonales}
*   \verb!abline(2,0,col="red")!     \retro{Esto añade la recta y=2+0*x}



* ¿Cuál de las instrucciones siguientes añade  al gráfico activo  el texto <<$(2,3)$>> a la derecha de las coordenadas $(2,3)$?
[(a)]
*  \verb!text(2,3,labels="(2,3)",pos=2)! \retro{Mira el significado de los valores de pos}
*  \verb!text(2,3,labels="(2,3)",pos=4)!  \retro{¡Perfecto!}
*  \verb!text(2,3,text="(2,3)",pos=4)! \retro{¿Con qué parámetro se especifica el texto?}
*  \verb!text(2,3,labels="(2,3)",pos="right")! \retro{Mira cuáles son los posibles valores de pos}





%%%%%%%%%%%%%


## Test de la lección 6

[(1)]

* El *data frame* `CO2` es uno de los que lleva predefinidos `R`. ¿Qué vale la variable `conc` para la observación correspondiente a la cuadragésima quinta fila?
[(a)]
*  250  \retro{¡Correcto!}
*  26.2   \retro{Te has equivocado de columna}
*  500 \retro{Te has equivocado de fila}
*  Esa fila no existe  \retro{Sí que existe}



* El *data frame* `CO2` es uno de los que lleva predefinidos `R`.  ¿De qué clase es su variable `Plant`?
[(a)]
*   Un factor simple  \retro{Consulta str(CO2). En la fila correspondiente a Plant, ¿pone factor a secas?}
*   Un vector de palabras \retro{Consulta str(CO2). En la fila correspondiente a Plant, ¿pone chr?}
*   Un factor ordenado  \retro{¡En efecto!}
*   Un *data frame*   \retro{Una variable no puede ser un data frame}



* El *data frame* `CO2` es uno de los que lleva predefinidos `R`. Crea un *data frame* llamado `CO2.bk` que contenga una copia exacta de esta tabla. ¿Cuál de las instrucciones siguientes redefine  este *data frame*  `CO2.bk` de manera que su variable `Treatment` sea un vector de palabras?

[(a)]
*   `Treatment=as.character(CO2.bk\$Treatment)`    \retro{Esto no redefine la variable del data frame}
*   `as.character(CO2.bk\$Treatment)`    \retro{Esto no redefine la variable del data frame}
*   `CO2.bk\$Treatment=as.character(CO2.bk\$Treatment)`  \retro{¡Muy bien!}
*   `CO2.bk\$Treatment=as.character(Treatment)`   \retro{¿Quién es Treatment, a secas?}



* Define un *data frame* con la tabla que encontrarás en [http://bioinfo.uib.es/~recerca/RMOOC/heartatk4R.txt](http://bioinfo.uib.es/~recerca/RMOOC/heartatk4R.txt) . ¿Cuántas mujeres  de las recogidas en esta tabla (su variable `SEX` vale `F`) murieron (su variable `DIED` vale 1)? 

[(a)]
* 0  \retro{¿Te has dejado las comillas en la F, al definir las filas cuyas variable SEX vale F?}
*  5065  \retro{Este es el número total de mujeres}
*   1410 \retro{Este es el número total de individuos que murieron}
*  767   \retro{¡Efectivamente!}  



* El *data frame* `DNase` es uno de los que lleva predefinidos `R`. Crea un *data frame* llamado `DNase.bk` que contenga una copia exacta de esta tabla, y a continuación añádele una nueva fila donde la variable `Run` tome el valor 5, la variable `conc` tome el valor 0.5 y la variable `density` tome el valor 2.3. ¿Qué vale la media, redondeada a 4 cifras decimales, de los valores de la variable  `density` en las filas del *data frame* resultante cuyo valor de la variable `Run` sea 5?

[(a)]
*   0.7192  \retro{Esta es la media de la variable density completa en el data frame DNase original} 
*   0.7046  \retro{¿Has añadido la fila que te pedíamos?} 
*   0.7281 \retro{Has añadido bien la fila, pero esta es la media de la variable density completa} 
*  0.7985   \retro{¡Estupendo!} 



* Define un *data frame* con la tabla [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) . ¿Qué valor, o valores, de la variable `Year` contienen las filas que toman el valor máximo de la variable `BH`?

[(a)]
*   $-3300$  \retro{¿Has buscado todas las filas con el valor máximo de BH?}
*   $-1850$ \retro{¿Has buscado todas las filas con el valor máximo de BH?}
*   $-3300$ y $-1850$   \retro{¡Correcto!}
*  Ninguna de las anteriores   \retro{Sí que es una de las anteriores}




* Define un *data frame* con la tabla [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) . ¿Cuál es el  año (`Year`) con valor medio de la variable `BH` mayor?

[(a)]
* $-4000$  \retro{Calcúlalo bien, hay un año cuyo  valor medio de BH es mayor}
*  $-3300$  \retro{Calcúlalo bien, hay un año cuyo  valor medio de BH es mayor}
*   $-1850$   \retro{¡Sí señor!}
*   Todos tienen el mismo valor medio de `BH`  \retro{No, hay un año en el que el valor medio de BH es mayor que en el resto}






## Test de la lección 7


[(1)]



* ¿Cuál de las instrucciones siguientes calculan la tabla de frecuencias relativas de un vector llamado `Provincia` ?

[(a)]
* \verb!prop.table(table("Provincia"))!   \retro{Las comillas sirven para entrar palabras, no vectores}
*  \verb!prop.table(Provincia)!   \retro{prop.table se aplica a una tabla, no a un vector}
*   \verb!prop.table(table(Provincia))!  \retro{¡Perfecto!}
*   \verb!table(prop.table(Provincia))! \retro{prop.table se aplica al resultado de table, no al revés}


* Queremos calcular la tabla bidimensional conjunta de frecuencias relativas de dos factores llamados `Sexo`  y `Especie` , de manera que las filas correspondan a los niveles del factor `Especie` , las  columnas a los niveles del factor  `Sexo`  y las frecuencias relativas se calculen dentro de las filas. ¿Cuál de las instrucciones siguientes lo hace?


[(a)]
* \verb!prop.table(Especie,Sexo, margin=1)!  \retro{prop.table se aplica a una tabla}
*  \verb!prop.table(table(Sexo,Especie), margin=2)!   \retro{Las filas son los niveles de la primera variable}
*   \verb!prop.table(table(Especie,Sexo), margin=1)!  \retro{¡Correcto!}
*   \verb!prop.table(table(Especie,Sexo), margin=2)!  \retro{margin=2 calcula frecuencias relativas marginales por columnas}


* Tenemos un factor `flores` que contiene 5 copias de `setosa`, 7 copias de `versicolor` y 8 copias de  `virginica`.  ¿Cual de las instrucciones siguientes produce el diagrama de barras de la Figura \@ref(fig:test3)?

[(a)]
* \verb!barplot(table(flores))!  \retro{El gráfico de la figura es un diagrama de barras de frecuencias relativas}
*  \verb!barplot(prop.table(table(flores)))!  \retro{¡En efecto!}
*   \verb!barplot(prop.table(flores))! \retro{prop.table se aplica a una tabla, no  a un vector}
*   \verb!barplot(as.numeric(flores)/length(flores))! \retro{Construye un factor como el descrito en el enunciado y prueba sobre él esta instrucción, a ver qué da}



\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.45\textwidth]{figtest1.pdf}
\end{center}
\caption{Diagrama de barras de la pregunta (3) del test.}\label{fig:test3}
\end{figure}


* ¿Cuál es la moda  de la variable `MB` de la tabla de datos que encontraréis en el `url`  [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) ?

[(a)]
*  131  \retro{Hay más de un valor con la misma frecuencia}
*   131 y 138    \retro{¡Muy bien!}
*   138 \retro{Hay más de un valor con la misma frecuencia}
*   131, 132, 133 ,134, 135, 136, 137 y 138  \retro{No todos estos valores tienen la misma frecuencia}


* Tenemos dos variables cualitativas, `A`  y `B` , que contienen observaciones sobre los mismos individuos en el mismo orden. Los niveles de `A`  son `a1` y `a2`, y los de `B`  son `b1` y `b2`. Supongamos que ejecutamos la instrucción
`prop.table(table(A,B), margin=2)`.
¿Cuál de las afirmaciones siguientes sobre la tabla que obtenemos es verdadera?

[(a)]
*  Las filas de la tabla corresponden a los niveles de $A$, y la entrada en la posición (`a1`,`b1`)
 es la frecuencia relativa de los individuos de tipo `b1` dentro del conjunto de los individuos de tipo `a1`
 \retro{Mira bien el significado de margin=2}
 
*   Las filas de la tabla corresponden a los niveles de $A$, y la entrada en la posición (`a1`,`b1`) es la frecuencia relativa de los individuos de tipo `a1` dentro del conjunto de los individuos de tipo `b1`  \retro{¡Bien visto!}

*   Las filas de la tabla corresponden a los niveles de $B$, y la entrada en la posición (`b1`,`a1`) es la frecuencia relativa de los individuos de tipo `b1` dentro del conjunto de los individuos de tipo `a1`
 \retro{Mira bien qué variable define las filas de la tabla}
 
*   Las filas de la tabla corresponden a los niveles de $B$, y la entrada en la posición (`b1`,`a1`)  es la frecuencia relativa de los individuos de tipo `a1` dentro del conjunto de los individuos de tipo `b1`  \retro{Mira bien qué variable define las filas de la tabla}




* ¿Cuál es la frecuencia relativa, redondeada a 2 cifras decimales, del valor 50 en la variable `NH` de la tabla de datos que encontraréis en el `url` 
  [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) ?

[(a)]
*   0.01 \retro{¿Has aplicado prop.table a table?}
*  20 \retro{Esta es la frecuencia absoluta}
* 0.13 \retro{¡Correcto!}
*  Ninguna de las anteriores  \retro{Sí que es alguna de las anteriores}



* Considerad la tabla de datos que encontraréis en el `url`  [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) . Entre las filas de esta tabla de datos que toman el valor 55  en la variable `NH`, ¿qué porcentaje representan las que toman el valor  $-1850$ en la variable `Year`? Redondead  a dos cifras decimales.


[(a)]
*  20\% \retro{Este es el porcentaje de filas que toman el valor 55 en la variable NH y el valor  -1850 en la variable Year}
*  33.33\%  \retro{¡Muy bien!}
*   10\%  \retro{Este es el porcentaje de filas que toman el valor 55 en la variable NH, en el total de filas que toman el valor  -1850 en la variable Year}
*   3\% \retro{¿Seguro que has calculado frecuencias relativas, y no absolutas?}



* El objeto de datos `HairEyeColor` que lleva predefinido `R` es una tabla de contingencia de tres factores, color de cabello (`Hair`), color de los ojos (`Eye`) y sexo (`Sex`) para un cierto conjunto de individuos (véase la página \pageref{page:HES}). ¿Qué porcentaje de hombres en esta tabla son pelirrojos y tienen los ojos verdes?  Redondead  a dos cifras decimales.

[(a)]
*  9.86\%  \retro{¿Respecto de qué variable has calculado las frecuencias relativas marginales?}
*   2.51\%  \retro{¡Correcto!}
*   1.18\%  \retro{¿Respecto de qué variable has calculado las frecuencias relativas marginales?}
*   20.59\% \retro{¿Respecto de qué variable has calculado las frecuencias relativas marginales?}


* Guardad la tabla de datos [http://bioinfo.uib.es/~recerca/RMOOC/NotaHermanos.txt](http://bioinfo.uib.es/~recerca/RMOOC/NotaHermanos.txt)  en un *data frame* llamado `NH`. ¿Cuál de las instrucciones siguientes dibuja la Figura \@ref(fig:test2)? Se trata del diagrama de barras por bloques de las frecuencias relativas de los niveles de la variable `Hermanos`  dentro de cada nivel de la variable `Grado` de este *data frame*.

[(a)]
* \verb!barplot(prop.table(table(NH$Hermanos,NH$Grado),margin=1),beside=TRUE)!  \retro{¿Qué frecuencias relativas marginales se calculan con margin=1?}
*  \verb!barplot(table(NH$Hermanos,NH$Grado),beside=TRUE)!  \retro{El diagrama de barras de la figura es de frecuencias relativas}
*   \verb!barplot(prop.table(table(NH$Hermanos,NH$Grado)),beside=TRUE)!  \retro{El diagrama de barras de la figura es de frecuencias relativas marginales}
*   \verb!barplot(prop.table(table(NH$Hermanos,NH$Grado),margin=2),beside=TRUE)!   \retro{¡Perfecto!}




\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.45\textwidth]{figtest2.pdf}
\end{center}
\caption{Diagrama de barras de la pregunta (9) del test.}\label{fig:test2}
\end{figure}


## Test de la Lección 8

[(1)]


*  Tenemos un factor ordenado llamado `Valoración`, uno de cuyos niveles es  <<Bueno>>. ¿Cuál de las instrucciones siguientes calcula la frecuencia relativa acumulada de este nivel?

[(a)]
*   `cumsum(prop.table(table(Valoración)))["Bueno"]`   \retro{¡En efecto!}
*   `prop.table(cumsum(table(Valoración)))["Bueno"]`   \retro{Esta instrucción no calcula frecuencias relativas acumuladas}
*   `cumsum(prop.table(table(Valoración)))[,"Bueno"]` \retro{¿Es bidimensional, la tabla?}
*   `cumsum(prop.table(table(Valoración)))[Bueno]` \retro{Esas comillas...}



* Considerad el vector [http://bioinfo.uib.es/~recerca/RMOOC/datostest9.txt](http://bioinfo.uib.es/~recerca/RMOOC/datostest9.txt)  como una variable ordinal de niveles $1,2,3,... ,9$, ordenados con su orden creciente natural. ¿Cuál es la frecuencia relativa acumulada de 6 en esta variable, redondeada a 3 cifras decimales?


[(a)]
*   0.103 \retro{¿Has calculado la frecuencia relativa sin acumular?}
*    0.397  \retro{¡Correcto!}
*   0.096 \retro{Cuidado con el orden en el que has aplicado las funciones...}
*   0.006    \retro{Recuerda que prop.table se aplica a una tabla, no a un vector}


* Considerad la tabla de datos [http://bioinfo.uib.es/~recerca/RMOOC/Felizdata.txt](http://bioinfo.uib.es/~recerca/RMOOC/Felizdata.txt) . Considerad su variable `nivel.feliz` como una variable ordinal con niveles ordenados
$$
\mbox{<<Infeliz>>} < \mbox{<<Poco.feliz>>} < \mbox{<<Feliz>>} < \mbox{<<Muy.feliz>>}
$$ 
¿Cuál es la frecuencia relativa acumulada del nivel <<Feliz>> (redondeada a 3 cifras decimales) entre los estudiantes de segundo curso de ambos sexos?

[(a)]
*   0.763  \retro{¡Muy bien!}
*   0.658  \retro{¿Cómo has ordenado los niveles?}
*   0.316 \retro{¿Cómo has ordenado los niveles?}
*    0.75  \retro{¿Te has acordado de restringirte a los estudiantes de segundo curso?}





%%%%%%%%%%%%%%%%%%%%

## Test de la Lección 9


[(1)]


* Considerad la tabla de datos `happy` del paquete `faraway`. 
¿Cuál de los cuatro valores de la variable `work` da un valor medio mayor de la variable
`money`?

[(a)]
*   1  \retro{¿Cómo has calculado las medias? Uno de los otros valores de work  da una media más alta en money}
*   2 \retro{¿Cómo has calculado las medias? Uno de los otros valores de work  da una media más alta en money }
*   4  \retro{¡Perfecto!}
*   Ninguno de los anteriores \retro{Sí que es uno de los anteriores}




* Considerad de nuevo la tabla de datos `happy` del paquete `faraway`. 
¿Qué vale la varianza, redondeada a 3 cifras decimales, de los valores que toma la variable `happy` entre los individuos de esta tabla  que tienen una actividad sexual satisfactoria?

[(a)]
*    3.37  \retro{Esta es la varianza de la variable happy completa}
*    3.217 \retro{¿Has calculado la varianza, o la varianza muestral?}
*     3.097  \retro{¡En efecto!}
*    3.34   \retro{¿Cómo has calculado la varianza a partir de la varianza muestral?}


* Considerad la tabla de datos  [http://bioinfo.uib.es/~recerca/RMOOC/heartatk4R.txt](http://bioinfo.uib.es/~recerca/RMOOC/heartatk4R.txt) . 
¿Qué vale, redondeada a un entero, la mediana de los valores que toma la variable `CHARGES` entre los individuos que no murieron (tienen un 0 en la variable `DIED`)? 

[(a)]
*   8701  \retro{¡Correcto!}
*   8445   \retro{Esta es la varianza de la variable CHARGES completa}
*  10087   \retro{¿No habrás calculado la media, en vez de la mediana?}
*   No existe \retro{¿Cómo no va a existir? Acuérdate de eliminar los NA}



* Si importáis  la tabla de datos [http://bioinfo.uib.es/~recerca/RMOOC/pulse.txt](http://bioinfo.uib.es/~recerca/RMOOC/pulse.txt)  en un *data frame* llamado `pulse.df`, ¿cuál de las instrucciones siguientes produce el gráfico de la Figura \@ref(fig:test10.3), que agrupa los diagramas de caja de su variable `PuBefor` segmentada en chicas y chicos?

[(a)]
*  \verb+boxplot(PuBefor~Sex, data=pulse.df)+  \retro{Ejecútala, a ver... Mira los nombres bajo las cajas.}
*   \verb+boxplot(PuBefor~Sex, data=pulse.df, names=c("Chicas","Chicos"))+ \retro{¡En efecto!}
*  \verb+boxplot(PuBefor~Sex, data=pulse.df, names=c("Chicos","Chicas"))+   \retro{Ejecútala, a ver... Mira los nombres bajo las cajas.}
*   \verb+boxplot(PuBefor, Sex, names=c("Chicas","Chicos"))+  \retro{¿Has probado a ejecutarla?}




\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.45\linewidth]{pulsebp.pdf}
\end{center}
\caption{Gráfico de la pregunta 4 del test de la Lección 10.}\label{fig:test10.3}
\end{figure}



## Test de la Lección 10

[(1)]



* Supongamos que tenemos un conjunto de 80 datos expresados con una precisión de una décima de unidad. Su valor mínimo es 15 y el máximo, 83. Su desviación típica muestral es $2.5623$ y su rango intercuartílico $3.1721$. Según la regla de Scott, ¿en cuántas clases los tendríamos que agrupar y qué amplitud tendrían estas clases? 


[(a)]
*    3 clases de amplitud 22.7 \retro{¿Cómo has calculado el número de clases?}
*   33 clases de amplitud 2.1 \retro{¡Correcto!}
*   32.7 clases de amplitud 2.1 \retro{¿Un número no entero de clases?}
*   47 clases  de amplitud 1.5 \retro{¿No habrás empleado la regla de Freedman-Diaconis, en vez de la de Scott?}



* Considerad el mismo conjunto de datos que en la pregunta anterior. Si los agrupamos según la regla de Freedman-Diaconis, ¿qué valdría el extremo izquierdo del tercer intervalo que obtendríamos? 

[(a)]
*    17.5 \retro{¡Cuidado! Aunque el mínimo sea un número entero, hemos dicho que los datos tienen precisión de una cifra decimal}
*   19.45 \retro{Míralo bien: éste es el extremo izquierdo del cuarto intervalo}
*   17.95 \retro{¡Muy bien!}
*   19.15 \retro{¿No habrás empleado la regla de Scott, en vez de la de Freedman-Diaconis?}



* Agrupad según la regla de Freedman-Diaconis los datos de la variable `uptake` del *data frame* `CO2` que lleva predefinido `R` (están expresados con una precisión de una cifra decimal). ¿Qué vale el extremo izquierdo del cuarto intervalo que habéis obtenido? 


[(a)]
*    30.45  \retro{¡En efecto!}
*   22.85 \retro{Míralo bien: éste es el extremo izquierdo del tercer intervalo}
*   38.05 \retro{Míralo bien: éste es el extremo izquierdo del quinto intervalo}
*   Ninguno de los anteriores \retro{Sí que es uno de los anteriores}



* Agrupad según la regla de Freedman-Diaconis los datos de la variable `uptake` del *data frame* `CO2` que lleva predefinido `R` (están expresados con una precisión de una cifra decimal). ¿Cuál es la frecuencia relativa de su tercer intervalo, redondeada a 3 cifras decimales?

[(a)]
*    0.143  \retro{¡Efectivamente!}
*   0.131 \retro{¿Has usado la construcción de los intervalos explicada en la lección?}
*   0.133 \retro{¿De qué amplitud has tomado las clases?}
*   Ninguno de los anteriores \retro{Sí que es uno de los anteriores}



* Supongamos que tenemos un vector de datos llamado <<alturas>>. 
Queremos agrupar estos datos en intervalos con extremos dados por un vector llamado <<Extremos>> y codificando cada intervalo por él mismo, y llamar <<alturas\_{}cut>> al factor resultante. Los intervalos resultantes tienen que ser todos cerrados a la izquierda y abiertos a la derecha. ¿Cuál de las instrucciones siguientes lleva a cabo correctamente este agrupamiento?


[(a)]
*    \verb?cut(alturas,breaks=Extremos,labels=TRUE,right=FALSE)? \retro{No has puesto nombre al resultado}
*   \verb?alturas_cut=cut(alturas,breaks=Extremos,labels=Extremos,right=FALSE)? \retro{Las etiquetas están mal}
*   \verb?alturas_cut=cut(alturas,breaks=Extremos,right=FALSE)? \retro{¡Perfecto!}
*   \verb?alturas_cut=cut(alturas,breaks=Extremos,labels=TRUE,right=FALSE)? \retro{Las etiquetas están mal}



* Definid un *data frame* con la tabla [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) .  A continuación, agrupad los valores de su variable `MB` según la regla de Sturges (mirad antes con qué precisión están dadas sus entradas). ¿Cuál es la frecuencia  absoluta del intervalo modal de este agrupamiento? 

[(a)]
*    48 \retro{¡Correcto!}
*   42 \retro{¿Has usado la construcción de los intervalos explicada en la lección?}
*   33 \retro{¿De qué amplitud has tomado las clases?}
*   36 \retro{¿De qué amplitud has tomado las clases?}




* Definid un *data frame* con la tabla [http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt](http://bioinfo.uib.es/~recerca/RMOOC/ESD.txt) .  A continuación, agrupad los valores de su variable `MB` según la regla de Sturges  (mirad antes con qué precisión están dadas sus entradas) y producid el histograma de este agrupamiento. ¿Cuánto vale la densidad del tercer intervalo, redondeada a 3 cifras decimales? 

[(a)]
*   0.022 \retro{¿Has usado la construcción de los intervalos explicada en la lección?}
*   0.033 \retro{¡En efecto!}
*   0.133 \retro{Esta es la frecuencia relativa de esta clase, no su densidad}
*   20 \retro{Esta es la frecuencia absoluta de esta clase, no su densidad}





%%%%%%







## Test de la lección 11


[(1)]



* Considerad la matriz
$$
X=\left(\begin{array}{ccc}
1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \\ 10 & 11 & 12 \\ 13 & 14 & 15\end{array}\right).
$$
¿Qué vale la entrada (2,3) de su matriz tipificada, redondeada a 3 cifras decimales?

[(a)]
* $-3$ \retro{Sólo la has centrado} 
*  $-0.632$ \retro{¿Has dividido por las desviaciones típicas muestrales o por las verdaderas?}
*  $-0.707$  \retro{¡Correcto!}
*  $-0.167$  \retro{¿Has dividido por las varianzas o por las desviaciones típicas?}



* Considerad la matriz
$$
X=\left(\begin{array}{ccc}
1 & 2 & 3 \\ 6 & 5 & 4 \\ -7 & 8 & -9 \\ 10 & 11 & 10\\ 2 & 5 & 7\end{array}\right).
$$
¿Qué vale la covarianza <<verdadera>> entre su segunda y su tercera columna, redondeada a 3 cifras decimales?

[(a)]
* $1.5$ \retro{¿Has calculado la covarianza muestral o la verdadera?}
*  $1.2$ \retro{¡Perfecto!}
*  $1.875$  \retro{¿Cómo has calculado la covarianza a partir de la covarianza muestral?}
*  $0.061$  \retro{¿Has calculado la correlación?}


* Una de estas tres matrices es la matriz de correlaciones de una tabla de datos de dos columnas. ¿Cuál?
$$
A=\left(
\begin{array}{ccc}
  1 & 1.2   \\ 
  1.2 & 1 
  \end{array}\right)
B=\left(\begin{array}{cc}
1 & 0.8\\ -0.8 & 1\end{array}
\right) 
C=\left(\begin{array}{cc}
0.6 & 0.8\\ 0.8 & 0.6\end{array}
\right) 
$$

[(a)]
* $A$ \retro{Una correlación no puede ser >1}
* $B$ \retro{La matriz de correlaciones es simétrica}
* $C$  \retro{La diagonal de la matriz de correlaciones está formada por unos}
* Hemos mentido, ninguna de las tres es una matriz de correlaciones \retro{¡En efecto! ¡Bien visto!}



* Considerad la tabla de datos `happy` del paquete `faraway`. 
¿Qué vale, redondeada a 3 cifras decimales, la correlación entre el nivel de felicidad (variable `happy`) y los ingresos familiares (variable `money`) para los individuos de esta muestra que no se sienten solos?

[(a)]
*   $23.486$  \retro{Esto es la covarianza muestral}
*   $0.384$  \retro{¡Perfecto!}
*    $0.271$  \retro{Esta es la correlación en el total de la población}
*   $-0.427$  \retro{Esta es la correlación para los individuos de esta muestra que sí que se sienten solos}







